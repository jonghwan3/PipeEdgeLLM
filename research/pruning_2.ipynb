{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Models module.\"\"\"\n",
    "from typing import Any, Tuple, Type, Union\n",
    "from torch import nn, Tensor\n",
    "\n",
    "ModuleShardData: Type = Union[Tensor, Tuple[Tensor, ...]]\n",
    "\"\"\"A module shard input/output type.\"\"\"\n",
    "\n",
    "\n",
    "class ModuleShardConfig:\n",
    "    \"\"\"Base class for shard configurations (distinct from model configurations).\"\"\"\n",
    "    # pylint: disable=too-few-public-methods\n",
    "\n",
    "    def __init__(self, **kwargs: dict):\n",
    "        # Attributes with default values\n",
    "        self.layer_start: int = kwargs.pop('layer_start', 0)\n",
    "        self.layer_end: int = kwargs.pop('layer_end', 0)\n",
    "        self.is_first: bool = kwargs.pop('is_first', False)\n",
    "        self.is_last: bool = kwargs.pop('is_last', False)\n",
    "\n",
    "        # Attributes without default values\n",
    "        for key, value in kwargs.items():\n",
    "            setattr(self, key, value)\n",
    "\n",
    "\n",
    "class ModuleShard(nn.Module):\n",
    "    \"\"\"Abstract parent class for module shards.\"\"\"\n",
    "    # pylint: disable=abstract-method\n",
    "\n",
    "    def __init__(self, config: Any, shard_config: ModuleShardConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.shard_config = shard_config\n",
    "\n",
    "    def has_layer(self, layer: int) -> bool:\n",
    "        \"\"\"Check if shard has the specified layer.\"\"\"\n",
    "        return layer in range(self.shard_config.layer_start, self.shard_config.layer_end + 1)\n",
    "\n",
    "\n",
    "def get_microbatch_size(shard_data: ModuleShardData, verify: bool=False):\n",
    "    \"\"\"Get the microbatch size from shard data.\"\"\"\n",
    "    if isinstance(shard_data, Tensor):\n",
    "        shard_data = (shard_data,)\n",
    "    ubatch_size = 0 if len(shard_data) == 0 else len(shard_data[0])\n",
    "    if verify:\n",
    "        # Sanity check that tensors are the same length\n",
    "        for tensor in shard_data:\n",
    "            assert isinstance(tensor, Tensor)\n",
    "            assert len(tensor) == ubatch_size\n",
    "    return ubatch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A transformer shard input/output type.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Transformers module.\"\"\"\n",
    "from typing import Tuple, Type, Union\n",
    "from torch import Tensor\n",
    "\n",
    "TransformerShardData: Type = Union[Tensor, Tuple[Tensor, Tensor]]\n",
    "\"\"\"A transformer shard input/output type.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"ViT Transformers.\"\"\"\n",
    "from collections.abc import Mapping\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "from typing import Optional, Union\n",
    "import numpy as np\n",
    "import requests\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import ViTConfig\n",
    "from transformers.models.vit.modeling_vit import (\n",
    "    ViTEmbeddings, ViTIntermediate, ViTOutput, ViTSelfAttention, ViTSelfOutput\n",
    ")\n",
    "import torch.nn.functional as F\n",
    "import types\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "_WEIGHTS_URLS = {\n",
    "    'google/vit-base-patch16-224': 'https://storage.googleapis.com/vit_models/imagenet21k%2Bimagenet2012/ViT-B_16-224.npz',\n",
    "    'google/vit-large-patch16-224': 'https://storage.googleapis.com/vit_models/imagenet21k%2Bimagenet2012/ViT-L_16-224.npz',\n",
    "    'google/vit-huge-patch14-224-in21k': 'https://storage.googleapis.com/vit_models/imagenet21k/ViT-H_14.npz',\n",
    "}\n",
    "\n",
    "\n",
    "class ViTLayerShard(ModuleShard):\n",
    "    \"\"\"Module shard based on `ViTLayer`.\"\"\"\n",
    "\n",
    "    def __init__(self, config: ViTConfig, shard_config: ModuleShardConfig):\n",
    "        super().__init__(config, shard_config)\n",
    "        self.layernorm_before = None\n",
    "        self.self_attention = None\n",
    "        self.self_output = None\n",
    "        self.layernorm_after = None\n",
    "        self.intermediate = None\n",
    "        self.output = None\n",
    "        self._build_shard()\n",
    "\n",
    "    def _build_shard(self):\n",
    "        if self.has_layer(0):\n",
    "            self.layernorm_before = nn.LayerNorm(self.config.hidden_size,\n",
    "                                                 eps=self.config.layer_norm_eps)\n",
    "            self.self_attention = ViTSelfAttention(self.config)\n",
    "        if self.has_layer(1):\n",
    "            self.self_output = ViTSelfOutput(self.config)\n",
    "        if self.has_layer(2):\n",
    "            self.layernorm_after = nn.LayerNorm(self.config.hidden_size,\n",
    "                                                eps=self.config.layer_norm_eps)\n",
    "            self.intermediate = ViTIntermediate(self.config)\n",
    "        if self.has_layer(3):\n",
    "            self.output = ViTOutput(self.config)\n",
    "    \n",
    "\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def forward(self, data: TransformerShardData) -> TransformerShardData:\n",
    "        \"\"\"Compute layer shard.\"\"\"\n",
    "        if self.has_layer(0):\n",
    "            data_norm = self.layernorm_before(data)\n",
    "            data = (self.self_attention(data_norm)[0], data)\n",
    "        if self.has_layer(1):\n",
    "            skip = data[1]\n",
    "            data = self.self_output(data[0], skip)\n",
    "            data += skip\n",
    "        if self.has_layer(2):\n",
    "            data_norm = self.layernorm_after(data)\n",
    "            data = (self.intermediate(data_norm), data)\n",
    "        if self.has_layer(3):\n",
    "            data = self.output(data[0], data[1])\n",
    "        return data\n",
    "\n",
    "\n",
    "class ViTModelShard(ModuleShard):\n",
    "    \"\"\"Module shard based on `ViTModel` (no pooling layer).\"\"\"\n",
    "\n",
    "    def __init__(self, config: ViTConfig, shard_config: ModuleShardConfig,\n",
    "                 model_weights: Union[str, Mapping]):\n",
    "        super().__init__(config, shard_config)\n",
    "        self.embeddings = None\n",
    "        # ViTModel uses an encoder here, but we'll just add the layers here instead.\n",
    "        # Since we just do inference, a ViTEncoderShard class wouldn't provide real benefit.\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layernorm = None\n",
    "\n",
    "        logger.debug(\">>>> Model name: %s\", self.config.name_or_path)\n",
    "        if isinstance(model_weights, str):\n",
    "            logger.debug(\">>>> Load weight file: %s\", model_weights)\n",
    "            with np.load(model_weights) as weights:\n",
    "                self._build_shard(weights)\n",
    "        else:\n",
    "            self._build_shard(model_weights)\n",
    "\n",
    "    def _build_shard(self, weights):\n",
    "        if self.shard_config.is_first:\n",
    "            logger.debug(\">>>> Load embeddings layer for the first shard\")\n",
    "            self.embeddings = ViTEmbeddings(self.config)\n",
    "            self._load_weights_first(weights)\n",
    "\n",
    "        layer_curr = self.shard_config.layer_start\n",
    "        while layer_curr <= self.shard_config.layer_end:\n",
    "            layer_id = math.ceil(layer_curr / 4) - 1\n",
    "            sublayer_start = (layer_curr - 1) % 4\n",
    "            if layer_id == math.ceil(self.shard_config.layer_end / 4) - 1:\n",
    "                sublayer_end = (self.shard_config.layer_end - 1) % 4\n",
    "            else:\n",
    "                sublayer_end = 3\n",
    "            logger.debug(\">>>> Load layer %d, sublayers %d-%d\",\n",
    "                         layer_id, sublayer_start, sublayer_end)\n",
    "            layer_config = ModuleShardConfig(layer_start=sublayer_start, layer_end=sublayer_end)\n",
    "            layer = ViTLayerShard(self.config, layer_config)\n",
    "            self._load_weights_layer(weights, layer_id, layer)\n",
    "            self.layers.append(layer)\n",
    "            layer_curr += sublayer_end - sublayer_start + 1\n",
    "\n",
    "        if self.shard_config.is_last:\n",
    "            logger.debug(\">>>> Load layernorm for the last shard\")\n",
    "            self.layernorm = nn.LayerNorm(self.config.hidden_size, eps=self.config.layer_norm_eps)\n",
    "            self._load_weights_last(weights)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _load_weights_first(self, weights):\n",
    "        self.embeddings.cls_token.copy_(torch.from_numpy(weights[\"cls\"]))\n",
    "        self.embeddings.position_embeddings.copy_(torch.from_numpy((weights[\"Transformer/posembed_input/pos_embedding\"])))\n",
    "        conv_weight = weights[\"embedding/kernel\"]\n",
    "        # O, I, J, K = conv_weight.shape\n",
    "        # conv_weight = conv_weight.reshape(K,J,O,I)\n",
    "        conv_weight = conv_weight.transpose([3, 2, 0, 1])\n",
    "        self.embeddings.patch_embeddings.projection.weight.copy_(torch.from_numpy(conv_weight))\n",
    "        self.embeddings.patch_embeddings.projection.bias.copy_(torch.from_numpy(weights[\"embedding/bias\"]))\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _load_weights_last(self, weights):\n",
    "        self.layernorm.weight.copy_(torch.from_numpy(weights[\"Transformer/encoder_norm/scale\"]))\n",
    "        self.layernorm.bias.copy_(torch.from_numpy(weights[\"Transformer/encoder_norm/bias\"]))\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _load_weights_layer(self, weights, layer_id, layer):\n",
    "        root = f\"Transformer/encoderblock_{layer_id}/\"\n",
    "        hidden_size = self.config.hidden_size\n",
    "        if layer.has_layer(0):\n",
    "            layer.layernorm_before.weight.copy_(torch.from_numpy(weights[root + \"LayerNorm_0/scale\"]))\n",
    "            layer.layernorm_before.bias.copy_(torch.from_numpy(weights[root + \"LayerNorm_0/bias\"]))\n",
    "            layer.self_attention.query.weight.copy_(torch.from_numpy(weights[root + \"MultiHeadDotProductAttention_1/query/kernel\"]).view(hidden_size, hidden_size).t())\n",
    "            layer.self_attention.key.weight.copy_(torch.from_numpy(weights[root + \"MultiHeadDotProductAttention_1/key/kernel\"]).view(hidden_size, hidden_size).t())\n",
    "            layer.self_attention.value.weight.copy_(torch.from_numpy(weights[root + \"MultiHeadDotProductAttention_1/value/kernel\"]).view(hidden_size, hidden_size).t())\n",
    "            layer.self_attention.query.bias.copy_(torch.from_numpy(weights[root + \"MultiHeadDotProductAttention_1/query/bias\"]).view(-1))\n",
    "            layer.self_attention.key.bias.copy_(torch.from_numpy(weights[root + \"MultiHeadDotProductAttention_1/key/bias\"]).view(-1))\n",
    "            layer.self_attention.value.bias.copy_(torch.from_numpy(weights[root + \"MultiHeadDotProductAttention_1/value/bias\"]).view(-1))\n",
    "        if layer.has_layer(1):\n",
    "            layer.self_output.dense.weight.copy_(torch.from_numpy(weights[root + \"MultiHeadDotProductAttention_1/out/kernel\"]).view(hidden_size, hidden_size).t())\n",
    "            layer.self_output.dense.bias.copy_(torch.from_numpy(weights[root + \"MultiHeadDotProductAttention_1/out/bias\"]).view(-1))\n",
    "        if layer.has_layer(2):\n",
    "            layer.layernorm_after.weight.copy_(torch.from_numpy(weights[root + \"LayerNorm_2/scale\"]))\n",
    "            layer.layernorm_after.bias.copy_(torch.from_numpy(weights[root + \"LayerNorm_2/bias\"]))\n",
    "            layer.intermediate.dense.weight.copy_(torch.from_numpy(weights[root + \"MlpBlock_3/Dense_0/kernel\"]).t())\n",
    "            layer.intermediate.dense.bias.copy_(torch.from_numpy(weights[root + \"MlpBlock_3/Dense_0/bias\"]).t())\n",
    "        if layer.has_layer(3):\n",
    "            layer.output.dense.weight.copy_(torch.from_numpy(weights[root + \"MlpBlock_3/Dense_1/kernel\"]).t())\n",
    "            layer.output.dense.bias.copy_(torch.from_numpy(weights[root + \"MlpBlock_3/Dense_1/bias\"]).t())\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def forward(self, data: TransformerShardData) -> TransformerShardData:\n",
    "        \"\"\"Compute shard layers.\"\"\"\n",
    "        if self.shard_config.is_first:\n",
    "            data = self.embeddings(data)\n",
    "        for layer in self.layers:\n",
    "            data = layer(data)\n",
    "        if self.shard_config.is_last:\n",
    "            data = self.layernorm(data)\n",
    "        return data\n",
    "\n",
    "    @staticmethod\n",
    "    def save_weights(model_name: str, model_file: str, url: Optional[str]=None,\n",
    "                     timeout_sec: Optional[float]=None) -> None:\n",
    "        \"\"\"Save the model weights file.\"\"\"\n",
    "        if url is None:\n",
    "            url = _WEIGHTS_URLS[model_name]\n",
    "        logger.info('Downloading model: %s: %s', model_name, url)\n",
    "        req = requests.get(url, stream=True, timeout=timeout_sec)\n",
    "        req.raise_for_status()\n",
    "        with open(model_file, 'wb') as file:\n",
    "            for chunk in req.iter_content(chunk_size=8192):\n",
    "                if chunk:\n",
    "                    file.write(chunk)\n",
    "                    file.flush()\n",
    "                    os.fsync(file.fileno())\n",
    "\n",
    "\n",
    "class ViTShardForImageClassification(ModuleShard):\n",
    "    \"\"\"Module shard based on `ViTForImageClassification`.\"\"\"\n",
    "\n",
    "    def __init__(self, config: ViTConfig, shard_config: ModuleShardConfig,\n",
    "                 model_weights: Union[str, Mapping]):\n",
    "        super().__init__(config, shard_config)\n",
    "        self.vit = None\n",
    "        self.classifier = None\n",
    "\n",
    "        logger.debug(\">>>> Model name: %s\", self.config.name_or_path)\n",
    "        if isinstance(model_weights, str):\n",
    "            logger.debug(\">>>> Load weight file: %s\", model_weights)\n",
    "            with np.load(model_weights) as weights:\n",
    "                self._build_shard(weights)\n",
    "        else:\n",
    "            self._build_shard(model_weights)\n",
    "\n",
    "    def _build_shard(self, weights):\n",
    "        ## all shards use the inner ViT model\n",
    "        self.vit = ViTModelShard(self.config, self.shard_config, weights)\n",
    "\n",
    "        if self.shard_config.is_last:\n",
    "            logger.debug(\">>>> Load classifier for the last shard\")\n",
    "            self.classifier = nn.Linear(self.config.hidden_size, self.config.num_labels) if self.config.num_labels > 0 else nn.Identity()\n",
    "            self._load_weights_last(weights, pruned=False)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _load_weights_last(self, weights, pruned=False):\n",
    "        if(pruned):\n",
    "            with np.load('vit_snip_pruned.npz') as weights_pruned:\n",
    "                print(1)\n",
    "                self.classifier.weight.copy_(torch.from_numpy(weights_pruned['classifier.weight']))\n",
    "                self.classifier.bias.copy_(torch.from_numpy(weights_pruned['classifier.bias']))\n",
    "        else:\n",
    "            self.classifier.weight.copy_(torch.from_numpy(np.transpose(weights[\"head/kernel\"])))\n",
    "            self.classifier.bias.copy_(torch.from_numpy(weights[\"head/bias\"]))\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def forward(self, data: TransformerShardData) -> TransformerShardData:\n",
    "        \"\"\"Compute shard layers.\"\"\"\n",
    "        data = self.vit(data)\n",
    "        if self.shard_config.is_last:\n",
    "            data = self.classifier(data[:, 0, :])\n",
    "        return data\n",
    "    \n",
    "    def prune_snip_transformer(self, ubatch, ubatch_labels):\n",
    "        self.vit.weight_mask = nn.Parameter(torch.ones_like(self.vit.weight))\n",
    "        self.vit.forward = types.MethodType(snip_forward_linear, self.vit)\n",
    "    \n",
    "    def prune_snip(self, ubatch, ubatch_labels):\n",
    "        self.classifier.weight_mask = nn.Parameter(torch.ones_like(self.classifier.weight))\n",
    "        self.classifier.forward = types.MethodType(snip_forward_linear, self.classifier)\n",
    "        self.zero_grad()\n",
    "        ubatch = self.vit(ubatch)\n",
    "        ubatch = self.classifier(ubatch[:, 0, :])\n",
    "        loss = F.nll_loss(ubatch, ubatch_labels)\n",
    "        loss.backward()\n",
    "        print(loss)\n",
    "        print(self.classifier.weight_mask.grad)\n",
    "        grads_abs = []\n",
    "        grads_abs.append(torch.abs(self.classifier.weight_mask.grad))\n",
    "        all_scores = torch.cat([torch.flatten(x) for x in grads_abs])\n",
    "        norm_factor = torch.sum(all_scores)\n",
    "        all_scores.div_(norm_factor)\n",
    "        keep_ratio = 0.0001\n",
    "        num_params_to_keep = int(len(all_scores) * keep_ratio)\n",
    "        threshold, _ = torch.topk(all_scores, num_params_to_keep, sorted=True)\n",
    "        acceptable_score = threshold[-1]\n",
    "        keep_masks = []\n",
    "        for g in grads_abs:\n",
    "            keep_masks.append(((g / norm_factor) >= acceptable_score).float())\n",
    "        print(torch.sum(torch.cat([torch.flatten(x == 1) for x in keep_masks])))\n",
    "        self.classifier.weight.data[keep_masks[0] == 0.] = 0.\n",
    "        model_file = 'vit_snip_pruned.npz'\n",
    "        weights = {}\n",
    "        weights['classifier.weight'] = self.classifier.weight.detach().numpy()\n",
    "        weights['classifier.bias'] = self.classifier.bias.detach().numpy()\n",
    "        # print(1)\n",
    "        np.savez(model_file, **weights)\n",
    "\n",
    "        # with np.load('vit_snip_pruned.npz') as weights_pruned:\n",
    "        #     print(1)\n",
    "        #     self.classifier.weight.copy_(torch.from_numpy(weights_pruned['classifier.weight']))\n",
    "        #     self.classifier.bias.copy_(torch.from_numpy(weights_pruned['classifier.bias']))\n",
    "\n",
    "# def save_weights(model_name: str, model_file: str) -> None:\n",
    "#     \"\"\"Save the model weights file.\"\"\"\n",
    "#     model = BertForSequenceClassification.from_pretrained(model_name)\n",
    "#     state_dict = model.state_dict()\n",
    "#     weights = {}\n",
    "#     for key, val in state_dict.items():\n",
    "#         weights[key] = val\n",
    "#     np.savez(model_file, **weights)\n",
    "\n",
    "\n",
    "# @staticmethod\n",
    "# def save_weights(model_name: str, model_file: str, url: Optional[str]=None,\n",
    "#                     timeout_sec: Optional[float]=None) -> None:\n",
    "#     \"\"\"Save the model weights file.\"\"\"\n",
    "#     if url is None:\n",
    "#         url = _WEIGHTS_URLS[model_name]\n",
    "#     logger.info('Downloading model: %s: %s', model_name, url)\n",
    "#     req = requests.get(url, stream=True, timeout=timeout_sec)\n",
    "#     req.raise_for_status()\n",
    "#     with open(model_file, 'wb') as file:\n",
    "#         for chunk in req.iter_content(chunk_size=8192):\n",
    "#             if chunk:\n",
    "#                 file.write(chunk)\n",
    "#                 file.flush()\n",
    "#                 os.fsync(file.fileno())\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def save_weights(model_name: str, model_file: str, url: Optional[str]=None,\n",
    "                     timeout_sec: Optional[float]=None) -> None:\n",
    "        \"\"\"Save the model weights file.\"\"\"\n",
    "        ViTModelShard.save_weights(model_name, model_file, url=url, timeout_sec=timeout_sec)\n",
    "\n",
    "def snip_forward_linear(self, x):\n",
    "    return F.linear(x, self.weight * self.weight_mask, self.bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = nn.ModuleList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pipellm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
