{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models,datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/fogsys/PipeEdge/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/alex/fogsys/PipeEdge/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /home/alex/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:11<00:00, 9.01MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load the pretrained ResNet-18 model\n",
    "model = models.resnet50(pretrained=True)\n",
    "# num_ftrs = model.fc.in_features\n",
    "# model.fc = nn.Linear(num_ftrs, 10)  # CIFAR-10 has 10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
<<<<<<< HEAD
=======
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/fogsys/PipeEdge/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/alex/fogsys/PipeEdge/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load the pretrained ResNet-18 model\n",
    "model34 = models.resnet34(pretrained=True)\n",
    "# num_ftrs = model.fc.in_features\n",
    "# model.fc = nn.Linear(num_ftrs, 10)  # CIFAR-10 has 10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/fogsys/PipeEdge/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
>>>>>>> e4bd167 (update resnet 34 and 50)
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): BasicBlock(\n",
       "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (1): BasicBlock(\n",
       "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layer1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layer1[0].conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetConfig:\n",
    "    def __init__(self, model=None):\n",
    "        self.info = {}\n",
    "        if model:\n",
    "            self.generate_config(model)\n",
    "\n",
    "    def get_layer_info(self, layer):\n",
    "        info = {}\n",
    "        \n",
    "        if isinstance(layer, models.resnet.BasicBlock):\n",
    "            for sub_name, sub_child in layer.named_children():\n",
    "                if sub_name == \"downsample\":\n",
    "                    print('dd')\n",
    "                    info[\"downsample_conv\"] = self.get_layer_info(sub_child[0])\n",
    "                    info[\"downsample_bn\"] = self.get_layer_info(sub_child[1])\n",
    "                    print(info)\n",
    "                else:\n",
    "                    info[sub_name] = self.get_layer_info(sub_child)\n",
    "\n",
    "        elif isinstance(layer, nn.Conv2d):\n",
    "            info['in_channels'] = layer.in_channels\n",
    "            info['out_channels'] = layer.out_channels\n",
    "            info['kernel_size'] = layer.kernel_size\n",
    "            info['stride'] = layer.stride\n",
    "            info['padding'] = layer.padding\n",
    "            info['bias'] = layer.bias is not None\n",
    "\n",
    "        elif isinstance(layer, nn.BatchNorm2d):\n",
    "            info['num_features'] = layer.num_features\n",
    "            info['eps'] = layer.eps\n",
    "            info['momentum'] = layer.momentum\n",
    "            info['affine'] = layer.affine\n",
    "            info['track_running_stats'] = layer.track_running_stats\n",
    "\n",
    "        elif isinstance(layer, nn.ReLU):\n",
    "            info['inplace'] = layer.inplace\n",
    "\n",
    "        elif isinstance(layer, nn.MaxPool2d):\n",
    "            info['kernel_size'] = layer.kernel_size\n",
    "            info['stride'] = layer.stride\n",
    "            info['padding'] = layer.padding\n",
    "            info['dilation'] = layer.dilation\n",
    "            info['ceil_mode'] = layer.ceil_mode\n",
    "\n",
    "        elif isinstance(layer, nn.AdaptiveAvgPool2d):\n",
    "            info['output_size'] = layer.output_size\n",
    "\n",
    "        elif isinstance(layer, nn.Linear):\n",
    "            info['in_features'] = layer.in_features\n",
    "            info['out_features'] = layer.out_features\n",
    "            info['bias'] = layer.bias is not None\n",
    "\n",
    "        return info\n",
    "\n",
    "    def generate_config(self, model):\n",
    "        for name, child in model.named_children():\n",
    "            if list(child.children()): \n",
    "                for sub_name, sub_child in child.named_children():\n",
    "                    self.info[f\"{name}_{sub_name}\"] = self.get_layer_info(sub_child)\n",
    "            else:\n",
    "                self.info[name] = self.get_layer_info(child)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        return self.info[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.conv1.children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_config = ResnetConfig(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conv1': {'in_channels': 3,\n",
       "  'out_channels': 64,\n",
       "  'kernel_size': (7, 7),\n",
       "  'stride': (2, 2),\n",
       "  'padding': (3, 3),\n",
       "  'bias': False},\n",
       " 'bn1': {'num_features': 64,\n",
       "  'eps': 1e-05,\n",
       "  'momentum': 0.1,\n",
       "  'affine': True,\n",
       "  'track_running_stats': True},\n",
       " 'relu': {'inplace': True},\n",
       " 'maxpool': {'kernel_size': 3,\n",
       "  'stride': 2,\n",
       "  'padding': 1,\n",
       "  'dilation': 1,\n",
       "  'ceil_mode': False},\n",
       " 'layer1_0': {'conv1': {'in_channels': 64,\n",
       "   'out_channels': 64,\n",
       "   'kernel_size': (3, 3),\n",
       "   'stride': (1, 1),\n",
       "   'padding': (1, 1),\n",
       "   'bias': False},\n",
       "  'bn1': {'num_features': 64,\n",
       "   'eps': 1e-05,\n",
       "   'momentum': 0.1,\n",
       "   'affine': True,\n",
       "   'track_running_stats': True},\n",
       "  'relu': {'inplace': True},\n",
       "  'conv2': {'in_channels': 64,\n",
       "   'out_channels': 64,\n",
       "   'kernel_size': (3, 3),\n",
       "   'stride': (1, 1),\n",
       "   'padding': (1, 1),\n",
       "   'bias': False},\n",
       "  'bn2': {'num_features': 64,\n",
       "   'eps': 1e-05,\n",
       "   'momentum': 0.1,\n",
       "   'affine': True,\n",
       "   'track_running_stats': True}},\n",
       " 'layer1_1': {'conv1': {'in_channels': 64,\n",
       "   'out_channels': 64,\n",
       "   'kernel_size': (3, 3),\n",
       "   'stride': (1, 1),\n",
       "   'padding': (1, 1),\n",
       "   'bias': False},\n",
       "  'bn1': {'num_features': 64,\n",
       "   'eps': 1e-05,\n",
       "   'momentum': 0.1,\n",
       "   'affine': True,\n",
       "   'track_running_stats': True},\n",
       "  'relu': {'inplace': True},\n",
       "  'conv2': {'in_channels': 64,\n",
       "   'out_channels': 64,\n",
       "   'kernel_size': (3, 3),\n",
       "   'stride': (1, 1),\n",
       "   'padding': (1, 1),\n",
       "   'bias': False},\n",
       "  'bn2': {'num_features': 64,\n",
       "   'eps': 1e-05,\n",
       "   'momentum': 0.1,\n",
       "   'affine': True,\n",
       "   'track_running_stats': True}},\n",
       " 'layer2_0': {'conv1': {'in_channels': 64,\n",
       "   'out_channels': 128,\n",
       "   'kernel_size': (3, 3),\n",
       "   'stride': (2, 2),\n",
       "   'padding': (1, 1),\n",
       "   'bias': False},\n",
       "  'bn1': {'num_features': 128,\n",
       "   'eps': 1e-05,\n",
       "   'momentum': 0.1,\n",
       "   'affine': True,\n",
       "   'track_running_stats': True},\n",
       "  'relu': {'inplace': True},\n",
       "  'conv2': {'in_channels': 128,\n",
       "   'out_channels': 128,\n",
       "   'kernel_size': (3, 3),\n",
       "   'stride': (1, 1),\n",
       "   'padding': (1, 1),\n",
       "   'bias': False},\n",
       "  'bn2': {'num_features': 128,\n",
       "   'eps': 1e-05,\n",
       "   'momentum': 0.1,\n",
       "   'affine': True,\n",
       "   'track_running_stats': True},\n",
       "  'downsample_conv': {'in_channels': 64,\n",
       "   'out_channels': 128,\n",
       "   'kernel_size': (1, 1),\n",
       "   'stride': (2, 2),\n",
       "   'padding': (0, 0),\n",
       "   'bias': False},\n",
       "  'downsample_bn': {'num_features': 128,\n",
       "   'eps': 1e-05,\n",
       "   'momentum': 0.1,\n",
       "   'affine': True,\n",
       "   'track_running_stats': True}},\n",
       " 'layer2_1': {'conv1': {'in_channels': 128,\n",
       "   'out_channels': 128,\n",
       "   'kernel_size': (3, 3),\n",
       "   'stride': (1, 1),\n",
       "   'padding': (1, 1),\n",
       "   'bias': False},\n",
       "  'bn1': {'num_features': 128,\n",
       "   'eps': 1e-05,\n",
       "   'momentum': 0.1,\n",
       "   'affine': True,\n",
       "   'track_running_stats': True},\n",
       "  'relu': {'inplace': True},\n",
       "  'conv2': {'in_channels': 128,\n",
       "   'out_channels': 128,\n",
       "   'kernel_size': (3, 3),\n",
       "   'stride': (1, 1),\n",
       "   'padding': (1, 1),\n",
       "   'bias': False},\n",
       "  'bn2': {'num_features': 128,\n",
       "   'eps': 1e-05,\n",
       "   'momentum': 0.1,\n",
       "   'affine': True,\n",
       "   'track_running_stats': True}},\n",
       " 'layer3_0': {'conv1': {'in_channels': 128,\n",
       "   'out_channels': 256,\n",
       "   'kernel_size': (3, 3),\n",
       "   'stride': (2, 2),\n",
       "   'padding': (1, 1),\n",
       "   'bias': False},\n",
       "  'bn1': {'num_features': 256,\n",
       "   'eps': 1e-05,\n",
       "   'momentum': 0.1,\n",
       "   'affine': True,\n",
       "   'track_running_stats': True},\n",
       "  'relu': {'inplace': True},\n",
       "  'conv2': {'in_channels': 256,\n",
       "   'out_channels': 256,\n",
       "   'kernel_size': (3, 3),\n",
       "   'stride': (1, 1),\n",
       "   'padding': (1, 1),\n",
       "   'bias': False},\n",
       "  'bn2': {'num_features': 256,\n",
       "   'eps': 1e-05,\n",
       "   'momentum': 0.1,\n",
       "   'affine': True,\n",
       "   'track_running_stats': True},\n",
       "  'downsample_conv': {'in_channels': 128,\n",
       "   'out_channels': 256,\n",
       "   'kernel_size': (1, 1),\n",
       "   'stride': (2, 2),\n",
       "   'padding': (0, 0),\n",
       "   'bias': False},\n",
       "  'downsample_bn': {'num_features': 256,\n",
       "   'eps': 1e-05,\n",
       "   'momentum': 0.1,\n",
       "   'affine': True,\n",
       "   'track_running_stats': True}},\n",
       " 'layer3_1': {'conv1': {'in_channels': 256,\n",
       "   'out_channels': 256,\n",
       "   'kernel_size': (3, 3),\n",
       "   'stride': (1, 1),\n",
       "   'padding': (1, 1),\n",
       "   'bias': False},\n",
       "  'bn1': {'num_features': 256,\n",
       "   'eps': 1e-05,\n",
       "   'momentum': 0.1,\n",
       "   'affine': True,\n",
       "   'track_running_stats': True},\n",
       "  'relu': {'inplace': True},\n",
       "  'conv2': {'in_channels': 256,\n",
       "   'out_channels': 256,\n",
       "   'kernel_size': (3, 3),\n",
       "   'stride': (1, 1),\n",
       "   'padding': (1, 1),\n",
       "   'bias': False},\n",
       "  'bn2': {'num_features': 256,\n",
       "   'eps': 1e-05,\n",
       "   'momentum': 0.1,\n",
       "   'affine': True,\n",
       "   'track_running_stats': True}},\n",
       " 'layer4_0': {'conv1': {'in_channels': 256,\n",
       "   'out_channels': 512,\n",
       "   'kernel_size': (3, 3),\n",
       "   'stride': (2, 2),\n",
       "   'padding': (1, 1),\n",
       "   'bias': False},\n",
       "  'bn1': {'num_features': 512,\n",
       "   'eps': 1e-05,\n",
       "   'momentum': 0.1,\n",
       "   'affine': True,\n",
       "   'track_running_stats': True},\n",
       "  'relu': {'inplace': True},\n",
       "  'conv2': {'in_channels': 512,\n",
       "   'out_channels': 512,\n",
       "   'kernel_size': (3, 3),\n",
       "   'stride': (1, 1),\n",
       "   'padding': (1, 1),\n",
       "   'bias': False},\n",
       "  'bn2': {'num_features': 512,\n",
       "   'eps': 1e-05,\n",
       "   'momentum': 0.1,\n",
       "   'affine': True,\n",
       "   'track_running_stats': True},\n",
       "  'downsample_conv': {'in_channels': 256,\n",
       "   'out_channels': 512,\n",
       "   'kernel_size': (1, 1),\n",
       "   'stride': (2, 2),\n",
       "   'padding': (0, 0),\n",
       "   'bias': False},\n",
       "  'downsample_bn': {'num_features': 512,\n",
       "   'eps': 1e-05,\n",
       "   'momentum': 0.1,\n",
       "   'affine': True,\n",
       "   'track_running_stats': True}},\n",
       " 'layer4_1': {'conv1': {'in_channels': 512,\n",
       "   'out_channels': 512,\n",
       "   'kernel_size': (3, 3),\n",
       "   'stride': (1, 1),\n",
       "   'padding': (1, 1),\n",
       "   'bias': False},\n",
       "  'bn1': {'num_features': 512,\n",
       "   'eps': 1e-05,\n",
       "   'momentum': 0.1,\n",
       "   'affine': True,\n",
       "   'track_running_stats': True},\n",
       "  'relu': {'inplace': True},\n",
       "  'conv2': {'in_channels': 512,\n",
       "   'out_channels': 512,\n",
       "   'kernel_size': (3, 3),\n",
       "   'stride': (1, 1),\n",
       "   'padding': (1, 1),\n",
       "   'bias': False},\n",
       "  'bn2': {'num_features': 512,\n",
       "   'eps': 1e-05,\n",
       "   'momentum': 0.1,\n",
       "   'affine': True,\n",
       "   'track_running_stats': True}},\n",
       " 'avgpool': {'output_size': (1, 1)},\n",
       " 'fc': {'in_features': 512, 'out_features': 1000, 'bias': True}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_config.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn import Conv2d, BatchNorm2d, ReLU\n",
    "test_conv = Conv2d(**res_config['layer1_1']['conv1'])\n",
    "test_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.1143e+00, -7.3999e-02, -3.4116e-01,  ..., -1.7981e-02,\n",
       "            3.4748e-01,  8.3445e-01],\n",
       "          [ 1.3330e-01, -3.5381e-01, -8.0415e-01,  ...,  9.3973e-01,\n",
       "           -1.8316e+00,  1.6434e+00],\n",
       "          [-6.2335e-01, -9.6574e-01,  2.0085e+00,  ..., -3.4671e-01,\n",
       "           -1.0507e-03,  2.2790e+00],\n",
       "          ...,\n",
       "          [-3.2594e+00,  2.9335e-02, -7.7299e-02,  ...,  8.2409e-01,\n",
       "           -3.1011e-01,  6.5414e-03],\n",
       "          [ 1.7148e-01, -3.3105e-01,  1.3501e-02,  ...,  5.4271e-01,\n",
       "           -7.4240e-01,  5.6459e-01],\n",
       "          [-3.3239e+00, -1.8574e-01, -7.4900e-01,  ..., -5.2063e-01,\n",
       "           -3.2951e-02,  2.7768e-01]],\n",
       "\n",
       "         [[ 6.5757e-01,  5.4565e-01, -1.3190e+00,  ..., -4.0047e-01,\n",
       "           -4.0200e-01, -4.7305e-01],\n",
       "          [-8.4372e-01, -1.2236e+00, -5.9368e-02,  ..., -4.4673e-02,\n",
       "           -2.5903e-01, -5.8077e-01],\n",
       "          [-3.7647e-01, -7.8690e-01, -9.0959e-01,  ..., -8.5009e-01,\n",
       "           -3.6470e-01, -2.2254e+00],\n",
       "          ...,\n",
       "          [ 7.5008e-02, -2.6203e-01, -1.0652e+00,  ..., -1.0474e+00,\n",
       "            2.8609e+00, -1.5165e+00],\n",
       "          [-1.2487e-01,  4.6004e-01, -4.8159e-01,  ...,  6.8735e-01,\n",
       "            3.6546e-01,  1.2711e+00],\n",
       "          [-3.9495e-01,  1.8666e-02, -2.5353e-01,  ..., -1.3160e+00,\n",
       "            1.4087e+00,  1.7291e-01]],\n",
       "\n",
       "         [[-4.1753e-01,  6.2024e-01, -3.8295e-01,  ..., -4.6291e-02,\n",
       "            6.1448e-01,  6.5625e-01],\n",
       "          [-4.8413e-01, -3.4005e-01, -2.0279e-01,  ..., -4.1809e-01,\n",
       "           -1.8327e+00, -1.1847e+00],\n",
       "          [ 8.9259e-02, -6.1104e-01, -3.1153e-01,  ...,  7.9991e-01,\n",
       "           -1.3402e+00,  2.5379e-01],\n",
       "          ...,\n",
       "          [-9.6849e-01,  1.2619e+00, -9.5672e-01,  ..., -1.9326e+00,\n",
       "           -1.0298e+00,  3.9162e-01],\n",
       "          [ 1.5977e+00,  2.5921e+00,  1.7893e+00,  ...,  7.8506e-01,\n",
       "            1.6371e+00, -1.2243e+00],\n",
       "          [ 2.7025e-01, -1.2999e-01, -1.4772e-01,  ..., -1.8016e-01,\n",
       "           -1.8054e+00, -1.3615e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.4308e-01,  5.1502e-01,  2.9365e-01,  ...,  7.2233e-02,\n",
       "            1.7466e+00, -1.4735e+00],\n",
       "          [ 2.0518e-01,  1.2769e+00, -1.0819e-01,  ...,  4.5033e-01,\n",
       "            8.3158e-01,  3.1495e-02],\n",
       "          [-2.2169e-01, -4.0554e-01,  1.8895e-01,  ..., -3.3898e-01,\n",
       "            1.1267e+00,  4.3036e-01],\n",
       "          ...,\n",
       "          [ 1.0378e+00, -4.0757e-01, -3.8563e-01,  ...,  1.9768e+00,\n",
       "           -2.9650e-01, -1.6994e+00],\n",
       "          [-2.8870e-01, -1.0222e+00,  5.3033e-01,  ...,  2.5654e-01,\n",
       "            1.1754e+00,  1.1144e-01],\n",
       "          [ 2.8037e+00,  3.5795e-01,  1.7394e+00,  ..., -2.8617e-01,\n",
       "           -4.5013e-01,  2.3045e-01]],\n",
       "\n",
       "         [[ 1.1638e+00,  2.1486e+00,  1.4711e+00,  ..., -1.1968e+00,\n",
       "            2.5596e-01,  4.4513e-01],\n",
       "          [ 5.7222e-01, -8.9315e-01, -1.6595e+00,  ...,  1.5563e+00,\n",
       "            7.1052e-01, -3.2727e-01],\n",
       "          [ 2.0206e-01, -2.0398e-01,  7.2310e-01,  ...,  2.9860e-01,\n",
       "            6.7259e-01, -7.9085e-01],\n",
       "          ...,\n",
       "          [-9.1801e-01, -9.1286e-03,  1.5439e+00,  ...,  1.6399e+00,\n",
       "           -5.4396e-02, -8.5427e-01],\n",
       "          [ 2.1229e-01, -1.2798e+00, -3.6018e-01,  ..., -3.4354e-01,\n",
       "           -9.2595e-01,  1.2543e+00],\n",
       "          [ 1.4012e+00,  4.3898e-01, -1.0515e+00,  ...,  1.3169e-01,\n",
       "            8.3311e-01,  7.2157e-01]],\n",
       "\n",
       "         [[-1.2013e+00, -6.1895e-01, -7.1690e-01,  ...,  6.3552e-01,\n",
       "            2.1091e-01, -3.9050e-01],\n",
       "          [ 9.1433e-01, -1.6448e+00,  1.4104e+00,  ..., -1.1005e-01,\n",
       "           -5.4175e-01,  4.9330e-01],\n",
       "          [ 1.1889e-01, -9.0569e-01, -1.4637e+00,  ..., -1.0181e+00,\n",
       "            2.4371e-01,  1.1826e+00],\n",
       "          ...,\n",
       "          [-2.0524e+00,  7.3768e-01, -1.1370e+00,  ...,  8.6629e-03,\n",
       "           -4.1692e-01,  1.5211e-01],\n",
       "          [ 8.4614e-01, -1.3763e+00,  3.1271e-01,  ...,  2.9656e-01,\n",
       "            1.1855e+00,  9.7703e-01],\n",
       "          [ 7.4805e-03, -3.7482e-01,  9.7813e-01,  ...,  2.2133e+00,\n",
       "            1.1396e+00, -3.6961e-02]]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor = torch.randn(1, 64, 56, 56)\n",
    "input_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_tensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/alex/fogsys/PipeEdge/src/pipeedge/models/transformers/resnet_test.ipynb Cell 11\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/alex/fogsys/PipeEdge/src/pipeedge/models/transformers/resnet_test.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m layer\u001b[39m.\u001b[39meval()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/alex/fogsys/PipeEdge/src/pipeedge/models/transformers/resnet_test.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad(): \n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/alex/fogsys/PipeEdge/src/pipeedge/models/transformers/resnet_test.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     output \u001b[39m=\u001b[39m layer(input_tensor)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/alex/fogsys/PipeEdge/src/pipeedge/models/transformers/resnet_test.ipynb#X13sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(output)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'input_tensor' is not defined"
     ]
    }
   ],
   "source": [
    "layer = model.layer1\n",
    "\n",
    "layer.eval()\n",
    "\n",
    "with torch.no_grad(): \n",
    "    output = layer(input_tensor)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Models module.\"\"\"\n",
    "from typing import Any, Tuple, Type, Union\n",
    "from torch import nn, Tensor\n",
    "\n",
    "ModuleShardData: Type = Union[Tensor, Tuple[Tensor, ...]]\n",
    "\"\"\"A module shard input/output type.\"\"\"\n",
    "\n",
    "\n",
    "class ModuleShardConfig:\n",
    "    \"\"\"Base class for shard configurations (distinct from model configurations).\"\"\"\n",
    "    # pylint: disable=too-few-public-methods\n",
    "\n",
    "    def __init__(self, **kwargs: dict):\n",
    "        # Attributes with default values\n",
    "        self.layer_start: int = kwargs.pop('layer_start', 0)\n",
    "        self.layer_end: int = kwargs.pop('layer_end', 0)\n",
    "        self.is_first: bool = kwargs.pop('is_first', False)\n",
    "        self.is_last: bool = kwargs.pop('is_last', False)\n",
    "\n",
    "        # Attributes without default values\n",
    "        for key, value in kwargs.items():\n",
    "            setattr(self, key, value)\n",
    "\n",
    "\n",
    "class ModuleShard(nn.Module):\n",
    "    \"\"\"Abstract parent class for module shards.\"\"\"\n",
    "    # pylint: disable=abstract-method\n",
    "\n",
    "    def __init__(self, config: Any, shard_config: ModuleShardConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.shard_config = shard_config\n",
    "\n",
    "    def has_layer(self, layer: int) -> bool:\n",
    "        \"\"\"Check if shard has the specified layer.\"\"\"\n",
    "        return layer in range(self.shard_config.layer_start, self.shard_config.layer_end + 1)\n",
    "\n",
    "\n",
    "def get_microbatch_size(shard_data: ModuleShardData, verify: bool=False):\n",
    "    \"\"\"Get the microbatch size from shard data.\"\"\"\n",
    "    if isinstance(shard_data, Tensor):\n",
    "        shard_data = (shard_data,)\n",
    "    ubatch_size = 0 if len(shard_data) == 0 else len(shard_data[0])\n",
    "    if verify:\n",
    "        # Sanity check that tensors are the same length\n",
    "        for tensor in shard_data:\n",
    "            assert isinstance(tensor, Tensor)\n",
    "            assert len(tensor) == ubatch_size\n",
    "    return ubatch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.ResnetConfig at 0x7f9c74f23dd0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_config.conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BasicBlock(\n",
       "  (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (downsample): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Layer 1 Test\n",
    "layer2_0_0_shard_config = ModuleShardConfig(layer_start=0, layer_end=0)\n",
    "layer2_0_1_shard_config = ModuleShardConfig(layer_start=1, layer_end=2, is_last = True)\n",
    "layer2_0_config = res_config.layer2_0\n",
    "layer2_0 = model.layer2[0]\n",
    "layer2_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer2_0.downsample[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): BasicBlock(\n",
       "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (downsample): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (1): BasicBlock(\n",
       "    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Conv2d, BatchNorm2d, ReLU, MaxPool2d\n",
    "\n",
    "class ResNetLayerShard(ModuleShard):\n",
    "    def __init__(self, config, shard_config: ModuleShardConfig):\n",
    "        super().__init__(config, shard_config)\n",
    "        self.conv1 = None\n",
    "        self.bn1 = None\n",
    "        self.relu = None\n",
    "        self.conv2 = None\n",
    "        self.bn2 = None\n",
    "        self.downsample_conv = None\n",
    "        self.downsample_bn = None\n",
    "\n",
    "        self._build_shard()\n",
    "\n",
    "    def _build_shard(self):\n",
    "        if self.has_layer(0):\n",
    "            self.conv1 = Conv2d(**self.config[\"conv1\"])\n",
    "            self.bn1 = BatchNorm2d(**self.config[\"bn1\"])\n",
    "            self.relu = ReLU(**self.config['relu'])\n",
    "        if self.has_layer(1):\n",
    "            self.conv2 = Conv2d(**self.config[\"conv2\"])\n",
    "            self.bn2 = BatchNorm2d(**self.config[\"bn2\"])\n",
    "        if self.has_layer(2):\n",
    "            self.downsample_conv = Conv2d(**self.config[\"downsample_conv\"])\n",
    "            self.downsample_bn = BatchNorm2d(**self.config[\"downsample_bn\"])\n",
    "        if self.shard_config.is_last:\n",
    "            self.relu = ReLU(inplace=True)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def forward(self, data_pack):\n",
    "        \"\"\"Compute layer shard.\"\"\"\n",
    "        identity = data_pack[0]\n",
    "        data = data_pack[1]\n",
    "        if self.has_layer(0):\n",
    "            data_conv = self.conv1(data)\n",
    "            data_bn = self.bn1(data_conv)\n",
    "            data = self.relu(data_bn)\n",
    "        if self.has_layer(1):\n",
    "            data_conv = self.conv2(data)\n",
    "            data = self.bn2(data_conv)\n",
    "        if self.has_layer(2):\n",
    "            data_conv = self.downsample_conv(identity)\n",
    "            identity = self.downsample_bn(data_conv)\n",
    "        if self.shard_config.is_last:\n",
    "            data += identity\n",
    "            data = self.relu(data)\n",
    "            return data, data\n",
    "        return [identity, data]\n",
    "    \n",
    "    # For unit test only\n",
    "    def load_weight(self, weight):\n",
    "        if self.has_layer(0):\n",
    "            self.conv1.load_state_dict(weight.conv1.state_dict())\n",
    "            self.bn1.load_state_dict(weight.bn1.state_dict())\n",
    "            self.relu.load_state_dict(weight.relu.state_dict())\n",
    "        if self.has_layer(1):\n",
    "            self.conv2.load_state_dict(weight.conv2.state_dict())\n",
    "            self.bn2.load_state_dict(weight.bn2.state_dict())\n",
    "        if self.has_layer(2):\n",
    "            self.downsample_conv.load_state_dict(weight.downsample[0].state_dict())\n",
    "            self.downsample_bn.load_state_dict(weight.downsample[1].state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer2_0_0_shard = ResNetLayerShard(layer2_0_config, layer2_0_0_shard_config)\n",
    "layer2_0_1_shard = ResNetLayerShard(layer2_0_config, layer2_0_1_shard_config)\n",
    "layer2_0_0_shard.load_weight(layer2_0)\n",
    "layer2_0_1_shard.load_weight(layer2_0)\n",
    "layer2_0_0_shard.conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNetLayerShard(\n",
       "  (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer2_0_0_shard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNetLayerShard(\n",
       "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (downsample_conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "  (downsample_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer2_0_1_shard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 8  \n",
    "sample_input = torch.randn(batch_size, 64, 32, 32)\n",
    "\n",
    "layer2_0_0_shard.conv1.eval()\n",
    "layer2_0.conv1.eval()\n",
    "\n",
    "with torch.no_grad(): \n",
    "    output_shard = layer2_0_0_shard.conv1(sample_input)\n",
    "    output_origin = layer2_0.conv1(sample_input)\n",
    "\n",
    "torch.all(output_shard.eq(output_origin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer2_0_0_shard.eval()\n",
    "layer2_0_1_shard.eval()\n",
    "layer2_0.eval()\n",
    "\n",
    "with torch.no_grad(): \n",
    "    output_shard = layer2_0_0_shard.forward([sample_input, sample_input])\n",
    "    output_shard = layer2_0_1_shard.forward(output_shard)[1]\n",
    "    output_origin = layer2_0(sample_input)\n",
    "\n",
    "torch.all(output_shard.eq(output_origin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1.4497e+00, 5.0381e-02, 1.6182e-01,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [1.6405e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           1.2451e-01, 2.3668e-01],\n",
       "          [4.6819e-01, 6.9522e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           9.1861e-02, 2.0136e+00],\n",
       "          ...,\n",
       "          [3.6825e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           1.5160e-01, 0.0000e+00],\n",
       "          [3.7026e-01, 0.0000e+00, 0.0000e+00,  ..., 9.6004e-01,\n",
       "           3.9320e-01, 0.0000e+00],\n",
       "          [4.3119e-01, 3.4049e-01, 9.0519e-02,  ..., 4.1006e-01,\n",
       "           2.9741e-01, 1.5836e+00]],\n",
       "\n",
       "         [[2.0187e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 3.9149e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 1.8350e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.0716e-01,\n",
       "           5.4462e-01, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 6.8036e-01],\n",
       "          [5.3215e-01, 7.1489e-02, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           4.6522e-02, 1.0686e+00]],\n",
       "\n",
       "         [[8.5510e-01, 2.2376e-01, 5.8542e-01,  ..., 9.3295e-01,\n",
       "           5.8217e-01, 0.0000e+00],\n",
       "          [3.4244e-01, 0.0000e+00, 4.0713e-01,  ..., 0.0000e+00,\n",
       "           1.0083e-01, 0.0000e+00],\n",
       "          [7.4409e-02, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 1.6971e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 4.1190e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [7.1163e-02, 0.0000e+00, 7.8899e-02,  ..., 0.0000e+00,\n",
       "           3.4777e-01, 0.0000e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[1.0313e+00, 1.2516e-02, 9.5080e-01,  ..., 2.0208e+00,\n",
       "           0.0000e+00, 3.4023e-01],\n",
       "          [0.0000e+00, 1.1445e+00, 8.1100e-01,  ..., 2.8381e-01,\n",
       "           0.0000e+00, 6.2301e-01],\n",
       "          [7.5391e-01, 0.0000e+00, 1.2985e+00,  ..., 9.6976e-02,\n",
       "           0.0000e+00, 9.9006e-01],\n",
       "          ...,\n",
       "          [0.0000e+00, 3.1044e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           1.2896e+00, 4.6451e-01],\n",
       "          [1.4895e-01, 2.0266e-02, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [1.0746e-02, 8.3480e-01, 7.1311e-01,  ..., 4.2968e-01,\n",
       "           1.3819e+00, 0.0000e+00]],\n",
       "\n",
       "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 7.8281e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 4.4434e-01,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 3.9569e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[1.2701e-01, 0.0000e+00, 0.0000e+00,  ..., 2.2615e-01,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 7.4392e-01, 5.6401e-01,  ..., 1.5800e-01,\n",
       "           0.0000e+00, 2.5627e-01],\n",
       "          [5.6561e-01, 6.6567e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           5.3036e-01, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 2.5874e-01, 1.3663e-01,  ..., 0.0000e+00,\n",
       "           1.1581e+00, 1.1805e-01],\n",
       "          [9.8650e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           4.0841e-01, 0.0000e+00],\n",
       "          [4.9521e-02, 0.0000e+00, 3.6259e-01,  ..., 0.0000e+00,\n",
       "           5.6237e-01, 6.8972e-02]]],\n",
       "\n",
       "\n",
       "        [[[0.0000e+00, 0.0000e+00, 5.6787e-01,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 1.9727e-02],\n",
       "          [1.7412e+00, 0.0000e+00, 1.2045e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 1.3242e-01],\n",
       "          [2.9793e-01, 1.2619e-01, 0.0000e+00,  ..., 5.9935e-01,\n",
       "           6.1987e-01, 0.0000e+00],\n",
       "          ...,\n",
       "          [4.7010e-01, 0.0000e+00, 3.7094e-01,  ..., 1.4231e+00,\n",
       "           4.3169e-02, 4.0984e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.3235e-01,\n",
       "           0.0000e+00, 8.6284e-01],\n",
       "          [8.6493e-01, 5.6294e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 1.1337e+00]],\n",
       "\n",
       "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 1.9993e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 1.3061e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 3.0511e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 5.1832e-02],\n",
       "          [0.0000e+00, 5.6361e-02, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 1.1172e-01]],\n",
       "\n",
       "         [[4.2517e-01, 3.1252e-01, 3.8644e-01,  ..., 0.0000e+00,\n",
       "           3.1183e-01, 3.6374e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 4.2506e-01,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 5.0552e-01],\n",
       "          [4.3538e-01, 0.0000e+00, 3.4545e-01,  ..., 9.7882e-02,\n",
       "           5.2040e-01, 0.0000e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.0000e+00, 6.0715e-01, 4.1244e-01,  ..., 9.8631e-01,\n",
       "           1.0954e+00, 4.8936e-01],\n",
       "          [6.5397e-01, 2.8174e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [7.3875e-01, 0.0000e+00, 0.0000e+00,  ..., 2.4011e-01,\n",
       "           2.3855e-01, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           3.4645e-01, 2.6629e-01],\n",
       "          [7.5022e-02, 1.8551e-01, 0.0000e+00,  ..., 2.2632e+00,\n",
       "           4.5138e-01, 0.0000e+00],\n",
       "          [1.0259e-01, 3.4764e-01, 7.9360e-01,  ..., 8.7986e-01,\n",
       "           1.0771e+00, 4.1669e-01]],\n",
       "\n",
       "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0475e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [5.8084e-01, 1.4376e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           6.2533e-01, 0.0000e+00]],\n",
       "\n",
       "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           2.2475e-01, 0.0000e+00],\n",
       "          [0.0000e+00, 6.9172e-02, 6.6139e-03,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 4.0499e-01, 4.6601e-01,  ..., 3.3344e-02,\n",
       "           0.0000e+00, 4.2957e-01],\n",
       "          ...,\n",
       "          [1.4554e+00, 1.5856e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           4.2880e-01, 4.6803e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.0981e+00,\n",
       "           1.2809e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 7.1840e-01,  ..., 1.9596e+00,\n",
       "           7.1032e-01, 5.8304e-01]]],\n",
       "\n",
       "\n",
       "        [[[0.0000e+00, 0.0000e+00, 7.2198e-01,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 6.6072e-01],\n",
       "          [1.5486e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 7.5617e-01],\n",
       "          [1.3748e+00, 0.0000e+00, 3.3303e-01,  ..., 1.0570e+00,\n",
       "           0.0000e+00, 1.8290e+00],\n",
       "          ...,\n",
       "          [1.0483e-01, 4.4652e-01, 0.0000e+00,  ..., 9.5183e-04,\n",
       "           3.4990e-01, 1.0851e+00],\n",
       "          [1.1156e-02, 0.0000e+00, 1.0841e+00,  ..., 1.7769e+00,\n",
       "           1.9072e-01, 0.0000e+00],\n",
       "          [0.0000e+00, 9.7070e-01, 7.8034e-02,  ..., 2.0233e+00,\n",
       "           2.6068e-01, 6.6206e-01]],\n",
       "\n",
       "         [[1.8284e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [6.3380e-02, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [2.2689e-02, 1.0758e-01, 0.0000e+00,  ..., 1.4724e-01,\n",
       "           4.0385e-01, 3.2216e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           1.9688e-01, 1.4458e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 4.4518e-02,\n",
       "           0.0000e+00, 3.9467e-02]],\n",
       "\n",
       "         [[3.8254e-01, 4.4834e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           1.7367e-01, 5.0812e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 2.7278e-01],\n",
       "          [1.3257e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 7.9102e-02],\n",
       "          ...,\n",
       "          [1.3193e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 3.2175e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [1.9826e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 8.8804e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 8.5073e-01,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [7.4290e-01, 0.0000e+00, 0.0000e+00,  ..., 1.1615e+00,\n",
       "           4.6606e-02, 1.7556e+00],\n",
       "          [3.7635e-01, 0.0000e+00, 5.7021e-01,  ..., 3.5371e-01,\n",
       "           0.0000e+00, 4.2073e-02],\n",
       "          ...,\n",
       "          [0.0000e+00, 5.3698e-01, 0.0000e+00,  ..., 4.4839e-01,\n",
       "           0.0000e+00, 5.0490e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [6.2428e-01, 3.8010e-01, 1.6406e+00,  ..., 6.3347e-01,\n",
       "           5.7745e-01, 1.7605e+00]],\n",
       "\n",
       "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 1.3311e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.3175e-01,\n",
       "           1.4469e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[8.0193e-01, 0.0000e+00, 3.8831e-01,  ..., 6.1116e-01,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [8.9102e-01, 1.8868e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 2.6688e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 1.7625e-01],\n",
       "          ...,\n",
       "          [2.2649e-01, 0.0000e+00, 0.0000e+00,  ..., 5.5687e-01,\n",
       "           2.3616e-01, 6.9581e-01],\n",
       "          [1.1366e+00, 6.4988e-01, 0.0000e+00,  ..., 6.8609e-01,\n",
       "           0.0000e+00, 7.4151e-01],\n",
       "          [1.0551e+00, 0.0000e+00, 0.0000e+00,  ..., 7.7450e-01,\n",
       "           0.0000e+00, 0.0000e+00]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[5.3205e-02, 2.5899e-01, 1.3621e-01,  ..., 8.0531e-01,\n",
       "           6.0878e-01, 4.7119e-01],\n",
       "          [2.8018e-01, 0.0000e+00, 6.3771e-01,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 4.4964e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 1.1530e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 5.2515e-02,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [4.2230e-02, 1.3798e+00, 2.2466e-01,  ..., 0.0000e+00,\n",
       "           3.0047e-01, 5.7744e-01],\n",
       "          [1.3471e+00, 0.0000e+00, 2.0628e-01,  ..., 3.7343e-01,\n",
       "           1.2341e+00, 0.0000e+00]],\n",
       "\n",
       "         [[3.0376e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           2.4378e-01, 8.9193e-02],\n",
       "          [1.2786e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 1.6562e-01],\n",
       "          [8.9309e-02, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[5.9940e-02, 3.4950e-01, 3.7714e-01,  ..., 5.7131e-01,\n",
       "           0.0000e+00, 5.1151e-01],\n",
       "          [2.3943e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 7.5350e-01],\n",
       "          ...,\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 8.6243e-02,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 4.5383e-01],\n",
       "          [5.1117e-01, 1.7821e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           3.6977e-01, 4.9342e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[3.8745e-01, 0.0000e+00, 1.8852e-02,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.3841e-01,\n",
       "           1.1571e+00, 1.1288e+00],\n",
       "          [5.2535e-01, 5.1745e-01, 4.4309e-01,  ..., 0.0000e+00,\n",
       "           7.0823e-01, 1.5454e+00],\n",
       "          ...,\n",
       "          [4.0490e-01, 1.8562e-01, 1.5118e+00,  ..., 3.7326e-01,\n",
       "           2.6481e-02, 4.8852e-01],\n",
       "          [4.2895e-01, 0.0000e+00, 0.0000e+00,  ..., 1.6130e-01,\n",
       "           9.0154e-01, 0.0000e+00],\n",
       "          [1.0551e+00, 1.4844e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           1.2912e+00, 9.9891e-01]],\n",
       "\n",
       "         [[0.0000e+00, 7.2341e-02, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 7.2071e-01,\n",
       "           3.3047e-02, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 2.8993e-01,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 4.6925e-01, 6.1180e-01,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[0.0000e+00, 6.1518e-02, 0.0000e+00,  ..., 3.0889e-01,\n",
       "           0.0000e+00, 1.0375e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 1.7534e-01,  ..., 0.0000e+00,\n",
       "           1.7508e-01, 1.8020e+00],\n",
       "          [0.0000e+00, 3.0754e-01, 1.5684e-01,  ..., 0.0000e+00,\n",
       "           6.4168e-01, 4.0023e-01],\n",
       "          ...,\n",
       "          [5.2109e-01, 9.2982e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           3.3277e-01, 0.0000e+00],\n",
       "          [3.2515e-01, 0.0000e+00, 8.7123e-01,  ..., 0.0000e+00,\n",
       "           3.0938e-01, 0.0000e+00],\n",
       "          [2.2820e-01, 5.5155e-01, 1.9926e-01,  ..., 6.8996e-01,\n",
       "           2.8845e-01, 0.0000e+00]]],\n",
       "\n",
       "\n",
       "        [[[3.1211e-02, 1.3782e-02, 0.0000e+00,  ..., 2.0329e+00,\n",
       "           1.0322e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 4.2012e-01,  ..., 0.0000e+00,\n",
       "           3.3367e-01, 0.0000e+00],\n",
       "          [2.9321e-01, 0.0000e+00, 1.1375e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 6.1771e-01, 1.4759e+00,  ..., 4.3920e-01,\n",
       "           9.7645e-01, 3.9554e-01],\n",
       "          [8.4101e-01, 0.0000e+00, 1.0500e+00,  ..., 3.9504e-01,\n",
       "           8.4379e-01, 0.0000e+00],\n",
       "          [8.2691e-01, 7.2192e-01, 1.0407e-01,  ..., 0.0000e+00,\n",
       "           3.3972e-01, 0.0000e+00]],\n",
       "\n",
       "         [[3.3712e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [4.5183e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [5.0902e-04, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [7.8593e-02, 0.0000e+00, 0.0000e+00,  ..., 2.1290e-02,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 1.2403e-01,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[6.0721e-01, 0.0000e+00, 0.0000e+00,  ..., 1.5513e-01,\n",
       "           2.3299e-02, 0.0000e+00],\n",
       "          [6.4320e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 5.2690e-01, 0.0000e+00,  ..., 2.0384e-01,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [9.8058e-02, 2.0882e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 2.7015e-01],\n",
       "          [3.8760e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [4.3157e-01, 0.0000e+00, 0.0000e+00,  ..., 5.8720e-01,\n",
       "           1.7926e-02, 5.0432e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[1.1425e-01, 0.0000e+00, 1.2159e-01,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 4.4362e-01],\n",
       "          [6.1408e-01, 0.0000e+00, 0.0000e+00,  ..., 5.8949e-01,\n",
       "           2.0036e-01, 7.2678e-01],\n",
       "          [1.1815e-01, 1.4275e-02, 0.0000e+00,  ..., 5.7301e-01,\n",
       "           1.3914e-01, 0.0000e+00],\n",
       "          ...,\n",
       "          [3.2283e-01, 1.3748e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 6.9420e-01],\n",
       "          [0.0000e+00, 5.5484e-01, 4.2654e-01,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 1.8060e-01],\n",
       "          [6.7374e-01, 7.4219e-01, 5.6655e-01,  ..., 5.3117e-01,\n",
       "           1.3099e+00, 1.4832e+00]],\n",
       "\n",
       "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 8.0818e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 5.0937e-02,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 6.5995e-02],\n",
       "          ...,\n",
       "          [1.2918e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 2.2392e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 4.7931e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[0.0000e+00, 4.2782e-02, 0.0000e+00,  ..., 5.0478e-01,\n",
       "           2.0801e-01, 4.7939e-01],\n",
       "          [7.5884e-01, 4.2259e-01, 1.3959e-01,  ..., 0.0000e+00,\n",
       "           4.5021e-01, 2.0188e-01],\n",
       "          [4.7644e-02, 0.0000e+00, 5.9271e-02,  ..., 6.0916e-01,\n",
       "           2.6002e-01, 0.0000e+00],\n",
       "          ...,\n",
       "          [9.4739e-02, 0.0000e+00, 0.0000e+00,  ..., 8.5846e-05,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [4.9982e-01, 0.0000e+00, 4.1659e-01,  ..., 1.8389e+00,\n",
       "           6.3754e-02, 0.0000e+00],\n",
       "          [3.1855e-01, 0.0000e+00, 5.5546e-01,  ..., 1.8926e+00,\n",
       "           1.6551e+00, 1.0950e+00]]],\n",
       "\n",
       "\n",
       "        [[[0.0000e+00, 6.3318e-01, 0.0000e+00,  ..., 7.4333e-01,\n",
       "           6.9670e-01, 6.9274e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 8.3924e-01,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [1.5931e+00, 9.0669e-01, 0.0000e+00,  ..., 1.1261e+00,\n",
       "           1.6526e-02, 0.0000e+00],\n",
       "          ...,\n",
       "          [1.2703e+00, 3.8788e-01, 0.0000e+00,  ..., 1.6973e+00,\n",
       "           6.0153e-01, 1.5480e+00],\n",
       "          [0.0000e+00, 5.6627e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.2542e+00,\n",
       "           0.0000e+00, 1.0429e-01]],\n",
       "\n",
       "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 5.6713e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           1.5341e-01, 3.3114e-01],\n",
       "          [3.0376e-01, 2.7635e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           1.1808e-02, 2.1135e-01],\n",
       "          ...,\n",
       "          [3.0732e-01, 0.0000e+00, 0.0000e+00,  ..., 1.4784e-01,\n",
       "           0.0000e+00, 1.8373e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 2.0114e-01, 1.3207e-01,  ..., 1.7457e-01,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[6.0850e-01, 8.7436e-01, 3.8647e-01,  ..., 1.3629e-01,\n",
       "           6.4122e-01, 5.5592e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 7.0349e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 9.1446e-01],\n",
       "          ...,\n",
       "          [0.0000e+00, 4.8093e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [3.2942e-03, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 4.8681e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           2.3278e-01, 9.2251e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[1.8358e-01, 2.2085e+00, 8.1256e-01,  ..., 4.1350e-01,\n",
       "           0.0000e+00, 1.2615e+00],\n",
       "          [4.6981e-01, 2.1320e-01, 0.0000e+00,  ..., 3.2226e-01,\n",
       "           0.0000e+00, 2.6301e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 1.9606e-01,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 3.5152e-01],\n",
       "          ...,\n",
       "          [6.5388e-01, 5.6220e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 4.6337e-01],\n",
       "          [3.0945e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 1.1775e+00],\n",
       "          [0.0000e+00, 1.0922e+00, 3.8297e-01,  ..., 2.2850e-01,\n",
       "           6.6357e-01, 1.9683e+00]],\n",
       "\n",
       "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 0.0000e+00, 3.8297e-01,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [1.1701e+00, 0.0000e+00, 4.8089e-01,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [2.1602e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[0.0000e+00, 2.3388e-01, 2.4697e-01,  ..., 8.1361e-01,\n",
       "           4.5365e-01, 2.3336e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 3.8737e-01],\n",
       "          [0.0000e+00, 5.3837e-01, 2.9176e-01,  ..., 6.5765e-01,\n",
       "           9.7962e-01, 4.9419e-02],\n",
       "          ...,\n",
       "          [2.4307e-01, 2.1016e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           4.9451e-01, 0.0000e+00],\n",
       "          [2.7198e-01, 3.7489e-01, 0.0000e+00,  ..., 3.7317e-01,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [3.1389e-01, 5.0526e-01, 8.3757e-02,  ..., 4.0303e-01,\n",
       "           1.0703e-01, 4.5476e-01]]]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1.4497e+00, 5.0381e-02, 1.6182e-01,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [1.6405e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           1.2451e-01, 2.3668e-01],\n",
       "          [4.6819e-01, 6.9522e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           9.1861e-02, 2.0136e+00],\n",
       "          ...,\n",
       "          [3.6825e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           1.5160e-01, 0.0000e+00],\n",
       "          [3.7026e-01, 0.0000e+00, 0.0000e+00,  ..., 9.6004e-01,\n",
       "           3.9320e-01, 0.0000e+00],\n",
       "          [4.3119e-01, 3.4049e-01, 9.0519e-02,  ..., 4.1006e-01,\n",
       "           2.9741e-01, 1.5836e+00]],\n",
       "\n",
       "         [[2.0187e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 3.9149e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 1.8350e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.0716e-01,\n",
       "           5.4462e-01, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 6.8036e-01],\n",
       "          [5.3215e-01, 7.1489e-02, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           4.6522e-02, 1.0686e+00]],\n",
       "\n",
       "         [[8.5510e-01, 2.2376e-01, 5.8542e-01,  ..., 9.3295e-01,\n",
       "           5.8217e-01, 0.0000e+00],\n",
       "          [3.4244e-01, 0.0000e+00, 4.0713e-01,  ..., 0.0000e+00,\n",
       "           1.0083e-01, 0.0000e+00],\n",
       "          [7.4409e-02, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 1.6971e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 4.1190e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [7.1163e-02, 0.0000e+00, 7.8899e-02,  ..., 0.0000e+00,\n",
       "           3.4777e-01, 0.0000e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[1.0313e+00, 1.2516e-02, 9.5080e-01,  ..., 2.0208e+00,\n",
       "           0.0000e+00, 3.4023e-01],\n",
       "          [0.0000e+00, 1.1445e+00, 8.1100e-01,  ..., 2.8381e-01,\n",
       "           0.0000e+00, 6.2301e-01],\n",
       "          [7.5391e-01, 0.0000e+00, 1.2985e+00,  ..., 9.6976e-02,\n",
       "           0.0000e+00, 9.9006e-01],\n",
       "          ...,\n",
       "          [0.0000e+00, 3.1044e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           1.2896e+00, 4.6451e-01],\n",
       "          [1.4895e-01, 2.0266e-02, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [1.0746e-02, 8.3480e-01, 7.1311e-01,  ..., 4.2968e-01,\n",
       "           1.3819e+00, 0.0000e+00]],\n",
       "\n",
       "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 7.8281e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 4.4434e-01,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 3.9569e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[1.2701e-01, 0.0000e+00, 0.0000e+00,  ..., 2.2615e-01,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 7.4392e-01, 5.6401e-01,  ..., 1.5800e-01,\n",
       "           0.0000e+00, 2.5627e-01],\n",
       "          [5.6561e-01, 6.6567e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           5.3036e-01, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 2.5874e-01, 1.3663e-01,  ..., 0.0000e+00,\n",
       "           1.1581e+00, 1.1805e-01],\n",
       "          [9.8650e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           4.0841e-01, 0.0000e+00],\n",
       "          [4.9521e-02, 0.0000e+00, 3.6259e-01,  ..., 0.0000e+00,\n",
       "           5.6237e-01, 6.8972e-02]]],\n",
       "\n",
       "\n",
       "        [[[0.0000e+00, 0.0000e+00, 5.6787e-01,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 1.9727e-02],\n",
       "          [1.7412e+00, 0.0000e+00, 1.2045e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 1.3242e-01],\n",
       "          [2.9793e-01, 1.2619e-01, 0.0000e+00,  ..., 5.9935e-01,\n",
       "           6.1987e-01, 0.0000e+00],\n",
       "          ...,\n",
       "          [4.7010e-01, 0.0000e+00, 3.7094e-01,  ..., 1.4231e+00,\n",
       "           4.3169e-02, 4.0984e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.3235e-01,\n",
       "           0.0000e+00, 8.6284e-01],\n",
       "          [8.6493e-01, 5.6294e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 1.1337e+00]],\n",
       "\n",
       "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 1.9993e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 1.3061e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 3.0511e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 5.1832e-02],\n",
       "          [0.0000e+00, 5.6361e-02, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 1.1172e-01]],\n",
       "\n",
       "         [[4.2517e-01, 3.1252e-01, 3.8644e-01,  ..., 0.0000e+00,\n",
       "           3.1183e-01, 3.6374e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 4.2506e-01,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 5.0552e-01],\n",
       "          [4.3538e-01, 0.0000e+00, 3.4545e-01,  ..., 9.7882e-02,\n",
       "           5.2040e-01, 0.0000e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.0000e+00, 6.0715e-01, 4.1244e-01,  ..., 9.8631e-01,\n",
       "           1.0954e+00, 4.8936e-01],\n",
       "          [6.5397e-01, 2.8174e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [7.3875e-01, 0.0000e+00, 0.0000e+00,  ..., 2.4011e-01,\n",
       "           2.3855e-01, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           3.4645e-01, 2.6629e-01],\n",
       "          [7.5022e-02, 1.8551e-01, 0.0000e+00,  ..., 2.2632e+00,\n",
       "           4.5138e-01, 0.0000e+00],\n",
       "          [1.0259e-01, 3.4764e-01, 7.9360e-01,  ..., 8.7986e-01,\n",
       "           1.0771e+00, 4.1669e-01]],\n",
       "\n",
       "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0475e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [5.8084e-01, 1.4376e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           6.2533e-01, 0.0000e+00]],\n",
       "\n",
       "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           2.2475e-01, 0.0000e+00],\n",
       "          [0.0000e+00, 6.9172e-02, 6.6139e-03,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 4.0499e-01, 4.6601e-01,  ..., 3.3344e-02,\n",
       "           0.0000e+00, 4.2957e-01],\n",
       "          ...,\n",
       "          [1.4554e+00, 1.5856e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           4.2880e-01, 4.6803e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.0981e+00,\n",
       "           1.2809e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 7.1840e-01,  ..., 1.9596e+00,\n",
       "           7.1032e-01, 5.8304e-01]]],\n",
       "\n",
       "\n",
       "        [[[0.0000e+00, 0.0000e+00, 7.2198e-01,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 6.6072e-01],\n",
       "          [1.5486e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 7.5617e-01],\n",
       "          [1.3748e+00, 0.0000e+00, 3.3303e-01,  ..., 1.0570e+00,\n",
       "           0.0000e+00, 1.8290e+00],\n",
       "          ...,\n",
       "          [1.0483e-01, 4.4652e-01, 0.0000e+00,  ..., 9.5183e-04,\n",
       "           3.4990e-01, 1.0851e+00],\n",
       "          [1.1156e-02, 0.0000e+00, 1.0841e+00,  ..., 1.7769e+00,\n",
       "           1.9072e-01, 0.0000e+00],\n",
       "          [0.0000e+00, 9.7070e-01, 7.8034e-02,  ..., 2.0233e+00,\n",
       "           2.6068e-01, 6.6206e-01]],\n",
       "\n",
       "         [[1.8284e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [6.3380e-02, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [2.2689e-02, 1.0758e-01, 0.0000e+00,  ..., 1.4724e-01,\n",
       "           4.0385e-01, 3.2216e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           1.9688e-01, 1.4458e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 4.4518e-02,\n",
       "           0.0000e+00, 3.9467e-02]],\n",
       "\n",
       "         [[3.8254e-01, 4.4834e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           1.7367e-01, 5.0812e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 2.7278e-01],\n",
       "          [1.3257e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 7.9102e-02],\n",
       "          ...,\n",
       "          [1.3193e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 3.2175e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [1.9826e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 8.8804e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 8.5073e-01,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [7.4290e-01, 0.0000e+00, 0.0000e+00,  ..., 1.1615e+00,\n",
       "           4.6606e-02, 1.7556e+00],\n",
       "          [3.7635e-01, 0.0000e+00, 5.7021e-01,  ..., 3.5371e-01,\n",
       "           0.0000e+00, 4.2073e-02],\n",
       "          ...,\n",
       "          [0.0000e+00, 5.3698e-01, 0.0000e+00,  ..., 4.4839e-01,\n",
       "           0.0000e+00, 5.0490e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [6.2428e-01, 3.8010e-01, 1.6406e+00,  ..., 6.3347e-01,\n",
       "           5.7745e-01, 1.7605e+00]],\n",
       "\n",
       "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 1.3311e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.3175e-01,\n",
       "           1.4469e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[8.0193e-01, 0.0000e+00, 3.8831e-01,  ..., 6.1116e-01,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [8.9102e-01, 1.8868e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 2.6688e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 1.7625e-01],\n",
       "          ...,\n",
       "          [2.2649e-01, 0.0000e+00, 0.0000e+00,  ..., 5.5687e-01,\n",
       "           2.3616e-01, 6.9581e-01],\n",
       "          [1.1366e+00, 6.4988e-01, 0.0000e+00,  ..., 6.8609e-01,\n",
       "           0.0000e+00, 7.4151e-01],\n",
       "          [1.0551e+00, 0.0000e+00, 0.0000e+00,  ..., 7.7450e-01,\n",
       "           0.0000e+00, 0.0000e+00]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[5.3205e-02, 2.5899e-01, 1.3621e-01,  ..., 8.0531e-01,\n",
       "           6.0878e-01, 4.7119e-01],\n",
       "          [2.8018e-01, 0.0000e+00, 6.3771e-01,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 4.4964e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 1.1530e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 5.2515e-02,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [4.2230e-02, 1.3798e+00, 2.2466e-01,  ..., 0.0000e+00,\n",
       "           3.0047e-01, 5.7744e-01],\n",
       "          [1.3471e+00, 0.0000e+00, 2.0628e-01,  ..., 3.7343e-01,\n",
       "           1.2341e+00, 0.0000e+00]],\n",
       "\n",
       "         [[3.0376e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           2.4378e-01, 8.9193e-02],\n",
       "          [1.2786e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 1.6562e-01],\n",
       "          [8.9309e-02, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[5.9940e-02, 3.4950e-01, 3.7714e-01,  ..., 5.7131e-01,\n",
       "           0.0000e+00, 5.1151e-01],\n",
       "          [2.3943e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 7.5350e-01],\n",
       "          ...,\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 8.6243e-02,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 4.5383e-01],\n",
       "          [5.1117e-01, 1.7821e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           3.6977e-01, 4.9342e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[3.8745e-01, 0.0000e+00, 1.8852e-02,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.3841e-01,\n",
       "           1.1571e+00, 1.1288e+00],\n",
       "          [5.2535e-01, 5.1745e-01, 4.4309e-01,  ..., 0.0000e+00,\n",
       "           7.0823e-01, 1.5454e+00],\n",
       "          ...,\n",
       "          [4.0490e-01, 1.8562e-01, 1.5118e+00,  ..., 3.7326e-01,\n",
       "           2.6481e-02, 4.8852e-01],\n",
       "          [4.2895e-01, 0.0000e+00, 0.0000e+00,  ..., 1.6130e-01,\n",
       "           9.0154e-01, 0.0000e+00],\n",
       "          [1.0551e+00, 1.4844e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           1.2912e+00, 9.9891e-01]],\n",
       "\n",
       "         [[0.0000e+00, 7.2341e-02, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 7.2071e-01,\n",
       "           3.3047e-02, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 2.8993e-01,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 4.6925e-01, 6.1180e-01,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[0.0000e+00, 6.1518e-02, 0.0000e+00,  ..., 3.0889e-01,\n",
       "           0.0000e+00, 1.0375e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 1.7534e-01,  ..., 0.0000e+00,\n",
       "           1.7508e-01, 1.8020e+00],\n",
       "          [0.0000e+00, 3.0754e-01, 1.5684e-01,  ..., 0.0000e+00,\n",
       "           6.4168e-01, 4.0023e-01],\n",
       "          ...,\n",
       "          [5.2109e-01, 9.2982e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           3.3277e-01, 0.0000e+00],\n",
       "          [3.2515e-01, 0.0000e+00, 8.7123e-01,  ..., 0.0000e+00,\n",
       "           3.0938e-01, 0.0000e+00],\n",
       "          [2.2820e-01, 5.5155e-01, 1.9926e-01,  ..., 6.8996e-01,\n",
       "           2.8845e-01, 0.0000e+00]]],\n",
       "\n",
       "\n",
       "        [[[3.1211e-02, 1.3782e-02, 0.0000e+00,  ..., 2.0329e+00,\n",
       "           1.0322e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 4.2012e-01,  ..., 0.0000e+00,\n",
       "           3.3367e-01, 0.0000e+00],\n",
       "          [2.9321e-01, 0.0000e+00, 1.1375e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 6.1771e-01, 1.4759e+00,  ..., 4.3920e-01,\n",
       "           9.7645e-01, 3.9554e-01],\n",
       "          [8.4101e-01, 0.0000e+00, 1.0500e+00,  ..., 3.9504e-01,\n",
       "           8.4379e-01, 0.0000e+00],\n",
       "          [8.2691e-01, 7.2192e-01, 1.0407e-01,  ..., 0.0000e+00,\n",
       "           3.3972e-01, 0.0000e+00]],\n",
       "\n",
       "         [[3.3712e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [4.5183e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [5.0902e-04, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [7.8593e-02, 0.0000e+00, 0.0000e+00,  ..., 2.1290e-02,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 1.2403e-01,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[6.0721e-01, 0.0000e+00, 0.0000e+00,  ..., 1.5513e-01,\n",
       "           2.3299e-02, 0.0000e+00],\n",
       "          [6.4320e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 5.2690e-01, 0.0000e+00,  ..., 2.0384e-01,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [9.8058e-02, 2.0882e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 2.7015e-01],\n",
       "          [3.8760e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [4.3157e-01, 0.0000e+00, 0.0000e+00,  ..., 5.8720e-01,\n",
       "           1.7926e-02, 5.0432e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[1.1425e-01, 0.0000e+00, 1.2159e-01,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 4.4362e-01],\n",
       "          [6.1408e-01, 0.0000e+00, 0.0000e+00,  ..., 5.8949e-01,\n",
       "           2.0036e-01, 7.2678e-01],\n",
       "          [1.1815e-01, 1.4275e-02, 0.0000e+00,  ..., 5.7301e-01,\n",
       "           1.3914e-01, 0.0000e+00],\n",
       "          ...,\n",
       "          [3.2283e-01, 1.3748e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 6.9420e-01],\n",
       "          [0.0000e+00, 5.5484e-01, 4.2654e-01,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 1.8060e-01],\n",
       "          [6.7374e-01, 7.4219e-01, 5.6655e-01,  ..., 5.3117e-01,\n",
       "           1.3099e+00, 1.4832e+00]],\n",
       "\n",
       "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 8.0818e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 5.0937e-02,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 6.5995e-02],\n",
       "          ...,\n",
       "          [1.2918e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 2.2392e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 4.7931e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[0.0000e+00, 4.2782e-02, 0.0000e+00,  ..., 5.0478e-01,\n",
       "           2.0801e-01, 4.7939e-01],\n",
       "          [7.5884e-01, 4.2259e-01, 1.3959e-01,  ..., 0.0000e+00,\n",
       "           4.5021e-01, 2.0188e-01],\n",
       "          [4.7644e-02, 0.0000e+00, 5.9271e-02,  ..., 6.0916e-01,\n",
       "           2.6002e-01, 0.0000e+00],\n",
       "          ...,\n",
       "          [9.4739e-02, 0.0000e+00, 0.0000e+00,  ..., 8.5846e-05,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [4.9982e-01, 0.0000e+00, 4.1659e-01,  ..., 1.8389e+00,\n",
       "           6.3754e-02, 0.0000e+00],\n",
       "          [3.1855e-01, 0.0000e+00, 5.5546e-01,  ..., 1.8926e+00,\n",
       "           1.6551e+00, 1.0950e+00]]],\n",
       "\n",
       "\n",
       "        [[[0.0000e+00, 6.3318e-01, 0.0000e+00,  ..., 7.4333e-01,\n",
       "           6.9670e-01, 6.9274e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 8.3924e-01,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [1.5931e+00, 9.0669e-01, 0.0000e+00,  ..., 1.1261e+00,\n",
       "           1.6526e-02, 0.0000e+00],\n",
       "          ...,\n",
       "          [1.2703e+00, 3.8788e-01, 0.0000e+00,  ..., 1.6973e+00,\n",
       "           6.0153e-01, 1.5480e+00],\n",
       "          [0.0000e+00, 5.6627e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.2542e+00,\n",
       "           0.0000e+00, 1.0429e-01]],\n",
       "\n",
       "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 5.6713e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           1.5341e-01, 3.3114e-01],\n",
       "          [3.0376e-01, 2.7635e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           1.1808e-02, 2.1135e-01],\n",
       "          ...,\n",
       "          [3.0732e-01, 0.0000e+00, 0.0000e+00,  ..., 1.4784e-01,\n",
       "           0.0000e+00, 1.8373e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 2.0114e-01, 1.3207e-01,  ..., 1.7457e-01,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[6.0850e-01, 8.7436e-01, 3.8647e-01,  ..., 1.3629e-01,\n",
       "           6.4122e-01, 5.5592e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 7.0349e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 9.1446e-01],\n",
       "          ...,\n",
       "          [0.0000e+00, 4.8093e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [3.2942e-03, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 4.8681e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           2.3278e-01, 9.2251e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[1.8358e-01, 2.2085e+00, 8.1256e-01,  ..., 4.1350e-01,\n",
       "           0.0000e+00, 1.2615e+00],\n",
       "          [4.6981e-01, 2.1320e-01, 0.0000e+00,  ..., 3.2226e-01,\n",
       "           0.0000e+00, 2.6301e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 1.9606e-01,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 3.5152e-01],\n",
       "          ...,\n",
       "          [6.5388e-01, 5.6220e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 4.6337e-01],\n",
       "          [3.0945e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 1.1775e+00],\n",
       "          [0.0000e+00, 1.0922e+00, 3.8297e-01,  ..., 2.2850e-01,\n",
       "           6.6357e-01, 1.9683e+00]],\n",
       "\n",
       "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 0.0000e+00, 3.8297e-01,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [1.1701e+00, 0.0000e+00, 4.8089e-01,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [2.1602e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[0.0000e+00, 2.3388e-01, 2.4697e-01,  ..., 8.1361e-01,\n",
       "           4.5365e-01, 2.3336e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 3.8737e-01],\n",
       "          [0.0000e+00, 5.3837e-01, 2.9176e-01,  ..., 6.5765e-01,\n",
       "           9.7962e-01, 4.9419e-02],\n",
       "          ...,\n",
       "          [2.4307e-01, 2.1016e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           4.9451e-01, 0.0000e+00],\n",
       "          [2.7198e-01, 3.7489e-01, 0.0000e+00,  ..., 3.7317e-01,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [3.1389e-01, 5.0526e-01, 8.3757e-02,  ..., 4.0303e-01,\n",
       "           1.0703e-01, 4.5476e-01]]]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_shard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 3.1518e-01,  4.7914e-01,  5.0946e-01,  ..., -2.4901e-01,\n",
       "            8.7414e-02,  7.3423e-01],\n",
       "          [ 7.6082e-01,  2.8780e-01, -1.4719e+00,  ...,  2.1155e-01,\n",
       "            1.2971e+00, -8.3264e-01],\n",
       "          [ 1.0617e-01,  2.6949e-01, -1.5501e-01,  ..., -1.4771e+00,\n",
       "            1.2163e-01,  5.0294e-01],\n",
       "          ...,\n",
       "          [-2.1101e-01,  9.2011e-01,  5.0889e-01,  ..., -1.7701e-02,\n",
       "           -3.5228e-01,  9.7531e-01],\n",
       "          [ 6.6314e-01,  4.6864e-01, -1.4375e-01,  ..., -1.5772e-01,\n",
       "            3.7204e-03, -2.7240e+00],\n",
       "          [-4.1135e-01, -2.7487e+00,  1.6552e-01,  ...,  1.9765e+00,\n",
       "           -6.0270e-02,  1.8295e+00]],\n",
       "\n",
       "         [[-1.0827e+00, -1.2007e+00, -3.5386e-01,  ...,  1.9629e+00,\n",
       "            8.0177e-01, -4.9080e-01],\n",
       "          [-6.1454e-01, -1.7132e+00, -1.8442e+00,  ..., -1.6827e+00,\n",
       "            1.6361e-01, -1.6788e+00],\n",
       "          [ 1.1552e+00, -8.7860e-01, -1.1324e+00,  ...,  1.7000e-02,\n",
       "           -4.4550e-01, -1.8406e-01],\n",
       "          ...,\n",
       "          [ 2.0472e+00,  1.8414e+00, -6.0672e-01,  ...,  7.4021e-01,\n",
       "            2.9703e-01,  1.8543e+00],\n",
       "          [ 1.3166e-01, -1.2411e+00, -1.8447e+00,  ..., -1.5488e+00,\n",
       "           -1.6288e+00,  1.0457e-01],\n",
       "          [ 5.6281e-01, -3.0390e-01, -9.5311e-02,  ...,  8.6417e-01,\n",
       "            1.7401e-01, -3.7487e-01]],\n",
       "\n",
       "         [[-6.5354e-02,  1.9090e+00, -1.1956e+00,  ..., -7.9963e-01,\n",
       "           -1.8799e+00, -1.4735e+00],\n",
       "          [ 2.9133e-01,  2.4019e-01,  1.7700e+00,  ...,  1.0855e+00,\n",
       "            5.0045e-02, -1.5999e+00],\n",
       "          [ 1.1731e+00,  2.6659e+00,  2.9368e-01,  ...,  2.0229e+00,\n",
       "           -2.8763e-02, -2.0749e-01],\n",
       "          ...,\n",
       "          [-6.5829e-01,  6.7159e-01, -1.2524e-01,  ...,  3.4362e-01,\n",
       "            2.3519e-01,  9.9038e-01],\n",
       "          [ 5.6988e-02,  2.1922e+00,  1.1212e+00,  ..., -5.1118e-01,\n",
       "           -7.0256e-01, -2.9397e-01],\n",
       "          [-7.3676e-01,  6.1258e-01,  4.5448e-02,  ..., -8.9821e-01,\n",
       "            4.9771e-01, -1.0843e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 4.2346e-01,  1.3245e-01, -5.3325e-01,  ...,  7.9815e-01,\n",
       "           -1.5254e-01,  2.8500e-02],\n",
       "          [-1.7888e-01, -1.0170e+00, -4.8754e-01,  ...,  1.9287e-01,\n",
       "           -1.6365e+00,  5.6189e-01],\n",
       "          [-4.2796e-01, -3.4337e+00, -1.0363e+00,  ..., -2.2107e-01,\n",
       "           -1.2260e+00, -1.5068e-01],\n",
       "          ...,\n",
       "          [-8.2165e-01,  1.1340e-01, -2.4093e+00,  ...,  3.4772e-01,\n",
       "           -2.5860e-01,  1.6612e+00],\n",
       "          [-6.6642e-01,  6.5244e-01, -1.5977e-01,  ...,  9.1639e-02,\n",
       "           -3.3595e-01, -1.2087e+00],\n",
       "          [ 1.2590e+00,  1.3558e-02,  3.2210e-01,  ..., -1.1142e+00,\n",
       "            2.3929e+00, -8.5482e-01]],\n",
       "\n",
       "         [[ 8.5538e-01,  3.0808e-01, -1.2418e+00,  ...,  7.9214e-01,\n",
       "            7.4775e-01, -1.3950e+00],\n",
       "          [ 3.4163e-01, -9.2197e-02,  6.0294e-01,  ..., -7.8234e-01,\n",
       "           -3.1360e-01, -1.1710e-01],\n",
       "          [ 1.2582e-01,  1.1079e+00, -1.9556e-01,  ..., -2.9543e-01,\n",
       "           -6.1779e-01,  6.5053e-01],\n",
       "          ...,\n",
       "          [-1.2217e+00,  1.2073e+00,  5.9855e-02,  ...,  5.0194e-01,\n",
       "           -7.3451e-01, -8.5654e-01],\n",
       "          [ 1.1159e+00,  2.7819e+00,  3.4780e-01,  ...,  9.4800e-01,\n",
       "           -3.6289e-01, -1.1039e+00],\n",
       "          [-3.9736e-01, -1.1484e+00,  3.4714e-02,  ...,  1.4499e+00,\n",
       "            1.7681e+00,  2.4668e+00]],\n",
       "\n",
       "         [[-5.0139e-01, -4.5909e-01,  6.9805e-01,  ...,  1.0381e+00,\n",
       "            3.7751e-02,  6.4398e-01],\n",
       "          [ 1.9213e-01,  8.0883e-01,  7.1527e-01,  ...,  4.3142e-01,\n",
       "            3.2455e-01, -1.6340e+00],\n",
       "          [-4.0402e-01, -1.2916e+00, -2.4465e+00,  ...,  7.6790e-01,\n",
       "            3.8616e-01,  6.7822e-01],\n",
       "          ...,\n",
       "          [-3.7663e-01, -9.2258e-01,  1.3479e+00,  ..., -7.3758e-01,\n",
       "           -1.9823e-01, -1.6148e-01],\n",
       "          [ 5.4647e-02,  1.9913e+00, -5.0483e-02,  ...,  9.4067e-01,\n",
       "           -2.7987e+00,  6.3720e-01],\n",
       "          [ 7.9775e-01, -2.2342e-01, -4.8701e-02,  ...,  6.7407e-02,\n",
       "            3.9825e-01, -9.2959e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 2.9652e-01,  3.3862e-01, -1.0888e+00,  ...,  5.9543e-01,\n",
       "           -6.9736e-01, -2.4530e+00],\n",
       "          [-7.3948e-01,  9.2831e-01, -4.2298e-01,  ..., -2.6083e-01,\n",
       "            9.6964e-01, -3.7657e-01],\n",
       "          [ 8.7537e-01, -6.7362e-01,  1.2456e+00,  ...,  9.6135e-01,\n",
       "           -3.8119e-01, -9.4720e-01],\n",
       "          ...,\n",
       "          [-3.7007e-01,  1.0317e+00, -5.2314e-01,  ..., -1.0196e-01,\n",
       "           -6.6172e-01, -2.2397e+00],\n",
       "          [ 1.0537e+00, -1.2653e-01, -9.3669e-01,  ..., -1.0742e+00,\n",
       "           -2.9748e-01,  3.7886e-02],\n",
       "          [-4.6545e-02, -1.7432e-01,  1.4578e+00,  ...,  1.9613e+00,\n",
       "           -4.7156e-01,  1.1792e+00]],\n",
       "\n",
       "         [[-4.1142e-01, -4.2345e-01,  8.6824e-02,  ..., -1.9306e-01,\n",
       "           -6.3767e-01,  1.4350e+00],\n",
       "          [ 6.1520e-01, -8.5214e-01, -1.1445e+00,  ...,  2.0111e+00,\n",
       "           -4.5747e-01,  1.5596e+00],\n",
       "          [ 1.9442e+00,  1.0268e+00,  2.5865e-01,  ..., -4.5984e-01,\n",
       "           -1.5305e-01, -4.2027e-01],\n",
       "          ...,\n",
       "          [ 1.0430e+00,  5.1464e-02,  3.1190e-01,  ..., -6.5689e-01,\n",
       "            1.4350e+00, -1.5076e-01],\n",
       "          [ 8.3990e-03,  4.9253e-01, -1.9186e-01,  ...,  1.8660e-01,\n",
       "            1.4002e+00,  1.4882e+00],\n",
       "          [ 9.6952e-01,  7.7137e-01, -3.2197e-01,  ..., -4.0197e-01,\n",
       "            8.0938e-01,  3.0132e-01]],\n",
       "\n",
       "         [[-2.2453e+00,  5.2286e-01,  5.1959e-01,  ...,  7.9955e-01,\n",
       "           -4.1452e-01, -1.1680e+00],\n",
       "          [-4.3809e-01,  7.5368e-01, -6.8048e-01,  ...,  4.2625e-01,\n",
       "           -5.4726e-02,  1.3133e+00],\n",
       "          [-5.7519e-01,  1.5583e+00,  1.5243e+00,  ..., -6.0205e-01,\n",
       "           -8.7703e-02, -1.3034e+00],\n",
       "          ...,\n",
       "          [ 1.4270e+00,  1.4509e+00,  2.8764e-01,  ...,  5.2127e-02,\n",
       "            3.1212e-01,  1.2351e-01],\n",
       "          [-1.1812e-01, -2.0147e-01,  4.0884e-01,  ..., -2.8013e-01,\n",
       "            1.1361e+00,  1.1073e+00],\n",
       "          [-1.8264e-01,  1.1525e+00, -5.2185e-01,  ..., -1.4402e-01,\n",
       "           -2.0347e+00,  1.2620e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 6.3586e-01,  3.5132e-01, -8.2857e-02,  ...,  8.0746e-01,\n",
       "           -4.2580e-01,  5.7939e-01],\n",
       "          [-4.7547e-01,  1.4167e+00,  3.7193e-01,  ..., -3.1421e-01,\n",
       "            1.0059e+00,  1.4219e-01],\n",
       "          [ 9.2624e-01, -1.2458e+00, -9.1752e-01,  ..., -3.8660e-01,\n",
       "           -1.3912e+00,  1.6744e+00],\n",
       "          ...,\n",
       "          [-8.0147e-01, -3.8213e-01, -6.5808e-01,  ..., -1.7961e-01,\n",
       "           -1.0756e+00, -1.7358e-01],\n",
       "          [-9.1216e-02, -2.1042e+00, -6.7863e-02,  ..., -9.4889e-01,\n",
       "            6.5490e-01, -4.2550e-01],\n",
       "          [-7.1318e-01, -4.9279e-02, -8.0255e-01,  ..., -1.0994e+00,\n",
       "           -6.6198e-01, -2.8424e-01]],\n",
       "\n",
       "         [[ 8.7742e-01, -4.2579e-01, -1.5986e+00,  ..., -5.0106e-01,\n",
       "           -1.4675e+00,  4.4823e-01],\n",
       "          [-1.1474e-01, -2.0360e-01,  1.1737e-01,  ...,  3.9209e-01,\n",
       "            1.9562e+00,  5.2814e-01],\n",
       "          [ 2.4620e+00,  6.9091e-01,  1.2457e+00,  ...,  7.8254e-01,\n",
       "            2.1170e+00, -1.5621e+00],\n",
       "          ...,\n",
       "          [ 2.7152e-01,  1.3776e+00, -8.4680e-01,  ..., -4.0361e-01,\n",
       "           -1.2159e+00, -2.3615e+00],\n",
       "          [ 1.6344e-01,  5.9169e-02,  1.4888e+00,  ..., -1.2167e+00,\n",
       "           -1.2599e+00,  3.2306e-01],\n",
       "          [ 3.4730e-01,  4.8265e-01,  6.1397e-01,  ..., -1.0079e+00,\n",
       "           -1.8752e+00, -1.6837e+00]],\n",
       "\n",
       "         [[-7.4829e-01,  7.5834e-01,  1.8787e-02,  ..., -1.1111e+00,\n",
       "            6.0981e-03, -1.9452e+00],\n",
       "          [-1.0598e-01,  2.5893e-01, -8.2903e-01,  ...,  8.5484e-01,\n",
       "           -2.5592e+00, -6.0518e-01],\n",
       "          [ 2.1099e+00,  1.2277e-02,  1.2061e+00,  ..., -4.0740e-01,\n",
       "           -6.7336e-03,  2.8477e-01],\n",
       "          ...,\n",
       "          [ 9.3367e-01,  4.0798e-01,  2.5116e+00,  ..., -2.8253e-01,\n",
       "           -1.1305e+00,  1.7798e-01],\n",
       "          [ 2.6062e-02, -7.7008e-01, -1.5357e+00,  ...,  1.4524e+00,\n",
       "           -4.4647e-01, -3.4804e-01],\n",
       "          [ 1.6232e-01,  3.3092e-02, -1.1237e+00,  ..., -4.1462e-01,\n",
       "            1.4062e+00,  9.6762e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 7.0115e-01,  1.1568e+00,  5.2504e-01,  ...,  1.6667e+00,\n",
       "           -3.6673e-01,  2.4627e-01],\n",
       "          [ 6.6920e-01,  8.5803e-01,  4.0193e-02,  ...,  2.2148e-02,\n",
       "           -9.9671e-01,  7.8193e-01],\n",
       "          [-1.7698e-01, -8.0044e-01,  2.9295e-01,  ...,  7.8055e-01,\n",
       "            7.4634e-01,  2.0313e-01],\n",
       "          ...,\n",
       "          [ 3.8959e-01, -1.4987e+00,  1.9104e+00,  ...,  1.4773e+00,\n",
       "           -3.8234e-01, -4.7310e-01],\n",
       "          [ 3.7294e-01,  2.2457e-01, -1.7092e+00,  ...,  7.1043e-01,\n",
       "            1.3638e+00, -9.4826e-01],\n",
       "          [-3.0933e-01, -5.2184e-01,  5.2668e-01,  ...,  8.3438e-01,\n",
       "            8.2800e-01, -7.3037e-01]],\n",
       "\n",
       "         [[-5.4165e-01, -1.7110e-01,  9.2469e-01,  ..., -3.6990e-01,\n",
       "            5.6277e-01, -1.6209e+00],\n",
       "          [-8.8596e-02, -6.1879e-01, -8.8539e-01,  ..., -1.4635e+00,\n",
       "            6.6555e-02, -4.3613e-01],\n",
       "          [-1.7296e-01, -1.0134e+00, -4.4068e-01,  ...,  1.5123e+00,\n",
       "            1.7422e+00, -3.9372e-01],\n",
       "          ...,\n",
       "          [ 1.0853e+00,  1.4967e-01,  5.4469e-02,  ...,  9.5313e-01,\n",
       "            9.8242e-01,  1.2375e+00],\n",
       "          [ 1.6971e-02,  1.1250e+00,  3.7569e-01,  ..., -3.5448e-01,\n",
       "            4.4309e-01, -6.7691e-01],\n",
       "          [ 2.0862e-01,  1.0133e+00,  3.1286e-01,  ..., -8.4728e-01,\n",
       "            8.4264e-02,  9.9349e-01]],\n",
       "\n",
       "         [[-1.3113e-01,  6.0886e-01, -2.5807e-02,  ...,  3.5574e-02,\n",
       "           -7.4109e-01, -5.2458e-03],\n",
       "          [-1.0074e+00,  3.9699e-02,  4.5189e-01,  ...,  1.8617e-02,\n",
       "            1.5385e+00, -3.6517e-01],\n",
       "          [ 1.7919e+00,  7.5458e-01,  1.8730e-01,  ..., -1.0390e+00,\n",
       "           -7.0965e-01, -1.7610e-02],\n",
       "          ...,\n",
       "          [ 5.8635e-01,  1.4241e-01, -4.7282e-01,  ...,  3.2524e-01,\n",
       "            3.4792e-01, -1.2827e+00],\n",
       "          [ 4.1625e-01,  1.8714e+00, -1.6345e+00,  ...,  5.4528e-01,\n",
       "            9.4137e-01, -9.3936e-01],\n",
       "          [-1.3554e+00,  8.0541e-02,  2.1983e+00,  ..., -5.5197e-01,\n",
       "           -1.3538e+00, -4.1592e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.1390e+00,  1.2168e+00,  1.0007e+00,  ...,  6.2342e-01,\n",
       "            1.1755e+00,  2.5687e-01],\n",
       "          [-1.3039e-01, -2.1381e-02,  1.3405e-01,  ...,  3.9219e-01,\n",
       "            7.0326e-01, -1.2626e+00],\n",
       "          [ 1.0392e+00, -1.4988e+00,  6.3006e-01,  ...,  3.1309e-01,\n",
       "           -1.4286e-01,  2.5000e-01],\n",
       "          ...,\n",
       "          [ 1.3424e+00,  8.6067e-01,  2.5209e-01,  ..., -1.6149e+00,\n",
       "           -6.8855e-01,  1.1284e-01],\n",
       "          [-1.4698e-01, -1.6408e-01,  8.5474e-01,  ...,  2.8528e-01,\n",
       "            3.0760e-01, -1.4374e+00],\n",
       "          [ 3.9209e-01,  7.2545e-01, -2.7291e-01,  ...,  1.1261e-01,\n",
       "           -4.2802e-02,  3.5837e-02]],\n",
       "\n",
       "         [[-5.3911e-01, -5.7648e-01, -1.8569e-01,  ...,  1.6486e+00,\n",
       "            3.6724e-01,  2.6760e-01],\n",
       "          [ 2.8315e-01,  2.4302e+00,  1.1052e+00,  ..., -6.0017e-01,\n",
       "           -1.0999e-01,  6.8663e-01],\n",
       "          [-5.2353e-01,  1.0940e+00,  3.2625e-02,  ..., -7.6983e-01,\n",
       "            4.6636e-01,  3.8874e-01],\n",
       "          ...,\n",
       "          [-1.8437e-02,  1.6769e+00,  2.6927e+00,  ...,  1.0824e+00,\n",
       "            3.6734e-01,  1.3939e-01],\n",
       "          [ 2.4794e+00,  6.0781e-03,  4.9316e-01,  ...,  1.9093e+00,\n",
       "            1.1431e-01,  6.0082e-01],\n",
       "          [-3.7427e-01,  1.2661e+00,  1.2462e+00,  ...,  9.9610e-01,\n",
       "            6.7761e-02,  6.5081e-01]],\n",
       "\n",
       "         [[-6.7814e-01,  6.4801e-01,  6.2037e-01,  ...,  5.6959e-02,\n",
       "           -4.8391e-01,  5.2051e-01],\n",
       "          [-4.4682e-01, -2.2063e+00,  4.7374e-02,  ..., -6.5985e-01,\n",
       "           -8.5104e-02,  8.5897e-01],\n",
       "          [-2.9026e-01, -4.1527e-01,  9.3552e-01,  ...,  4.0859e-01,\n",
       "            6.9466e-02, -1.3479e+00],\n",
       "          ...,\n",
       "          [-2.5629e-01,  6.2396e-01, -5.2162e-01,  ..., -7.0181e-01,\n",
       "            7.2300e-01,  4.1658e-01],\n",
       "          [-2.4643e-02, -1.1416e+00, -4.9109e-01,  ...,  1.1653e+00,\n",
       "            1.8295e+00,  7.7084e-02],\n",
       "          [-3.6232e-02, -6.0639e-01,  4.9110e-01,  ..., -2.1748e-01,\n",
       "           -1.9142e+00, -5.0188e-01]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-8.4449e-01, -3.1054e-01,  7.4393e-01,  ..., -1.3802e-01,\n",
       "           -1.5769e-01,  1.2694e+00],\n",
       "          [ 4.0734e-01,  1.0311e+00,  1.4099e+00,  ..., -2.0394e+00,\n",
       "           -8.0174e-02,  4.8653e-01],\n",
       "          [-8.5730e-01, -1.2084e+00,  1.1503e+00,  ...,  2.1617e+00,\n",
       "            4.5080e-01,  9.5799e-01],\n",
       "          ...,\n",
       "          [-1.6313e+00,  6.3070e-01, -1.2716e+00,  ..., -7.0382e-01,\n",
       "           -1.1017e+00,  5.1421e-01],\n",
       "          [-5.7818e-01,  1.9130e-01, -2.5116e-01,  ..., -3.1614e-01,\n",
       "           -8.2341e-02,  2.2006e-01],\n",
       "          [-1.6932e-01, -1.8900e-01, -4.6270e-01,  ...,  5.9598e-01,\n",
       "            1.0592e+00,  5.5931e-01]],\n",
       "\n",
       "         [[ 3.8536e-01,  5.1803e-01, -2.1042e-01,  ...,  4.2492e-02,\n",
       "            1.7581e-01, -5.7725e-01],\n",
       "          [-6.2329e-01, -1.4325e+00,  1.1459e+00,  ...,  8.1996e-02,\n",
       "            8.9785e-01, -6.7094e-01],\n",
       "          [-9.0639e-01, -2.5898e-02,  1.2691e-01,  ..., -8.8044e-01,\n",
       "           -1.5379e+00, -4.8087e-01],\n",
       "          ...,\n",
       "          [ 3.6577e-01, -5.0483e-01,  7.1383e-01,  ..., -4.7783e-01,\n",
       "           -6.4625e-01, -1.4057e+00],\n",
       "          [ 6.1719e-01, -9.0305e-02,  9.6176e-01,  ..., -9.4177e-01,\n",
       "           -8.5357e-01, -9.5487e-01],\n",
       "          [ 4.2564e-01, -2.1406e-01,  8.6739e-01,  ..., -8.8041e-01,\n",
       "           -1.3807e+00,  2.3340e-01]],\n",
       "\n",
       "         [[ 7.6536e-02, -8.0313e-01, -3.7532e-01,  ...,  3.1250e-01,\n",
       "           -1.6714e+00, -4.8132e-01],\n",
       "          [ 6.8650e-01, -1.9117e-01, -6.5110e-01,  ...,  1.9392e-02,\n",
       "            1.0054e+00,  1.6585e+00],\n",
       "          [ 1.2033e+00, -7.0582e-01,  5.9159e-05,  ..., -8.9472e-01,\n",
       "            4.9988e-01,  1.7188e+00],\n",
       "          ...,\n",
       "          [-5.2611e-01, -5.2415e-01, -5.0461e-01,  ..., -3.4254e-01,\n",
       "            7.1628e-01,  9.1386e-01],\n",
       "          [ 1.6540e-02, -1.6526e+00, -8.0171e-01,  ...,  1.8666e+00,\n",
       "            4.2950e-01,  3.4657e-01],\n",
       "          [-5.1324e-01, -6.3243e-01, -1.5993e-01,  ...,  2.7483e-02,\n",
       "            2.9604e-01,  1.1444e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 5.0752e-01, -7.2531e-01, -4.9737e-01,  ...,  4.2010e-01,\n",
       "            1.2264e+00,  8.9826e-01],\n",
       "          [ 1.2061e+00, -2.4076e+00,  4.3014e-01,  ..., -7.7281e-02,\n",
       "           -1.4434e+00,  1.9268e-01],\n",
       "          [ 7.8985e-01, -3.7847e-01,  3.0736e-02,  ..., -1.1284e+00,\n",
       "            6.8994e-01,  6.3074e-01],\n",
       "          ...,\n",
       "          [-3.7535e-01, -1.0764e+00, -1.1667e+00,  ..., -6.8281e-01,\n",
       "           -5.7148e-01, -2.4064e-01],\n",
       "          [-2.8880e-01, -2.8085e-01,  8.4885e-01,  ...,  4.1421e-01,\n",
       "           -1.4342e+00,  5.0632e-01],\n",
       "          [ 2.1689e-02, -4.5075e-02, -7.2962e-01,  ..., -8.7950e-01,\n",
       "            4.1462e-01,  5.9741e-01]],\n",
       "\n",
       "         [[-1.2580e+00, -5.3258e-01,  2.0797e+00,  ...,  1.1320e+00,\n",
       "           -2.1860e-01, -4.6040e-01],\n",
       "          [ 1.1961e+00,  4.5934e-01,  3.1300e-01,  ..., -1.5943e+00,\n",
       "           -9.9401e-01, -9.8105e-01],\n",
       "          [-6.8412e-01,  2.9499e-01,  8.3444e-01,  ...,  2.1928e+00,\n",
       "            2.6982e-01, -1.0671e+00],\n",
       "          ...,\n",
       "          [-8.9471e-01,  1.2911e+00,  1.8885e+00,  ..., -1.9139e-02,\n",
       "            1.4692e+00, -5.0274e-01],\n",
       "          [ 1.5429e-01, -6.4294e-01, -3.0026e-01,  ..., -6.7997e-01,\n",
       "            1.0663e+00, -1.1426e+00],\n",
       "          [ 9.5567e-01,  4.6173e-01,  1.0777e+00,  ...,  1.4583e+00,\n",
       "           -4.4900e-01, -9.4877e-01]],\n",
       "\n",
       "         [[-5.9035e-01, -2.6939e-01,  1.0102e-01,  ..., -1.7904e+00,\n",
       "            4.9510e-01,  2.4770e-01],\n",
       "          [-7.1843e-01, -4.0723e-01,  8.4910e-01,  ...,  4.2879e-01,\n",
       "            1.1990e+00, -1.7056e+00],\n",
       "          [-5.7541e-01, -4.3096e-02,  8.9378e-01,  ..., -6.6706e-01,\n",
       "            2.5522e-01, -8.8368e-01],\n",
       "          ...,\n",
       "          [-1.0843e+00,  9.9184e-01,  2.4171e-01,  ..., -9.6367e-01,\n",
       "           -1.6221e-01,  5.3021e-01],\n",
       "          [ 3.7764e-01,  1.1992e+00, -2.9280e-01,  ..., -1.3393e-01,\n",
       "           -1.8530e+00, -1.5721e-01],\n",
       "          [-1.8294e+00,  6.9619e-01, -3.5347e-01,  ..., -3.4182e-01,\n",
       "            2.2049e+00, -1.3802e+00]]],\n",
       "\n",
       "\n",
       "        [[[ 4.0841e-01,  9.9011e-01, -9.5358e-01,  ..., -5.2508e-01,\n",
       "           -1.3238e-01,  1.5877e-01],\n",
       "          [ 2.1083e-01, -9.5787e-01,  1.0958e+00,  ..., -7.5553e-01,\n",
       "           -1.8168e+00, -3.4175e-01],\n",
       "          [-3.0719e-01, -8.5834e-01, -3.0396e-01,  ...,  8.1902e-01,\n",
       "           -7.7917e-01,  3.5380e-01],\n",
       "          ...,\n",
       "          [-1.7807e+00, -7.5911e-01, -8.3641e-01,  ...,  2.0099e-01,\n",
       "            1.0571e-02,  4.8226e-01],\n",
       "          [-5.8886e-01, -1.0594e+00,  1.1447e+00,  ..., -2.7871e-01,\n",
       "           -7.4637e-01, -4.9501e-01],\n",
       "          [ 1.9697e+00,  1.1198e+00, -4.9811e-01,  ..., -6.4749e-01,\n",
       "            1.1291e+00,  8.1582e-01]],\n",
       "\n",
       "         [[-8.4422e-01,  7.6981e-01,  9.6033e-01,  ..., -6.6946e-01,\n",
       "           -6.2595e-01, -2.6971e-01],\n",
       "          [-4.5547e-01, -8.1683e-01, -1.1946e+00,  ...,  3.1388e-01,\n",
       "            5.9450e-02,  3.8721e-01],\n",
       "          [ 8.6028e-02, -7.1963e-01, -1.0470e+00,  ...,  1.6206e+00,\n",
       "            2.5911e+00,  3.9180e-01],\n",
       "          ...,\n",
       "          [ 6.6824e-01, -5.6510e-01, -8.8610e-02,  ...,  1.6640e-01,\n",
       "            7.9176e-01, -1.4600e-01],\n",
       "          [ 1.0932e+00,  3.0682e-01,  5.5205e-01,  ..., -6.8833e-01,\n",
       "           -1.9644e+00, -1.0562e-01],\n",
       "          [-5.6081e-02, -1.1325e-01, -1.5777e-01,  ...,  4.1493e-01,\n",
       "           -8.1056e-01,  4.9299e-01]],\n",
       "\n",
       "         [[-8.8155e-01, -3.7686e-01, -6.8923e-01,  ..., -2.6792e-01,\n",
       "           -8.1189e-01, -1.6157e+00],\n",
       "          [-9.3473e-01,  4.8011e-01, -7.8844e-01,  ...,  9.1570e-01,\n",
       "            1.6478e+00, -8.5262e-01],\n",
       "          [-5.1750e-01,  7.7401e-01, -2.4999e+00,  ..., -1.0440e+00,\n",
       "            3.5370e-01,  1.0304e+00],\n",
       "          ...,\n",
       "          [-1.7308e+00, -1.1142e+00, -3.4512e-01,  ...,  2.6908e-03,\n",
       "            2.1593e-01,  7.0134e-01],\n",
       "          [-7.0748e-01, -1.3320e+00, -6.5713e-01,  ..., -5.6553e-01,\n",
       "            2.4499e-01, -1.0783e+00],\n",
       "          [-2.3226e-01,  5.7852e-01,  9.8555e-01,  ...,  1.0422e+00,\n",
       "           -5.7054e-01, -1.3453e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.6855e-01,  1.8274e+00, -2.0351e-01,  ...,  2.2719e-01,\n",
       "           -1.4757e+00,  1.2291e-01],\n",
       "          [ 1.4656e+00,  1.6707e+00,  1.0738e-03,  ...,  1.1479e+00,\n",
       "           -6.0172e-02,  5.2814e-01],\n",
       "          [-8.4975e-02,  3.9711e-02, -1.0208e+00,  ...,  3.0873e-01,\n",
       "            1.3595e+00,  1.8255e+00],\n",
       "          ...,\n",
       "          [-1.4357e+00,  2.8514e-01,  5.7806e-01,  ..., -2.7934e-01,\n",
       "           -3.8262e-01,  1.2918e-02],\n",
       "          [ 1.9101e-01, -2.3390e-01,  1.5535e+00,  ..., -4.9105e-01,\n",
       "            1.1573e+00,  9.8320e-02],\n",
       "          [ 4.0030e-01, -9.2692e-01, -3.7863e-01,  ..., -2.2342e-01,\n",
       "            1.3271e+00,  1.1432e+00]],\n",
       "\n",
       "         [[ 3.5927e-01,  1.0842e-01, -8.6384e-02,  ...,  4.4730e-01,\n",
       "           -5.2837e-01, -7.0581e-01],\n",
       "          [ 1.4244e+00,  5.5650e-01, -2.0686e-01,  ..., -6.6912e-01,\n",
       "           -1.6668e+00,  2.1883e+00],\n",
       "          [-6.5281e-01, -1.2437e+00,  9.4858e-01,  ...,  1.1101e+00,\n",
       "           -1.4198e+00, -1.0690e+00],\n",
       "          ...,\n",
       "          [-7.2054e-01,  1.3020e+00, -1.0504e-01,  ..., -1.8513e+00,\n",
       "           -6.9866e-01,  1.0450e-01],\n",
       "          [-5.6716e-01, -3.3272e-01,  3.3680e-01,  ..., -3.1726e-01,\n",
       "           -1.4620e-01, -4.0581e-01],\n",
       "          [ 1.6074e+00,  1.7540e+00,  3.7208e-01,  ..., -5.8116e-01,\n",
       "            8.0560e-01,  1.1698e-01]],\n",
       "\n",
       "         [[-4.1286e-01,  9.0806e-01, -5.1521e-02,  ..., -6.8787e-02,\n",
       "           -4.7326e-01, -7.0441e-01],\n",
       "          [-1.7425e+00, -3.1083e-01,  7.0862e-01,  ..., -3.0077e+00,\n",
       "            2.3097e-02, -2.1783e-01],\n",
       "          [ 8.2948e-01,  8.0119e-01, -7.4915e-01,  ...,  5.0223e-01,\n",
       "           -4.2008e-01,  6.4800e-01],\n",
       "          ...,\n",
       "          [ 1.5237e-01,  5.8489e-01,  2.7933e-01,  ...,  1.2629e+00,\n",
       "           -1.7348e-01,  1.6134e+00],\n",
       "          [-3.4661e-01,  8.2259e-01, -1.5103e+00,  ...,  1.0209e+00,\n",
       "           -9.2384e-01,  3.3402e-01],\n",
       "          [-1.5888e+00,  6.6719e-01, -9.5775e-01,  ..., -8.6791e-01,\n",
       "           -7.5255e-01,  4.6365e-01]]],\n",
       "\n",
       "\n",
       "        [[[-1.1781e+00, -1.3029e-01, -2.1359e-01,  ..., -5.2043e-01,\n",
       "            1.0668e-01,  7.6728e-01],\n",
       "          [-4.0477e-01,  1.5941e+00,  4.0464e-02,  ..., -2.9895e-02,\n",
       "           -1.0520e+00, -6.6093e-01],\n",
       "          [ 5.1410e-01, -9.9765e-01, -1.1831e+00,  ...,  6.7105e-01,\n",
       "           -2.0721e-01,  1.1759e+00],\n",
       "          ...,\n",
       "          [ 3.2077e-01,  1.2735e-01, -6.0121e-02,  ...,  3.1107e-01,\n",
       "           -7.2654e-01, -2.1201e-01],\n",
       "          [ 1.7129e-01,  2.2661e+00,  1.2502e-01,  ...,  1.1252e+00,\n",
       "            7.6363e-01, -2.9062e-01],\n",
       "          [ 6.3870e-02, -2.1921e-01,  6.0971e-01,  ...,  1.9659e-01,\n",
       "           -6.5217e-01, -1.7491e-01]],\n",
       "\n",
       "         [[-4.0313e-01, -3.7030e-01, -6.1690e-01,  ...,  1.4351e+00,\n",
       "            7.4512e-01, -1.7763e-01],\n",
       "          [-3.9798e-01,  2.8655e-01, -1.4086e+00,  ...,  1.5126e+00,\n",
       "           -5.0445e-02, -1.5961e+00],\n",
       "          [ 9.1489e-01, -1.1033e-01,  1.3447e-01,  ...,  3.1795e-01,\n",
       "           -1.6018e-01, -7.5443e-01],\n",
       "          ...,\n",
       "          [ 2.2213e-02,  1.3395e+00,  4.9885e-01,  ..., -1.9183e+00,\n",
       "           -1.1057e+00, -3.2128e-01],\n",
       "          [-1.3978e+00,  4.6282e-01, -3.8105e-01,  ...,  4.2300e-01,\n",
       "            1.9446e+00,  1.5503e+00],\n",
       "          [-4.2430e-01, -2.4496e-01, -7.4665e-01,  ..., -7.0191e-01,\n",
       "           -6.9214e-02,  6.3993e-01]],\n",
       "\n",
       "         [[-4.0638e-01,  4.5298e-01,  9.6241e-01,  ..., -6.8923e-01,\n",
       "            7.1981e-01,  1.5792e+00],\n",
       "          [-3.5914e-01, -1.3084e+00, -1.9838e-01,  ..., -4.7463e-01,\n",
       "            1.3723e+00, -9.8090e-01],\n",
       "          [ 1.2931e+00, -4.1264e-01,  3.4402e-01,  ...,  8.3675e-01,\n",
       "            6.2328e-01,  7.2662e-02],\n",
       "          ...,\n",
       "          [ 1.0189e+00,  1.0096e-01, -9.1739e-01,  ...,  7.8042e-01,\n",
       "            9.6347e-01, -3.9538e-01],\n",
       "          [ 1.6489e-01, -1.4948e-01,  1.4439e-01,  ..., -1.4419e+00,\n",
       "            1.0571e+00,  8.9109e-01],\n",
       "          [-6.0056e-01, -6.0866e-01,  2.4883e-01,  ..., -6.1388e-01,\n",
       "           -8.8694e-01,  5.2452e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 5.4223e-01,  9.0744e-01, -8.8018e-01,  ..., -6.0667e-01,\n",
       "            6.9835e-01, -5.2519e-01],\n",
       "          [-1.0279e+00, -1.8919e-01,  1.2437e+00,  ...,  3.5944e-02,\n",
       "           -9.6511e-01, -1.3595e+00],\n",
       "          [-4.1287e-01,  4.2947e-02, -7.3876e-01,  ..., -3.5916e-01,\n",
       "            7.8682e-02, -1.4648e+00],\n",
       "          ...,\n",
       "          [ 3.7129e-01,  2.4884e-02,  1.3481e+00,  ..., -1.1293e+00,\n",
       "           -1.9650e+00,  3.2563e-01],\n",
       "          [ 1.2283e+00,  6.5394e-01, -6.5680e-01,  ...,  3.8077e-01,\n",
       "           -2.0544e+00,  8.4972e-01],\n",
       "          [ 1.8815e+00, -3.2848e-01,  1.3378e+00,  ..., -3.4089e-01,\n",
       "           -3.1580e-01,  3.4743e-01]],\n",
       "\n",
       "         [[-1.1181e-01,  2.7570e+00,  1.2883e+00,  ...,  7.7799e-01,\n",
       "           -5.2922e-01,  1.4170e+00],\n",
       "          [-1.5824e+00, -3.0634e-01,  2.8346e-01,  ..., -2.0310e+00,\n",
       "            9.9892e-01, -9.0461e-01],\n",
       "          [ 1.1028e+00, -7.1082e-02, -1.3889e+00,  ..., -1.1211e+00,\n",
       "           -8.8891e-01,  2.9426e-01],\n",
       "          ...,\n",
       "          [-2.9851e-01,  3.5998e-02, -2.1459e+00,  ...,  4.6036e-01,\n",
       "           -8.1007e-01,  4.1877e-01],\n",
       "          [-8.5375e-01,  8.9668e-01,  1.7436e+00,  ...,  6.9000e-01,\n",
       "           -7.6200e-01,  5.4065e-01],\n",
       "          [-3.9913e-01, -1.4681e-01,  5.6256e-01,  ...,  1.4061e-01,\n",
       "           -1.5199e+00,  3.8824e-01]],\n",
       "\n",
       "         [[-7.1494e-01,  3.5460e-01,  3.2846e-01,  ...,  1.0049e+00,\n",
       "            2.5455e-01, -1.1718e-01],\n",
       "          [-1.4988e+00, -8.1568e-01, -1.2888e-01,  ..., -2.9455e-02,\n",
       "            1.4978e+00, -2.1660e+00],\n",
       "          [-4.7152e-01, -9.5928e-01,  2.6479e+00,  ...,  7.2488e-02,\n",
       "            8.3756e-01,  1.7704e+00],\n",
       "          ...,\n",
       "          [-3.9523e-01,  1.2113e+00, -1.7260e-01,  ..., -2.0189e-01,\n",
       "           -1.1272e+00, -1.9069e-01],\n",
       "          [ 1.0252e+00, -1.7807e+00,  9.9746e-01,  ...,  4.5211e-01,\n",
       "           -1.2334e+00,  5.1907e-01],\n",
       "          [ 1.1869e+00, -6.4923e-02, -5.0778e-01,  ...,  3.1477e-01,\n",
       "            1.3170e-01, -6.6688e-01]]]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): BasicBlock(\n",
       "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (1): BasicBlock(\n",
       "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import logging\n",
    "import math\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class ResNetModelShard(ModuleShard):\n",
    "\n",
    "    def __init__(self, config, shard_config: ModuleShardConfig,\n",
    "                 model_weights):\n",
    "        super().__init__(config, shard_config)\n",
    "        self.conv1 = None\n",
    "        self.bn1 = None\n",
    "        self.relu = None\n",
    "        self.maxpool = None\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "\n",
    "        self.avgpool = None\n",
    "        self.fc = None\n",
    "\n",
    "        logger.debug(\">>>> Model name: %s\", self.config.name_or_path)\n",
    "        if isinstance(model_weights, str):\n",
    "            logger.debug(\">>>> Load weight file: %s\", model_weights)\n",
    "            with np.load(model_weights) as weights:\n",
    "                self._build_shard(weights)\n",
    "        else:\n",
    "            self._build_shard(model_weights)\n",
    "\n",
    "    def _build_shard(self, weights):\n",
    "        if self.shard_config.is_first:\n",
    "            logger.debug(\">>>> Load embeddings layer for the first shard\")\n",
    "            self.conv1 = Conv2d(**self.config['conv1'])\n",
    "            self.bn1 = BatchNorm2d(**self.config['bn1'])\n",
    "            self.relu = ReLU(**self.config['relu'])\n",
    "            self.maxpool = MaxPool2d(**self.config['maxpool'])\n",
    "            self._load_weights_first(weights)\n",
    "\n",
    "        layer_curr = self.shard_config.layer_start\n",
    "        while layer_curr <= (self.shard_config.layer_end -1 if self.shard_config.is_last else self.shard_config.layer_end):\n",
    "            print(layer_curr)\n",
    "            if self.shard_config.layer_end != 0:\n",
    "                layer_id = layer_curr // 5 + 1\n",
    "                layer_sub_id = layer_curr  %5 // 3\n",
    "                \n",
    "\n",
    "                if layer_sub_id == 0:\n",
    "                    if layer_id ==1:\n",
    "                        layer_curr = max(1, layer_curr)\n",
    "                        sublayer_start = (layer_curr - 1) % 2\n",
    "                        if self.shard_config.layer_end > 2:\n",
    "                            sublayer_end = 1\n",
    "                        else:\n",
    "                            sublayer_end = self.shard_config.layer_end - 1\n",
    "                        sub_layer_is_last = True if sublayer_end == 1 else False\n",
    "\n",
    "                    else:\n",
    "                        sublayer_start = layer_curr % 5 % 3\n",
    "                        if layer_id == self.shard_config.layer_end // 5 + 1 and layer_sub_id == self.shard_config.layer_end %5 // 3:\n",
    "                            sublayer_end = self.shard_config.layer_end % 5 % 3\n",
    "                        else:\n",
    "                            sublayer_end = 2\n",
    "                        sub_layer_is_last = True if sublayer_end == 2 else False\n",
    "                else:\n",
    "                    sublayer_start = layer_curr % 5 % 3\n",
    "                    if layer_id == self.shard_config.layer_end // 5 + 1 and layer_sub_id == self.shard_config.layer_end %5 // 3:\n",
    "                        sublayer_end = self.shard_config.layer_end % 5 % 3\n",
    "                    else:\n",
    "                        sublayer_end = 1\n",
    "                    sub_layer_is_last = True if sublayer_end == 1 else False\n",
    "\n",
    "                sub_layer_is_first = True if sublayer_start == 0 else False\n",
    "\n",
    "\n",
    "                layer_config = ModuleShardConfig(layer_start=sublayer_start, layer_end=sublayer_end\n",
    "                                                ,is_first = sub_layer_is_first, is_last = sub_layer_is_last)\n",
    "                sub_model_config = self.config[f'layer{layer_id}_{layer_sub_id}']\n",
    "                layer = ResNetLayerShard(sub_model_config, layer_config)\n",
    "                self._load_weights_layer(weights.__getattr__(f'layer{layer_id}')[layer_sub_id], layer)\n",
    "                self.layers.append(layer)\n",
    "\n",
    "                layer_curr += sublayer_end - sublayer_start + 1\n",
    "            else:\n",
    "                layer_curr = 1\n",
    "\n",
    "\n",
    "        if self.shard_config.is_last:\n",
    "            logger.debug(\">>>> Load layernorm for the last shard\")\n",
    "            self.avgpool = nn.AdaptiveAvgPool2d(**self.config[\"avgpool\"])\n",
    "            self.fc = nn.Linear(**self.config[\"fc\"])\n",
    "            self._load_weights_last(weights)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _load_weights_first(self, weights):\n",
    "        self.conv1.load_state_dict(weights.conv1.state_dict())\n",
    "        self.bn1.load_state_dict(weights.bn1.state_dict())\n",
    "        self.relu.load_state_dict(weights.relu.state_dict())\n",
    "        self.maxpool.load_state_dict(weights.maxpool.state_dict())\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _load_weights_last(self, weights):\n",
    "        self.avgpool.load_state_dict(weights.avgpool.state_dict())\n",
    "        self.fc.load_state_dict(weights.fc.state_dict())\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _load_weights_layer(self, weights, layer):\n",
    "        if layer.has_layer(0):\n",
    "            layer.conv1.load_state_dict(weights.conv1.state_dict())\n",
    "            layer.bn1.load_state_dict(weights.bn1.state_dict())\n",
    "            layer.relu.load_state_dict(weights.relu.state_dict())\n",
    "        if layer.has_layer(1):\n",
    "            layer.conv2.load_state_dict(weights.conv2.state_dict())\n",
    "            layer.bn2.load_state_dict(weights.bn2.state_dict())\n",
    "        if layer.has_layer(2):\n",
    "            layer.downsample_conv.load_state_dict(weights.downsample[0].state_dict())\n",
    "            layer.downsample_bn.load_state_dict(weights.downsample[1].state_dict())\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def forward(self, data):\n",
    "        \"\"\"Compute shard layers.\"\"\"\n",
    "        if self.shard_config.is_first:\n",
    "            data = self.conv1(data[1])\n",
    "            data = self.bn1(data)\n",
    "            data = self.relu(data)\n",
    "            data = self.maxpool(data)\n",
    "            data = [data, data]\n",
    "        for layer in self.layers:\n",
    "            data = layer(data)\n",
    "        if self.shard_config.is_last:\n",
    "            data = self.avgpool(data[1])\n",
    "            data = torch.flatten(data, 1)\n",
    "            data = self.fc(data)\n",
    "            data = [data, data]\n",
    "        return data\n",
    "\n",
    "    # @staticmethod\n",
    "    # def save_weights(model_name: str, model_file: str, url: Optional[str]=None,\n",
    "    #                  timeout_sec: Optional[float]=None) -> None:\n",
    "    #     \"\"\"Save the model weights file.\"\"\"\n",
    "    #     if url is None:\n",
    "    #         url = _WEIGHTS_URLS[model_name]\n",
    "    #     logger.info('Downloading model: %s: %s', model_name, url)\n",
    "    #     req = requests.get(url, stream=True, timeout=timeout_sec)\n",
    "    #     req.raise_for_status()\n",
    "    #     with open(model_file, 'wb') as file:\n",
    "    #         for chunk in req.iter_content(chunk_size=8192):\n",
    "    #             if chunk:\n",
    "    #                 file.write(chunk)\n",
    "    #                 file.flush()\n",
    "    #                 os.fsync(file.fileno())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "3\n",
      "5\n",
      "8\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "model_part1_shard_config = ModuleShardConfig(layer_start=0, layer_end=10, is_first = True)\n",
    "model_part1 = ResNetModelShard(res_config, model_part1_shard_config, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "13\n",
      "15\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "model_part2_shard_config = ModuleShardConfig(layer_start=11, layer_end=20, is_last = True)\n",
    "model_part2 = ResNetModelShard(res_config, model_part2_shard_config, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "3\n",
      "5\n",
      "8\n",
      "10\n",
      "13\n",
      "15\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "model_part2_shard_config = ModuleShardConfig(layer_start=0, layer_end=20, is_last = True)\n",
    "model_part2 = ResNetModelShard(res_config, model_part2_shard_config, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): BasicBlock(\n",
       "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (downsample): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (1): BasicBlock(\n",
       "    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layer3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNetModelShard(\n",
       "  (layers): ModuleList(\n",
       "    (0-1): 2 x ResNetLayerShard(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): ResNetLayerShard(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample_conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (downsample_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): ResNetLayerShard(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): ResNetLayerShard(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_part1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): BasicBlock(\n",
       "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (downsample): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (1): BasicBlock(\n",
       "    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNetLayerShard(\n",
      "  (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (downsample_conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "  (downsample_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "ResNetLayerShard(\n",
      "  (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model_part1.layers[2])\n",
    "print(model_part1.layers[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8  \n",
    "sample_input = torch.randn(batch_size, 64, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer2 = model.layer2\n",
    "model_part1.layers[2].eval()\n",
    "model_part1.layers[3].eval()\n",
    "model.layer2[0].eval()\n",
    "\n",
    "with torch.no_grad(): \n",
    "    output_shard = model_part1.layers[2].forward([sample_input, sample_input])[1]\n",
    "    output_shard = model_part1.layers[3].forward([output_shard, output_shard])[1]\n",
    "    # output_shard = model_part1.layers[3].forward(output_shard)[1]\n",
    "    output_origin = model.layer2(sample_input)\n",
    "\n",
    "torch.all(output_shard.eq(output_origin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[8.5445e-01, 1.0418e-02, 2.2933e-03,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 1.0321e-01],\n",
       "          [1.4065e-01, 0.0000e+00, 0.0000e+00,  ..., 7.5085e-01,\n",
       "           7.7745e-02, 1.2300e+00],\n",
       "          [0.0000e+00, 3.7654e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [2.0328e-01, 8.4154e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 2.0143e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.2478e+00,\n",
       "           9.3016e-01, 9.0557e-01],\n",
       "          [9.0711e-01, 9.7260e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           9.4678e-02, 2.4047e-02]],\n",
       "\n",
       "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 2.3810e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 3.1409e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 8.9930e-02],\n",
       "          ...,\n",
       "          [1.1089e-02, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [4.5487e-01, 1.6325e-01, 6.3373e-02,  ..., 3.4063e-02,\n",
       "           1.0447e-01, 0.0000e+00],\n",
       "          [1.5503e-01, 6.8088e-02, 2.0863e-02,  ..., 0.0000e+00,\n",
       "           1.2780e-02, 0.0000e+00]],\n",
       "\n",
       "         [[0.0000e+00, 4.3047e-01, 8.3589e-01,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 3.7993e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           9.2340e-03, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [6.0738e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           1.1521e-01, 0.0000e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.0000e+00, 2.0630e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [2.0867e-01, 4.3076e-02, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           1.0204e-01, 0.0000e+00],\n",
       "          [7.5397e-01, 8.7089e-01, 0.0000e+00,  ..., 8.0394e-02,\n",
       "           1.2460e+00, 5.3680e-01],\n",
       "          ...,\n",
       "          [3.4957e-01, 0.0000e+00, 1.0840e-01,  ..., 4.8696e-01,\n",
       "           9.4255e-01, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           1.4721e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 3.4186e-01,  ..., 0.0000e+00,\n",
       "           5.3203e-01, 0.0000e+00]],\n",
       "\n",
       "         [[2.5923e-01, 1.7395e-01, 2.3232e-01,  ..., 1.6652e-01,\n",
       "           7.1863e-02, 7.5029e-02],\n",
       "          [4.1327e-01, 2.9681e-01, 4.3982e-01,  ..., 2.4188e-02,\n",
       "           0.0000e+00, 1.2454e-02],\n",
       "          [3.0207e-01, 1.2444e-01, 1.8848e-01,  ..., 2.1243e-01,\n",
       "           1.5597e-01, 1.5369e-01],\n",
       "          ...,\n",
       "          [3.0575e-01, 1.6771e-01, 2.2010e-01,  ..., 9.2646e-02,\n",
       "           1.5017e-01, 1.2451e-01],\n",
       "          [2.4401e-01, 6.5059e-02, 2.0340e-01,  ..., 8.0156e-03,\n",
       "           2.3731e-01, 1.0779e-01],\n",
       "          [2.3781e-01, 2.0858e-01, 3.1462e-01,  ..., 1.7653e-01,\n",
       "           2.5740e-01, 1.2708e-01]],\n",
       "\n",
       "         [[3.3204e-01, 5.0805e-01, 6.6381e-01,  ..., 5.3894e-01,\n",
       "           6.7283e-02, 2.5847e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 6.1693e-01,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           4.2376e-01, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.4044e-01,\n",
       "           8.9860e-01, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 2.2886e+00,  ..., 0.0000e+00,\n",
       "           1.3565e+00, 4.6619e-01],\n",
       "          [0.0000e+00, 1.0710e+00, 1.1727e+00,  ..., 3.0938e-01,\n",
       "           1.2527e+00, 5.3815e-01]]],\n",
       "\n",
       "\n",
       "        [[[6.2456e-03, 4.5905e-02, 5.4408e-01,  ..., 7.1423e-02,\n",
       "           2.3862e-01, 2.6221e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 2.1754e-01,  ..., 0.0000e+00,\n",
       "           4.4719e-01, 0.0000e+00],\n",
       "          [1.1823e+00, 0.0000e+00, 7.8641e-01,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 6.9786e-01],\n",
       "          ...,\n",
       "          [1.1557e+00, 5.4498e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 7.0469e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           3.7926e-01, 4.7308e-02],\n",
       "          [6.3920e-01, 1.3680e-01, 4.5467e-01,  ..., 0.0000e+00,\n",
       "           2.6770e-02, 0.0000e+00]],\n",
       "\n",
       "         [[0.0000e+00, 0.0000e+00, 2.3959e-02,  ..., 1.6746e-01,\n",
       "           0.0000e+00, 9.4686e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 1.0514e-01,  ..., 1.0947e-01,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 1.0330e-02, 1.3795e-01,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 6.3974e-02],\n",
       "          [8.4053e-02, 1.0285e-01, 2.3631e-01,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 2.5191e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           2.4209e-01, 4.9070e-01]],\n",
       "\n",
       "         [[3.6395e-02, 0.0000e+00, 0.0000e+00,  ..., 4.9220e-01,\n",
       "           6.2120e-01, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 0.0000e+00, 9.6000e-02,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.0000e+00, 4.9438e-01, 0.0000e+00,  ..., 1.3130e-01,\n",
       "           6.3582e-01, 3.5638e-01],\n",
       "          [0.0000e+00, 3.1481e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 8.8891e-01, 0.0000e+00,  ..., 1.3146e-01,\n",
       "           0.0000e+00, 6.2893e-01],\n",
       "          ...,\n",
       "          [4.1316e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           1.5916e-01, 2.3717e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 9.7938e-01,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [1.1856e+00, 5.7738e-01, 1.2133e+00,  ..., 1.3673e+00,\n",
       "           9.1021e-01, 0.0000e+00]],\n",
       "\n",
       "         [[4.0638e-01, 2.5139e-01, 3.0593e-01,  ..., 2.5483e-01,\n",
       "           1.5868e-01, 1.8937e-01],\n",
       "          [2.9217e-01, 9.3835e-02, 9.4571e-02,  ..., 4.2526e-01,\n",
       "           3.2156e-01, 2.1841e-01],\n",
       "          [3.9160e-01, 1.7009e-01, 2.9892e-01,  ..., 3.8797e-01,\n",
       "           1.6239e+00, 2.1123e-01],\n",
       "          ...,\n",
       "          [3.7832e-01, 4.1018e-02, 6.9119e-02,  ..., 7.0999e-01,\n",
       "           4.7643e-01, 1.0927e-02],\n",
       "          [1.8997e-01, 0.0000e+00, 0.0000e+00,  ..., 1.6990e-01,\n",
       "           6.9892e-02, 6.3697e-02],\n",
       "          [3.7454e-01, 2.0130e-01, 1.3944e-01,  ..., 2.6104e-01,\n",
       "           1.4413e-01, 9.7538e-02]],\n",
       "\n",
       "         [[0.0000e+00, 0.0000e+00, 6.6454e-01,  ..., 1.5133e-01,\n",
       "           2.7557e-01, 0.0000e+00],\n",
       "          [3.5523e-01, 0.0000e+00, 1.6617e-01,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [2.4437e-01, 0.0000e+00, 2.9925e-01,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 1.3721e-01],\n",
       "          ...,\n",
       "          [7.2344e-03, 4.9452e-01, 1.8844e+00,  ..., 0.0000e+00,\n",
       "           2.2771e-01, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 2.5604e-01]]],\n",
       "\n",
       "\n",
       "        [[[7.7200e-01, 1.6798e+00, 0.0000e+00,  ..., 1.1432e-02,\n",
       "           4.1016e-01, 6.0844e-01],\n",
       "          [1.3692e+00, 0.0000e+00, 2.5361e-01,  ..., 0.0000e+00,\n",
       "           1.3192e-01, 0.0000e+00],\n",
       "          [5.6669e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           1.0551e-01, 0.0000e+00],\n",
       "          ...,\n",
       "          [2.5295e-02, 0.0000e+00, 5.6670e-03,  ..., 1.1882e+00,\n",
       "           0.0000e+00, 4.3266e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 6.2499e-01,  ..., 0.0000e+00,\n",
       "           2.8328e-01, 1.3586e-02],\n",
       "          [0.0000e+00, 1.1030e+00, 2.1997e-01,  ..., 0.0000e+00,\n",
       "           1.1052e+00, 1.5926e+00]],\n",
       "\n",
       "         [[0.0000e+00, 1.2666e-01, 3.5022e-01,  ..., 1.3167e-01,\n",
       "           9.8579e-02, 7.1410e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3266e-02,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 4.4572e-01],\n",
       "          [4.9981e-02, 6.0419e-02, 3.8916e-02,  ..., 6.8659e-02,\n",
       "           3.8691e-02, 2.2388e-01],\n",
       "          [0.0000e+00, 6.8079e-02, 9.9755e-03,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 3.9040e-02]],\n",
       "\n",
       "         [[6.4427e-01, 7.0519e-02, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           4.5187e-02, 1.2355e-01],\n",
       "          [1.1901e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 1.0845e-01,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 4.2318e-02,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 4.4751e-01,\n",
       "           4.2523e-01, 7.0595e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 9.0877e-01,\n",
       "           1.1888e+00, 1.7118e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 9.0646e-03,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 1.3067e+00, 9.6913e-02,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 3.3281e-02, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           2.4427e-01, 7.2747e-01],\n",
       "          [0.0000e+00, 5.8038e-01, 0.0000e+00,  ..., 1.1378e+00,\n",
       "           9.4370e-01, 4.0943e-01]],\n",
       "\n",
       "         [[2.4910e-01, 1.6208e-01, 2.8021e-01,  ..., 1.5068e-01,\n",
       "           1.8523e-01, 1.7600e-01],\n",
       "          [1.4327e-01, 0.0000e+00, 2.4173e-01,  ..., 2.7221e-01,\n",
       "           2.6570e-01, 2.1178e-01],\n",
       "          [1.9606e-01, 7.3728e-02, 3.0380e-01,  ..., 1.1234e+00,\n",
       "           2.9438e-01, 3.0083e-01],\n",
       "          ...,\n",
       "          [2.8982e-01, 1.5000e-01, 2.3888e-01,  ..., 1.2659e-01,\n",
       "           7.5866e-02, 8.1103e-02],\n",
       "          [2.4884e-01, 2.1275e-01, 1.7285e-01,  ..., 9.5810e-02,\n",
       "           1.5089e-01, 1.4121e-01],\n",
       "          [2.0444e-01, 8.7551e-02, 1.2509e-01,  ..., 0.0000e+00,\n",
       "           1.5970e-02, 0.0000e+00]],\n",
       "\n",
       "         [[8.5626e-02, 0.0000e+00, 0.0000e+00,  ..., 1.4019e-01,\n",
       "           8.4129e-01, 0.0000e+00],\n",
       "          [5.5095e-01, 3.2418e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 1.1222e+00, 7.7462e-01,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 8.6158e-01],\n",
       "          ...,\n",
       "          [0.0000e+00, 0.0000e+00, 2.8546e-01,  ..., 9.6533e-02,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 7.6948e-02, 0.0000e+00,  ..., 1.2147e+00,\n",
       "           2.2911e-01, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 7.3134e-02]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0.0000e+00, 8.7409e-02, 1.8123e+00,  ..., 0.0000e+00,\n",
       "           2.6792e-01, 8.2157e-01],\n",
       "          [9.8919e-01, 2.2812e-01, 0.0000e+00,  ..., 5.7845e-01,\n",
       "           4.1844e-01, 8.6389e-01],\n",
       "          [3.2661e-01, 0.0000e+00, 0.0000e+00,  ..., 9.4642e-02,\n",
       "           0.0000e+00, 1.2117e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 1.3681e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           1.0919e+00, 0.0000e+00],\n",
       "          [4.3509e-02, 0.0000e+00, 3.3898e-01,  ..., 0.0000e+00,\n",
       "           7.8853e-01, 0.0000e+00],\n",
       "          [8.0936e-01, 6.6300e-01, 3.9403e-01,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 1.7974e-01]],\n",
       "\n",
       "         [[3.9357e-01, 8.9203e-02, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           2.6838e-01, 3.5872e-01],\n",
       "          [0.0000e+00, 2.5165e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           2.3059e-01, 1.6851e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           7.6091e-02, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 0.0000e+00, 2.0723e-01,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 4.3304e-01],\n",
       "          [1.4086e-01, 0.0000e+00, 0.0000e+00,  ..., 6.4797e-02,\n",
       "           2.8580e-01, 4.0076e-01],\n",
       "          [2.7228e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           1.0320e-01, 1.8390e-01]],\n",
       "\n",
       "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 5.9118e-01,\n",
       "           1.1724e-02, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 1.6908e-02,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.0000e+00, 0.0000e+00, 2.2838e-01,  ..., 7.3119e-01,\n",
       "           0.0000e+00, 1.7154e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 4.0971e-01,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [1.7363e-01, 0.0000e+00, 0.0000e+00,  ..., 3.4660e-01,\n",
       "           0.0000e+00, 5.2885e-01],\n",
       "          ...,\n",
       "          [4.3759e-01, 0.0000e+00, 0.0000e+00,  ..., 5.0856e-01,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [4.5721e-01, 0.0000e+00, 2.9859e-01,  ..., 3.3806e-01,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 3.5533e-01, 0.0000e+00,  ..., 1.1364e+00,\n",
       "           0.0000e+00, 8.6170e-01]],\n",
       "\n",
       "         [[1.1982e-01, 3.7045e-02, 3.9659e-01,  ..., 3.7311e-01,\n",
       "           2.4967e-02, 1.3648e-01],\n",
       "          [2.6537e-01, 2.8489e-02, 2.7645e-01,  ..., 1.5322e-01,\n",
       "           1.9086e-02, 7.7718e-02],\n",
       "          [2.1761e-01, 8.7883e-02, 3.6987e-01,  ..., 2.8807e-01,\n",
       "           1.4463e-01, 1.8451e-01],\n",
       "          ...,\n",
       "          [4.7619e-02, 7.3415e-02, 3.1608e-01,  ..., 2.5922e-01,\n",
       "           3.4840e-01, 0.0000e+00],\n",
       "          [1.5041e-01, 8.8719e-02, 1.7228e-01,  ..., 1.3857e-01,\n",
       "           1.8315e-01, 0.0000e+00],\n",
       "          [1.3909e-01, 6.2694e-01, 9.2505e-02,  ..., 2.7674e-01,\n",
       "           3.1841e-02, 0.0000e+00]],\n",
       "\n",
       "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.2087e-01,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [1.8061e-01, 0.0000e+00, 0.0000e+00,  ..., 5.1077e-02,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [8.5034e-01, 8.7225e-01, 0.0000e+00,  ..., 1.7894e-01,\n",
       "           6.7994e-01, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 0.0000e+00, 5.4185e-01,  ..., 2.7242e-01,\n",
       "           3.1067e-04, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 6.3675e-01,  ..., 3.7345e-01,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 5.9095e-01, 4.6144e-02,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]]],\n",
       "\n",
       "\n",
       "        [[[0.0000e+00, 0.0000e+00, 1.2157e+00,  ..., 6.2755e-01,\n",
       "           1.3215e-01, 1.3445e-01],\n",
       "          [8.6409e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           5.7571e-02, 5.7037e-01],\n",
       "          [1.0818e+00, 0.0000e+00, 2.5199e-02,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 8.9625e-01, 0.0000e+00,  ..., 2.2039e-02,\n",
       "           7.9619e-03, 1.2406e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 1.1194e+00],\n",
       "          [9.1308e-01, 0.0000e+00, 2.4158e-02,  ..., 2.7244e-02,\n",
       "           9.9656e-01, 1.4405e+00]],\n",
       "\n",
       "         [[5.7215e-02, 5.8914e-01, 1.1274e-01,  ..., 0.0000e+00,\n",
       "           5.4497e-02, 2.2801e-01],\n",
       "          [0.0000e+00, 4.1472e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           7.3322e-03, 1.3992e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.1256e-01,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           3.4883e-02, 0.0000e+00],\n",
       "          [3.1722e-01, 2.0288e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           3.7629e-02, 7.4656e-02],\n",
       "          [4.1161e-01, 1.3167e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           1.7318e-01, 0.0000e+00]],\n",
       "\n",
       "         [[0.0000e+00, 6.5743e-01, 4.7137e-01,  ..., 0.0000e+00,\n",
       "           1.9133e-01, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [3.0961e-01, 2.6557e-01, 0.0000e+00,  ..., 2.4768e-02,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 2.6029e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           9.0408e-02, 0.0000e+00],\n",
       "          [8.5324e-02, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[7.2286e-02, 0.0000e+00, 0.0000e+00,  ..., 1.1797e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 7.5408e-01,  ..., 3.4858e-01,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 0.0000e+00, 9.8053e-01,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 1.0079e+00],\n",
       "          [0.0000e+00, 1.0100e-02, 9.1328e-01,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 8.9575e-01],\n",
       "          [0.0000e+00, 4.6318e-01, 2.9146e-01,  ..., 1.0565e+00,\n",
       "           1.0645e+00, 0.0000e+00]],\n",
       "\n",
       "         [[1.5494e-01, 1.1426e-01, 2.6436e-01,  ..., 1.3663e-01,\n",
       "           2.1761e-01, 2.0321e-01],\n",
       "          [3.3628e-01, 3.5177e-01, 2.6546e-01,  ..., 1.9712e-01,\n",
       "           1.6798e-01, 1.6164e-01],\n",
       "          [3.5153e-01, 4.5887e-01, 1.9546e-01,  ..., 7.2719e-02,\n",
       "           1.4273e-01, 2.2822e-01],\n",
       "          ...,\n",
       "          [4.2785e-01, 1.5539e-01, 3.0596e-01,  ..., 2.2177e-01,\n",
       "           2.1443e-01, 1.0424e-01],\n",
       "          [2.7623e-01, 2.2435e-01, 5.6603e-01,  ..., 1.3362e-01,\n",
       "           6.5187e-02, 1.0215e-03],\n",
       "          [2.6282e-01, 1.1075e-01, 1.1521e-01,  ..., 2.4251e-01,\n",
       "           5.0851e-02, 5.8691e-02]],\n",
       "\n",
       "         [[0.0000e+00, 2.3326e-01, 6.9607e-01,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 7.8015e-01, 3.8207e-01,  ..., 2.7335e-01,\n",
       "           2.9417e-02, 0.0000e+00],\n",
       "          [2.4071e-01, 6.6014e-01, 1.4593e-01,  ..., 1.0149e-01,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [8.5982e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 1.3460e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 2.1542e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [2.8952e-01, 4.2721e-01, 5.6952e-02,  ..., 8.1799e-01,\n",
       "           1.2235e-01, 1.0549e-01]]],\n",
       "\n",
       "\n",
       "        [[[7.6778e-01, 0.0000e+00, 1.2821e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 5.2051e-01],\n",
       "          [0.0000e+00, 8.7761e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           3.7397e-01, 7.0237e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 1.2876e-01],\n",
       "          ...,\n",
       "          [5.9210e-01, 0.0000e+00, 0.0000e+00,  ..., 3.1728e-01,\n",
       "           6.0077e-01, 0.0000e+00],\n",
       "          [0.0000e+00, 1.6553e+00, 2.9213e-02,  ..., 4.0167e-01,\n",
       "           1.0004e+00, 1.0478e+00],\n",
       "          [6.6195e-01, 2.4120e-01, 6.8291e-02,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 3.6082e-01]],\n",
       "\n",
       "         [[1.2363e-01, 3.4389e-02, 0.0000e+00,  ..., 1.9862e-01,\n",
       "           1.9692e-03, 1.6070e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 9.0899e-02],\n",
       "          [1.2761e-02, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 8.2179e-03, 9.6024e-02,  ..., 6.7234e-02,\n",
       "           2.9390e-01, 2.6358e-01],\n",
       "          [1.5473e-01, 4.1094e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[6.7295e-02, 4.4022e-02, 7.2434e-01,  ..., 7.6025e-01,\n",
       "           0.0000e+00, 6.2187e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           2.1593e-02, 0.0000e+00],\n",
       "          [9.8802e-02, 1.8070e-02, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.0000e+00, 1.0094e+00, 1.8857e-02,  ..., 1.3419e-01,\n",
       "           0.0000e+00, 2.1985e+00],\n",
       "          [0.0000e+00, 1.8186e-01, 8.0753e-01,  ..., 6.1418e-03,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 4.4559e-01, 5.8932e-01,  ..., 4.7356e-01,\n",
       "           0.0000e+00, 5.2468e-01],\n",
       "          ...,\n",
       "          [0.0000e+00, 0.0000e+00, 1.2628e-01,  ..., 3.9997e-03,\n",
       "           4.7514e-01, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.1714e-01,\n",
       "           2.9654e-01, 5.9914e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 1.3618e+00,  ..., 1.1558e+00,\n",
       "           9.0987e-02, 4.9707e-01]],\n",
       "\n",
       "         [[2.3750e-01, 6.1613e-02, 1.9323e-01,  ..., 1.3049e-01,\n",
       "           2.8700e-01, 6.4280e-02],\n",
       "          [1.7762e-01, 1.5240e-01, 3.9060e-01,  ..., 2.3442e-01,\n",
       "           3.2669e-01, 7.7356e-02],\n",
       "          [1.2746e-01, 3.0213e-01, 2.1284e-01,  ..., 1.7982e-01,\n",
       "           1.7067e-01, 1.0200e-01],\n",
       "          ...,\n",
       "          [4.0557e-01, 1.6124e-01, 9.4807e-01,  ..., 7.5167e-02,\n",
       "           1.5785e-01, 9.3549e-02],\n",
       "          [3.5589e-01, 8.0058e-01, 3.7291e-01,  ..., 2.1593e-02,\n",
       "           9.4124e-02, 0.0000e+00],\n",
       "          [1.3593e-01, 1.2900e-01, 4.3932e-01,  ..., 5.0796e-01,\n",
       "           2.1442e-01, 9.2758e-02]],\n",
       "\n",
       "         [[5.5982e-01, 6.4729e-01, 2.8872e-01,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 4.6814e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 5.9426e-01,\n",
       "           6.7377e-02, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 4.2214e-01,\n",
       "           7.7521e-01, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.1823e+00,\n",
       "           3.3741e-01, 7.7158e-01],\n",
       "          [4.8813e-01, 9.6347e-01, 3.6555e-01,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 2.3859e-01],\n",
       "          [2.7942e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]]]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_shard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[8.5445e-01, 1.0418e-02, 2.2933e-03,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 1.0321e-01],\n",
       "          [1.4065e-01, 0.0000e+00, 0.0000e+00,  ..., 7.5085e-01,\n",
       "           7.7745e-02, 1.2300e+00],\n",
       "          [0.0000e+00, 3.7654e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [2.0328e-01, 8.4154e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 2.0143e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.2478e+00,\n",
       "           9.3016e-01, 9.0557e-01],\n",
       "          [9.0711e-01, 9.7260e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           9.4678e-02, 2.4047e-02]],\n",
       "\n",
       "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 2.3810e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 3.1409e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 8.9930e-02],\n",
       "          ...,\n",
       "          [1.1089e-02, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [4.5487e-01, 1.6325e-01, 6.3373e-02,  ..., 3.4063e-02,\n",
       "           1.0447e-01, 0.0000e+00],\n",
       "          [1.5503e-01, 6.8088e-02, 2.0863e-02,  ..., 0.0000e+00,\n",
       "           1.2780e-02, 0.0000e+00]],\n",
       "\n",
       "         [[0.0000e+00, 4.3047e-01, 8.3589e-01,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 3.7993e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           9.2340e-03, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [6.0738e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           1.1521e-01, 0.0000e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.0000e+00, 2.0630e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [2.0867e-01, 4.3076e-02, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           1.0204e-01, 0.0000e+00],\n",
       "          [7.5397e-01, 8.7089e-01, 0.0000e+00,  ..., 8.0394e-02,\n",
       "           1.2460e+00, 5.3680e-01],\n",
       "          ...,\n",
       "          [3.4957e-01, 0.0000e+00, 1.0840e-01,  ..., 4.8696e-01,\n",
       "           9.4255e-01, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           1.4721e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 3.4186e-01,  ..., 0.0000e+00,\n",
       "           5.3203e-01, 0.0000e+00]],\n",
       "\n",
       "         [[2.5923e-01, 1.7395e-01, 2.3232e-01,  ..., 1.6652e-01,\n",
       "           7.1863e-02, 7.5029e-02],\n",
       "          [4.1327e-01, 2.9681e-01, 4.3982e-01,  ..., 2.4188e-02,\n",
       "           0.0000e+00, 1.2454e-02],\n",
       "          [3.0207e-01, 1.2444e-01, 1.8848e-01,  ..., 2.1243e-01,\n",
       "           1.5597e-01, 1.5369e-01],\n",
       "          ...,\n",
       "          [3.0575e-01, 1.6771e-01, 2.2010e-01,  ..., 9.2646e-02,\n",
       "           1.5017e-01, 1.2451e-01],\n",
       "          [2.4401e-01, 6.5059e-02, 2.0340e-01,  ..., 8.0156e-03,\n",
       "           2.3731e-01, 1.0779e-01],\n",
       "          [2.3781e-01, 2.0858e-01, 3.1462e-01,  ..., 1.7653e-01,\n",
       "           2.5740e-01, 1.2708e-01]],\n",
       "\n",
       "         [[3.3204e-01, 5.0805e-01, 6.6381e-01,  ..., 5.3894e-01,\n",
       "           6.7283e-02, 2.5847e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 6.1693e-01,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           4.2376e-01, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.4044e-01,\n",
       "           8.9860e-01, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 2.2886e+00,  ..., 0.0000e+00,\n",
       "           1.3565e+00, 4.6619e-01],\n",
       "          [0.0000e+00, 1.0710e+00, 1.1727e+00,  ..., 3.0938e-01,\n",
       "           1.2527e+00, 5.3815e-01]]],\n",
       "\n",
       "\n",
       "        [[[6.2456e-03, 4.5905e-02, 5.4408e-01,  ..., 7.1423e-02,\n",
       "           2.3862e-01, 2.6221e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 2.1754e-01,  ..., 0.0000e+00,\n",
       "           4.4719e-01, 0.0000e+00],\n",
       "          [1.1823e+00, 0.0000e+00, 7.8641e-01,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 6.9786e-01],\n",
       "          ...,\n",
       "          [1.1557e+00, 5.4498e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 7.0469e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           3.7926e-01, 4.7308e-02],\n",
       "          [6.3920e-01, 1.3680e-01, 4.5467e-01,  ..., 0.0000e+00,\n",
       "           2.6770e-02, 0.0000e+00]],\n",
       "\n",
       "         [[0.0000e+00, 0.0000e+00, 2.3959e-02,  ..., 1.6746e-01,\n",
       "           0.0000e+00, 9.4686e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 1.0514e-01,  ..., 1.0947e-01,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 1.0330e-02, 1.3795e-01,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 6.3974e-02],\n",
       "          [8.4053e-02, 1.0285e-01, 2.3631e-01,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 2.5191e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           2.4209e-01, 4.9070e-01]],\n",
       "\n",
       "         [[3.6395e-02, 0.0000e+00, 0.0000e+00,  ..., 4.9220e-01,\n",
       "           6.2120e-01, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 0.0000e+00, 9.6000e-02,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.0000e+00, 4.9438e-01, 0.0000e+00,  ..., 1.3130e-01,\n",
       "           6.3582e-01, 3.5638e-01],\n",
       "          [0.0000e+00, 3.1481e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 8.8891e-01, 0.0000e+00,  ..., 1.3146e-01,\n",
       "           0.0000e+00, 6.2893e-01],\n",
       "          ...,\n",
       "          [4.1316e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           1.5916e-01, 2.3717e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 9.7938e-01,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [1.1856e+00, 5.7738e-01, 1.2133e+00,  ..., 1.3673e+00,\n",
       "           9.1021e-01, 0.0000e+00]],\n",
       "\n",
       "         [[4.0638e-01, 2.5139e-01, 3.0593e-01,  ..., 2.5483e-01,\n",
       "           1.5868e-01, 1.8937e-01],\n",
       "          [2.9217e-01, 9.3835e-02, 9.4571e-02,  ..., 4.2526e-01,\n",
       "           3.2156e-01, 2.1841e-01],\n",
       "          [3.9160e-01, 1.7009e-01, 2.9892e-01,  ..., 3.8797e-01,\n",
       "           1.6239e+00, 2.1123e-01],\n",
       "          ...,\n",
       "          [3.7832e-01, 4.1018e-02, 6.9119e-02,  ..., 7.0999e-01,\n",
       "           4.7643e-01, 1.0927e-02],\n",
       "          [1.8997e-01, 0.0000e+00, 0.0000e+00,  ..., 1.6990e-01,\n",
       "           6.9892e-02, 6.3697e-02],\n",
       "          [3.7454e-01, 2.0130e-01, 1.3944e-01,  ..., 2.6104e-01,\n",
       "           1.4413e-01, 9.7538e-02]],\n",
       "\n",
       "         [[0.0000e+00, 0.0000e+00, 6.6454e-01,  ..., 1.5133e-01,\n",
       "           2.7557e-01, 0.0000e+00],\n",
       "          [3.5523e-01, 0.0000e+00, 1.6617e-01,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [2.4437e-01, 0.0000e+00, 2.9925e-01,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 1.3721e-01],\n",
       "          ...,\n",
       "          [7.2344e-03, 4.9452e-01, 1.8844e+00,  ..., 0.0000e+00,\n",
       "           2.2771e-01, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 2.5604e-01]]],\n",
       "\n",
       "\n",
       "        [[[7.7200e-01, 1.6798e+00, 0.0000e+00,  ..., 1.1432e-02,\n",
       "           4.1016e-01, 6.0844e-01],\n",
       "          [1.3692e+00, 0.0000e+00, 2.5361e-01,  ..., 0.0000e+00,\n",
       "           1.3192e-01, 0.0000e+00],\n",
       "          [5.6669e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           1.0551e-01, 0.0000e+00],\n",
       "          ...,\n",
       "          [2.5295e-02, 0.0000e+00, 5.6670e-03,  ..., 1.1882e+00,\n",
       "           0.0000e+00, 4.3266e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 6.2499e-01,  ..., 0.0000e+00,\n",
       "           2.8328e-01, 1.3586e-02],\n",
       "          [0.0000e+00, 1.1030e+00, 2.1997e-01,  ..., 0.0000e+00,\n",
       "           1.1052e+00, 1.5926e+00]],\n",
       "\n",
       "         [[0.0000e+00, 1.2666e-01, 3.5022e-01,  ..., 1.3167e-01,\n",
       "           9.8579e-02, 7.1410e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3266e-02,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 4.4572e-01],\n",
       "          [4.9981e-02, 6.0419e-02, 3.8916e-02,  ..., 6.8659e-02,\n",
       "           3.8691e-02, 2.2388e-01],\n",
       "          [0.0000e+00, 6.8079e-02, 9.9755e-03,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 3.9040e-02]],\n",
       "\n",
       "         [[6.4427e-01, 7.0519e-02, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           4.5187e-02, 1.2355e-01],\n",
       "          [1.1901e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 1.0845e-01,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 4.2318e-02,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 4.4751e-01,\n",
       "           4.2523e-01, 7.0595e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 9.0877e-01,\n",
       "           1.1888e+00, 1.7118e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 9.0646e-03,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 1.3067e+00, 9.6913e-02,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 3.3281e-02, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           2.4427e-01, 7.2747e-01],\n",
       "          [0.0000e+00, 5.8038e-01, 0.0000e+00,  ..., 1.1378e+00,\n",
       "           9.4370e-01, 4.0943e-01]],\n",
       "\n",
       "         [[2.4910e-01, 1.6208e-01, 2.8021e-01,  ..., 1.5068e-01,\n",
       "           1.8523e-01, 1.7600e-01],\n",
       "          [1.4327e-01, 0.0000e+00, 2.4173e-01,  ..., 2.7221e-01,\n",
       "           2.6570e-01, 2.1178e-01],\n",
       "          [1.9606e-01, 7.3728e-02, 3.0380e-01,  ..., 1.1234e+00,\n",
       "           2.9438e-01, 3.0083e-01],\n",
       "          ...,\n",
       "          [2.8982e-01, 1.5000e-01, 2.3888e-01,  ..., 1.2659e-01,\n",
       "           7.5866e-02, 8.1103e-02],\n",
       "          [2.4884e-01, 2.1275e-01, 1.7285e-01,  ..., 9.5810e-02,\n",
       "           1.5089e-01, 1.4121e-01],\n",
       "          [2.0444e-01, 8.7551e-02, 1.2509e-01,  ..., 0.0000e+00,\n",
       "           1.5970e-02, 0.0000e+00]],\n",
       "\n",
       "         [[8.5626e-02, 0.0000e+00, 0.0000e+00,  ..., 1.4019e-01,\n",
       "           8.4129e-01, 0.0000e+00],\n",
       "          [5.5095e-01, 3.2418e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 1.1222e+00, 7.7462e-01,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 8.6158e-01],\n",
       "          ...,\n",
       "          [0.0000e+00, 0.0000e+00, 2.8546e-01,  ..., 9.6533e-02,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 7.6948e-02, 0.0000e+00,  ..., 1.2147e+00,\n",
       "           2.2911e-01, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 7.3134e-02]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0.0000e+00, 8.7409e-02, 1.8123e+00,  ..., 0.0000e+00,\n",
       "           2.6792e-01, 8.2157e-01],\n",
       "          [9.8919e-01, 2.2812e-01, 0.0000e+00,  ..., 5.7845e-01,\n",
       "           4.1844e-01, 8.6389e-01],\n",
       "          [3.2661e-01, 0.0000e+00, 0.0000e+00,  ..., 9.4642e-02,\n",
       "           0.0000e+00, 1.2117e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 1.3681e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           1.0919e+00, 0.0000e+00],\n",
       "          [4.3509e-02, 0.0000e+00, 3.3898e-01,  ..., 0.0000e+00,\n",
       "           7.8853e-01, 0.0000e+00],\n",
       "          [8.0936e-01, 6.6300e-01, 3.9403e-01,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 1.7974e-01]],\n",
       "\n",
       "         [[3.9357e-01, 8.9203e-02, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           2.6838e-01, 3.5872e-01],\n",
       "          [0.0000e+00, 2.5165e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           2.3059e-01, 1.6851e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           7.6091e-02, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 0.0000e+00, 2.0723e-01,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 4.3304e-01],\n",
       "          [1.4086e-01, 0.0000e+00, 0.0000e+00,  ..., 6.4797e-02,\n",
       "           2.8580e-01, 4.0076e-01],\n",
       "          [2.7228e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           1.0320e-01, 1.8390e-01]],\n",
       "\n",
       "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 5.9118e-01,\n",
       "           1.1724e-02, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 1.6908e-02,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.0000e+00, 0.0000e+00, 2.2838e-01,  ..., 7.3119e-01,\n",
       "           0.0000e+00, 1.7154e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 4.0971e-01,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [1.7363e-01, 0.0000e+00, 0.0000e+00,  ..., 3.4660e-01,\n",
       "           0.0000e+00, 5.2885e-01],\n",
       "          ...,\n",
       "          [4.3759e-01, 0.0000e+00, 0.0000e+00,  ..., 5.0856e-01,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [4.5721e-01, 0.0000e+00, 2.9859e-01,  ..., 3.3806e-01,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 3.5533e-01, 0.0000e+00,  ..., 1.1364e+00,\n",
       "           0.0000e+00, 8.6170e-01]],\n",
       "\n",
       "         [[1.1982e-01, 3.7045e-02, 3.9659e-01,  ..., 3.7311e-01,\n",
       "           2.4967e-02, 1.3648e-01],\n",
       "          [2.6537e-01, 2.8489e-02, 2.7645e-01,  ..., 1.5322e-01,\n",
       "           1.9086e-02, 7.7718e-02],\n",
       "          [2.1761e-01, 8.7883e-02, 3.6987e-01,  ..., 2.8807e-01,\n",
       "           1.4463e-01, 1.8451e-01],\n",
       "          ...,\n",
       "          [4.7619e-02, 7.3415e-02, 3.1608e-01,  ..., 2.5922e-01,\n",
       "           3.4840e-01, 0.0000e+00],\n",
       "          [1.5041e-01, 8.8719e-02, 1.7228e-01,  ..., 1.3857e-01,\n",
       "           1.8315e-01, 0.0000e+00],\n",
       "          [1.3909e-01, 6.2694e-01, 9.2505e-02,  ..., 2.7674e-01,\n",
       "           3.1841e-02, 0.0000e+00]],\n",
       "\n",
       "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.2087e-01,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [1.8061e-01, 0.0000e+00, 0.0000e+00,  ..., 5.1077e-02,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [8.5034e-01, 8.7225e-01, 0.0000e+00,  ..., 1.7894e-01,\n",
       "           6.7994e-01, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 0.0000e+00, 5.4185e-01,  ..., 2.7242e-01,\n",
       "           3.1067e-04, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 6.3675e-01,  ..., 3.7345e-01,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 5.9095e-01, 4.6144e-02,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]]],\n",
       "\n",
       "\n",
       "        [[[0.0000e+00, 0.0000e+00, 1.2157e+00,  ..., 6.2755e-01,\n",
       "           1.3215e-01, 1.3445e-01],\n",
       "          [8.6409e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           5.7571e-02, 5.7037e-01],\n",
       "          [1.0818e+00, 0.0000e+00, 2.5199e-02,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 8.9625e-01, 0.0000e+00,  ..., 2.2039e-02,\n",
       "           7.9619e-03, 1.2406e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 1.1194e+00],\n",
       "          [9.1308e-01, 0.0000e+00, 2.4158e-02,  ..., 2.7244e-02,\n",
       "           9.9656e-01, 1.4405e+00]],\n",
       "\n",
       "         [[5.7215e-02, 5.8914e-01, 1.1274e-01,  ..., 0.0000e+00,\n",
       "           5.4497e-02, 2.2801e-01],\n",
       "          [0.0000e+00, 4.1472e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           7.3322e-03, 1.3992e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.1256e-01,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           3.4883e-02, 0.0000e+00],\n",
       "          [3.1722e-01, 2.0288e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           3.7629e-02, 7.4656e-02],\n",
       "          [4.1161e-01, 1.3167e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           1.7318e-01, 0.0000e+00]],\n",
       "\n",
       "         [[0.0000e+00, 6.5743e-01, 4.7137e-01,  ..., 0.0000e+00,\n",
       "           1.9133e-01, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [3.0961e-01, 2.6557e-01, 0.0000e+00,  ..., 2.4768e-02,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 2.6029e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           9.0408e-02, 0.0000e+00],\n",
       "          [8.5324e-02, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[7.2286e-02, 0.0000e+00, 0.0000e+00,  ..., 1.1797e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 7.5408e-01,  ..., 3.4858e-01,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 0.0000e+00, 9.8053e-01,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 1.0079e+00],\n",
       "          [0.0000e+00, 1.0100e-02, 9.1328e-01,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 8.9575e-01],\n",
       "          [0.0000e+00, 4.6318e-01, 2.9146e-01,  ..., 1.0565e+00,\n",
       "           1.0645e+00, 0.0000e+00]],\n",
       "\n",
       "         [[1.5494e-01, 1.1426e-01, 2.6436e-01,  ..., 1.3663e-01,\n",
       "           2.1761e-01, 2.0321e-01],\n",
       "          [3.3628e-01, 3.5177e-01, 2.6546e-01,  ..., 1.9712e-01,\n",
       "           1.6798e-01, 1.6164e-01],\n",
       "          [3.5153e-01, 4.5887e-01, 1.9546e-01,  ..., 7.2719e-02,\n",
       "           1.4273e-01, 2.2822e-01],\n",
       "          ...,\n",
       "          [4.2785e-01, 1.5539e-01, 3.0596e-01,  ..., 2.2177e-01,\n",
       "           2.1443e-01, 1.0424e-01],\n",
       "          [2.7623e-01, 2.2435e-01, 5.6603e-01,  ..., 1.3362e-01,\n",
       "           6.5187e-02, 1.0215e-03],\n",
       "          [2.6282e-01, 1.1075e-01, 1.1521e-01,  ..., 2.4251e-01,\n",
       "           5.0851e-02, 5.8691e-02]],\n",
       "\n",
       "         [[0.0000e+00, 2.3326e-01, 6.9607e-01,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 7.8015e-01, 3.8207e-01,  ..., 2.7335e-01,\n",
       "           2.9417e-02, 0.0000e+00],\n",
       "          [2.4071e-01, 6.6014e-01, 1.4593e-01,  ..., 1.0149e-01,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [8.5982e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 1.3460e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 2.1542e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [2.8952e-01, 4.2721e-01, 5.6952e-02,  ..., 8.1799e-01,\n",
       "           1.2235e-01, 1.0549e-01]]],\n",
       "\n",
       "\n",
       "        [[[7.6778e-01, 0.0000e+00, 1.2821e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 5.2051e-01],\n",
       "          [0.0000e+00, 8.7761e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           3.7397e-01, 7.0237e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 1.2876e-01],\n",
       "          ...,\n",
       "          [5.9210e-01, 0.0000e+00, 0.0000e+00,  ..., 3.1728e-01,\n",
       "           6.0077e-01, 0.0000e+00],\n",
       "          [0.0000e+00, 1.6553e+00, 2.9213e-02,  ..., 4.0167e-01,\n",
       "           1.0004e+00, 1.0478e+00],\n",
       "          [6.6195e-01, 2.4120e-01, 6.8291e-02,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 3.6082e-01]],\n",
       "\n",
       "         [[1.2363e-01, 3.4389e-02, 0.0000e+00,  ..., 1.9862e-01,\n",
       "           1.9692e-03, 1.6070e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 9.0899e-02],\n",
       "          [1.2761e-02, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 8.2179e-03, 9.6024e-02,  ..., 6.7234e-02,\n",
       "           2.9390e-01, 2.6358e-01],\n",
       "          [1.5473e-01, 4.1094e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[6.7295e-02, 4.4022e-02, 7.2434e-01,  ..., 7.6025e-01,\n",
       "           0.0000e+00, 6.2187e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           2.1593e-02, 0.0000e+00],\n",
       "          [9.8802e-02, 1.8070e-02, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.0000e+00, 1.0094e+00, 1.8857e-02,  ..., 1.3419e-01,\n",
       "           0.0000e+00, 2.1985e+00],\n",
       "          [0.0000e+00, 1.8186e-01, 8.0753e-01,  ..., 6.1418e-03,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 4.4559e-01, 5.8932e-01,  ..., 4.7356e-01,\n",
       "           0.0000e+00, 5.2468e-01],\n",
       "          ...,\n",
       "          [0.0000e+00, 0.0000e+00, 1.2628e-01,  ..., 3.9997e-03,\n",
       "           4.7514e-01, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.1714e-01,\n",
       "           2.9654e-01, 5.9914e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 1.3618e+00,  ..., 1.1558e+00,\n",
       "           9.0987e-02, 4.9707e-01]],\n",
       "\n",
       "         [[2.3750e-01, 6.1613e-02, 1.9323e-01,  ..., 1.3049e-01,\n",
       "           2.8700e-01, 6.4280e-02],\n",
       "          [1.7762e-01, 1.5240e-01, 3.9060e-01,  ..., 2.3442e-01,\n",
       "           3.2669e-01, 7.7356e-02],\n",
       "          [1.2746e-01, 3.0213e-01, 2.1284e-01,  ..., 1.7982e-01,\n",
       "           1.7067e-01, 1.0200e-01],\n",
       "          ...,\n",
       "          [4.0557e-01, 1.6124e-01, 9.4807e-01,  ..., 7.5167e-02,\n",
       "           1.5785e-01, 9.3549e-02],\n",
       "          [3.5589e-01, 8.0058e-01, 3.7291e-01,  ..., 2.1593e-02,\n",
       "           9.4124e-02, 0.0000e+00],\n",
       "          [1.3593e-01, 1.2900e-01, 4.3932e-01,  ..., 5.0796e-01,\n",
       "           2.1442e-01, 9.2758e-02]],\n",
       "\n",
       "         [[5.5982e-01, 6.4729e-01, 2.8872e-01,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 4.6814e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 5.9426e-01,\n",
       "           6.7377e-02, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 4.2214e-01,\n",
       "           7.7521e-01, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.1823e+00,\n",
       "           3.3741e-01, 7.7158e-01],\n",
       "          [4.8813e-01, 9.6347e-01, 3.6555e-01,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 2.3859e-01],\n",
       "          [2.7942e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]]]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = (3, 224, 224)  # (channels, height, width)\n",
    "input_tensor = torch.randn(1, *input_size)  # Batch size of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 7, 7])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_part1.eval()\n",
    "model_part2.eval()\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad(): \n",
    "    output_shard = model_part1.forward([input_tensor, input_tensor])\n",
    "    output_shard = model_part2.forward(output_shard)[1]\n",
    "    # output_shard = model_part1.layers[3].forward(output_shard)[1]\n",
    "    output_origin = model(input_tensor)\n",
    "\n",
    "torch.all(output_shard.eq(output_origin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(True)\n",
      "1 tensor(True)\n",
      "2 tensor(True)\n",
      "3 tensor(True)\n",
      "4 tensor(True)\n",
      "5 tensor(True)\n",
      "6 tensor(True)\n",
      "7 tensor(True)\n",
      "8 tensor(True)\n",
      "9 tensor(True)\n",
      "10 tensor(True)\n",
      "11 tensor(True)\n",
      "12 tensor(True)\n",
      "13 tensor(True)\n",
      "14 tensor(True)\n",
      "15 tensor(True)\n",
      "16 tensor(True)\n",
      "17 tensor(True)\n",
      "18 tensor(True)\n",
      "19 tensor(True)\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    model_part1_shard_config = ModuleShardConfig(layer_start=0, layer_end=i, is_first = True)\n",
    "    model_part2_shard_config = ModuleShardConfig(layer_start=i+1, layer_end=20, is_last = True)\n",
    "\n",
    "    model_part1 = ResNetModelShard(res_config, model_part1_shard_config, model)\n",
    "    model_part2 = ResNetModelShard(res_config, model_part2_shard_config, model)\n",
    "\n",
    "    model_part1.eval()\n",
    "    model_part2.eval()\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad(): \n",
    "        output_shard = model_part1.forward([input_tensor, input_tensor])\n",
    "        output_shard = model_part2.forward(output_shard)[1]\n",
    "        output_origin = model(input_tensor)\n",
    "    print(i, torch.all(output_shard.eq(output_origin)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python runtime.py 0 1 -m torchvision/resnet18 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
=======
   "execution_count": 5,
>>>>>>> e4bd167 (update resnet 34 and 50)
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import Conv2d, BatchNorm2d, ReLU, MaxPool2d\n",
    "import numpy as np\n",
    "from torchvision import models\n",
    "# from .. import ModuleShard, ModuleShardConfig\n",
    "\n",
    "import pdb\n",
    "\n",
    "\n",
    "\"\"\"Models module.\"\"\"\n",
    "from typing import Any, Tuple, Type, Union\n",
    "from torch import nn, Tensor\n",
    "\n",
    "ModuleShardData: Type = Union[Tensor, Tuple[Tensor, ...]]\n",
    "\"\"\"A module shard input/output type.\"\"\"\n",
    "\n",
    "\n",
    "class ModuleShardConfig:\n",
    "    \"\"\"Base class for shard configurations (distinct from model configurations).\"\"\"\n",
    "    # pylint: disable=too-few-public-methods\n",
    "\n",
    "    def __init__(self, **kwargs: dict):\n",
    "        # Attributes with default values\n",
    "        self.layer_start: int = kwargs.pop('layer_start', 0)\n",
    "        self.layer_end: int = kwargs.pop('layer_end', 0)\n",
    "        self.is_first: bool = kwargs.pop('is_first', False)\n",
    "        self.is_last: bool = kwargs.pop('is_last', False)\n",
    "\n",
    "        # Attributes without default values\n",
    "        for key, value in kwargs.items():\n",
    "            setattr(self, key, value)\n",
    "\n",
    "\n",
    "class ModuleShard(nn.Module):\n",
    "    \"\"\"Abstract parent class for module shards.\"\"\"\n",
    "    # pylint: disable=abstract-method\n",
    "\n",
    "    def __init__(self, config: Any, shard_config: ModuleShardConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.shard_config = shard_config\n",
    "\n",
    "    def has_layer(self, layer: int) -> bool:\n",
    "        \"\"\"Check if shard has the specified layer.\"\"\"\n",
    "        return layer in range(self.shard_config.layer_start, self.shard_config.layer_end + 1)\n",
    "\n",
    "\n",
    "def get_microbatch_size(shard_data: ModuleShardData, verify: bool=False):\n",
    "    \"\"\"Get the microbatch size from shard data.\"\"\"\n",
    "    if isinstance(shard_data, Tensor):\n",
    "        shard_data = (shard_data,)\n",
    "    ubatch_size = 0 if len(shard_data) == 0 else len(shard_data[0])\n",
    "    if verify:\n",
    "        # Sanity check that tensors are the same length\n",
    "        for tensor in shard_data:\n",
    "            assert isinstance(tensor, Tensor)\n",
    "            assert len(tensor) == ubatch_size\n",
    "    return ubatch_size\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "\n",
    "class ResnetConfig:\n",
    "    def __init__(self, model=None):\n",
    "        self.name_or_path = ''\n",
    "        self.info = {}\n",
    "        if model:\n",
    "            self.name_or_path = model.__class__.__name__\n",
    "            self.generate_config(model)\n",
    "\n",
    "    def get_layer_info(self, layer):\n",
    "        info = {}\n",
    "        \n",
    "        if isinstance(layer, models.resnet.BasicBlock):\n",
    "            for sub_name, sub_child in layer.named_children():\n",
    "                if sub_name == \"downsample\":\n",
    "                    info[\"downsample_conv\"] = self.get_layer_info(sub_child[0])\n",
    "                    info[\"downsample_bn\"] = self.get_layer_info(sub_child[1])\n",
    "                else:\n",
    "                    info[sub_name] = self.get_layer_info(sub_child)\n",
    "\n",
    "        elif isinstance(layer, nn.Conv2d):\n",
    "            info['in_channels'] = layer.in_channels\n",
    "            info['out_channels'] = layer.out_channels\n",
    "            info['kernel_size'] = layer.kernel_size\n",
    "            info['stride'] = layer.stride\n",
    "            info['padding'] = layer.padding\n",
    "            info['bias'] = layer.bias is not None\n",
    "\n",
    "        elif isinstance(layer, nn.BatchNorm2d):\n",
    "            info['num_features'] = layer.num_features\n",
    "            info['eps'] = layer.eps\n",
    "            info['momentum'] = layer.momentum\n",
    "            info['affine'] = layer.affine\n",
    "            info['track_running_stats'] = layer.track_running_stats\n",
    "\n",
    "        elif isinstance(layer, nn.ReLU):\n",
    "            info['inplace'] = layer.inplace\n",
    "\n",
    "        elif isinstance(layer, nn.MaxPool2d):\n",
    "            info['kernel_size'] = layer.kernel_size\n",
    "            info['stride'] = layer.stride\n",
    "            info['padding'] = layer.padding\n",
    "            info['dilation'] = layer.dilation\n",
    "            info['ceil_mode'] = layer.ceil_mode\n",
    "\n",
    "        elif isinstance(layer, nn.AdaptiveAvgPool2d):\n",
    "            info['output_size'] = layer.output_size\n",
    "\n",
    "        elif isinstance(layer, nn.Linear):\n",
    "            info['in_features'] = layer.in_features\n",
    "            info['out_features'] = layer.out_features\n",
    "            info['bias'] = layer.bias is not None\n",
    "\n",
    "        return info\n",
    "\n",
    "    def generate_config(self, model):\n",
    "        for name, child in model.named_children():\n",
    "            if list(child.children()): \n",
    "                for sub_name, sub_child in child.named_children():\n",
    "                    self.info[f\"{name}_{sub_name}\"] = self.get_layer_info(sub_child)\n",
    "            else:\n",
    "                self.info[name] = self.get_layer_info(child)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        return self.info[key]\n",
    "\n",
    "\n",
    "\n",
    "class ResNetLayerShard(ModuleShard):\n",
    "    def __init__(self, config, shard_config: ModuleShardConfig):\n",
    "        super().__init__(config, shard_config)\n",
    "        self.conv1 = None\n",
    "        self.bn1 = None\n",
    "        self.relu = None\n",
    "        self.conv2 = None\n",
    "        self.bn2 = None\n",
    "        self.downsample_conv = None\n",
    "        self.downsample_bn = None\n",
    "\n",
    "        self._build_shard()\n",
    "\n",
    "    def _build_shard(self):\n",
    "        if self.has_layer(0):\n",
    "            self.conv1 = Conv2d(**self.config[\"conv1\"])\n",
    "            self.bn1 = BatchNorm2d(**self.config[\"bn1\"])\n",
    "            self.relu = ReLU(**self.config['relu'])\n",
    "        if self.has_layer(1):\n",
    "            self.conv2 = Conv2d(**self.config[\"conv2\"])\n",
    "            self.bn2 = BatchNorm2d(**self.config[\"bn2\"])\n",
    "        if self.has_layer(2):\n",
    "            self.downsample_conv = Conv2d(**self.config[\"downsample_conv\"])\n",
    "            self.downsample_bn = BatchNorm2d(**self.config[\"downsample_bn\"])\n",
    "        if self.shard_config.is_last:\n",
    "            self.relu = ReLU(inplace=True)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def forward(self, data_pack):\n",
    "        \"\"\"Compute layer shard.\"\"\"\n",
    "        # pdb.set_trace()\n",
    "        data = data_pack[0]\n",
    "        identity = data_pack[1]\n",
    "        if self.has_layer(0):\n",
    "            data_conv = self.conv1(data)\n",
    "            data_bn = self.bn1(data_conv)\n",
    "            data = self.relu(data_bn)\n",
    "        if self.has_layer(1):\n",
    "            data_conv = self.conv2(data)\n",
    "            data = self.bn2(data_conv)\n",
    "        if self.has_layer(2):\n",
    "            data_conv = self.downsample_conv(identity)\n",
    "            identity = self.downsample_bn(data_conv)\n",
    "        if self.shard_config.is_last:\n",
    "            data += identity\n",
    "            data = self.relu(data)\n",
    "            return data, data\n",
    "        return data, identity\n",
    "    \n",
    "    # For unit test only\n",
    "    def load_weight(self, weight):\n",
    "        if self.has_layer(0):\n",
    "            self.conv1.load_state_dict(weight.conv1.state_dict())\n",
    "            self.bn1.load_state_dict(weight.bn1.state_dict())\n",
    "            self.relu.load_state_dict(weight.relu.state_dict())\n",
    "        if self.has_layer(1):\n",
    "            self.conv2.load_state_dict(weight.conv2.state_dict())\n",
    "            self.bn2.load_state_dict(weight.bn2.state_dict())\n",
    "        if self.has_layer(2):\n",
    "            self.downsample_conv.load_state_dict(weight.downsample[0].state_dict())\n",
    "            self.downsample_bn.load_state_dict(weight.downsample[1].state_dict())\n",
    "\n",
    "class ResNetModelShard(ModuleShard):\n",
    "\n",
    "    def __init__(self, config, shard_config: ModuleShardConfig,\n",
    "                 model_weights):\n",
    "        super().__init__(config, shard_config)\n",
    "        self.conv1 = None\n",
    "        self.bn1 = None\n",
    "        self.relu = None\n",
    "        self.maxpool = None\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "\n",
    "        self.avgpool = None\n",
    "        self.fc = None\n",
    "\n",
    "        logger.debug(\">>>> Model name: %s\", self.config.name_or_path)\n",
    "        if isinstance(model_weights, str):\n",
    "            logger.debug(\">>>> Load weight file: %s\", model_weights)\n",
    "            with np.load(model_weights) as weights:\n",
    "                self._build_shard(weights)\n",
    "        else:\n",
    "            self._build_shard(model_weights)\n",
    "\n",
    "    def _build_shard(self, weights):\n",
    "        if self.shard_config.is_first:\n",
    "            logger.debug(\">>>> Load embeddings layer for the first shard\")\n",
    "            self.conv1 = Conv2d(**self.config['conv1'])\n",
    "            self.bn1 = BatchNorm2d(**self.config['bn1'])\n",
    "            self.relu = ReLU(**self.config['relu'])\n",
    "            self.maxpool = MaxPool2d(**self.config['maxpool'])\n",
    "            self._load_weights_first(weights)\n",
    "\n",
    "        layer_curr = self.shard_config.layer_start - 1\n",
    "        layer_end = self.shard_config.layer_end - 1\n",
    "        while layer_curr <= (layer_end - 1 if self.shard_config.is_last else layer_end):\n",
    "\n",
    "            if layer_end != 0:\n",
    "                layer_id = layer_curr // 5 + 1\n",
    "                layer_sub_id = layer_curr  %5 // 3\n",
    "                \n",
    "\n",
    "                if layer_sub_id == 0:\n",
    "                    if layer_id ==1:\n",
    "                        layer_curr = max(1, layer_curr)\n",
    "                        sublayer_start = (layer_curr - 1) % 2\n",
    "                        if layer_end > 2:\n",
    "                            sublayer_end = 1\n",
    "                        else:\n",
    "                            sublayer_end = layer_end - 1\n",
    "                        sub_layer_is_last = True if sublayer_end == 1 else False\n",
    "\n",
    "                    else:\n",
    "                        sublayer_start = layer_curr % 5 % 3\n",
    "                        if layer_id == layer_end // 5 + 1 and layer_sub_id == layer_end %5 // 3:\n",
    "                            sublayer_end = layer_end % 5 % 3\n",
    "                        else:\n",
    "                            sublayer_end = 2\n",
    "                        sub_layer_is_last = True if sublayer_end == 2 else False\n",
    "                else:\n",
    "                    sublayer_start = layer_curr % 5 % 3\n",
    "                    if layer_id == layer_end // 5 + 1 and layer_sub_id == layer_end %5 // 3:\n",
    "                        sublayer_end = layer_end % 5 % 3\n",
    "                    else:\n",
    "                        sublayer_end = 1\n",
    "                    sub_layer_is_last = True if sublayer_end == 1 else False\n",
    "\n",
    "                sub_layer_is_first = True if sublayer_start == 0 else False\n",
    "\n",
    "\n",
    "                layer_config = ModuleShardConfig(layer_start=sublayer_start, layer_end=sublayer_end\n",
    "                                                ,is_first = sub_layer_is_first, is_last = sub_layer_is_last)\n",
    "                sub_model_config = self.config[f'layer{layer_id}_{layer_sub_id}']\n",
    "                layer = ResNetLayerShard(sub_model_config, layer_config)\n",
    "                self._load_weights_layer(weights.__getattr__(f'layer{layer_id}')[layer_sub_id], layer)\n",
    "                self.layers.append(layer)\n",
    "\n",
    "                layer_curr += sublayer_end - sublayer_start + 1\n",
    "            else:\n",
    "                layer_curr = 1\n",
    "\n",
    "\n",
    "        if self.shard_config.is_last:\n",
    "            logger.debug(\">>>> Load layernorm for the last shard\")\n",
    "            self.avgpool = nn.AdaptiveAvgPool2d(**self.config[\"avgpool\"])\n",
    "            self.fc = nn.Linear(**self.config[\"fc\"])\n",
    "            self._load_weights_last(weights)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _load_weights_first(self, weights):\n",
    "        self.conv1.load_state_dict(weights.conv1.state_dict())\n",
    "        self.bn1.load_state_dict(weights.bn1.state_dict())\n",
    "        self.relu.load_state_dict(weights.relu.state_dict())\n",
    "        self.maxpool.load_state_dict(weights.maxpool.state_dict())\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _load_weights_last(self, weights):\n",
    "        self.avgpool.load_state_dict(weights.avgpool.state_dict())\n",
    "        self.fc.load_state_dict(weights.fc.state_dict())\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _load_weights_layer(self, weights, layer):\n",
    "        if layer.has_layer(0):\n",
    "            layer.conv1.load_state_dict(weights.conv1.state_dict())\n",
    "            layer.bn1.load_state_dict(weights.bn1.state_dict())\n",
    "            layer.relu.load_state_dict(weights.relu.state_dict())\n",
    "        if layer.has_layer(1):\n",
    "            layer.conv2.load_state_dict(weights.conv2.state_dict())\n",
    "            layer.bn2.load_state_dict(weights.bn2.state_dict())\n",
    "        if layer.has_layer(2):\n",
    "            layer.downsample_conv.load_state_dict(weights.downsample[0].state_dict())\n",
    "            layer.downsample_bn.load_state_dict(weights.downsample[1].state_dict())\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def forward(self, data):\n",
    "        \"\"\"Compute shard layers.\"\"\"\n",
    "        # pdb.set_trace()\n",
    "        if self.shard_config.is_first:\n",
    "            data = self.conv1(data)\n",
    "            data = self.bn1(data)\n",
    "            data = self.relu(data)\n",
    "            data = self.maxpool(data)\n",
    "            data = [data, data]\n",
    "        for layer in self.layers:\n",
    "            data = layer(data)\n",
    "        if self.shard_config.is_last:\n",
    "            data = self.avgpool(data[0])\n",
    "            data = torch.flatten(data, 1)\n",
    "            data = self.fc(data)\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import Callable, Optional, Sequence, Tuple, Union\n",
    "import torch\n",
    "from torch.utils.data import Dataset, Subset\n",
    "\n",
    "class RolloverTensorDataset(Dataset[Tuple[torch.Tensor, ...]]):\n",
    "    \"\"\"Like `TensorDataset`, but rolls over when the requested length exceeds the actual length.\"\"\"\n",
    "\n",
    "    def __init__(self, length: int, *tensors: torch.Tensor):\n",
    "        assert all(tensors[0].size(0) == t.size(0) for t in tensors), \\\n",
    "               \"Size mismatch between tensors\"\n",
    "        self.length = length\n",
    "        self.tensors = tensors\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return tuple(t[index % len(t)] for t in self.tensors)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "\n",
    "class DatasetsDataset(Dataset[Tuple]):\n",
    "    \"\"\"Extract values from a `datasets.Dataset` into a tuple.\"\"\"\n",
    "\n",
    "    def __init__(self, dataset: 'datasets.Dataset', keys: Sequence):\n",
    "        self.dataset = dataset\n",
    "        self.keys = keys\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        item = self.dataset[index]\n",
    "        return tuple(item[key] for key in self.keys)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "\n",
    "def load_dataset_subset(dataset: Dataset, indices: Optional[Sequence[int]]=None,\n",
    "                        max_size: Optional[int]=None, shuffle: bool=False) -> Dataset:\n",
    "    \"\"\"Get a Dataset subset.\"\"\"\n",
    "    if indices is None:\n",
    "        indices = list(range(len(dataset)))\n",
    "    if shuffle:\n",
    "        random.shuffle(indices)\n",
    "    if max_size is not None:\n",
    "        indices = indices[:max_size]\n",
    "    return Subset(dataset, indices)\n",
    "\n",
    "\n",
    "# NOTE: We're importing dataset dependencies within functions---rather than at the top level---to\n",
    "#       allow for reduced runtime dependencies on systems that don't need all datasets.\n",
    "\n",
    "\n",
    "def load_dataset_glue(tokenizer: Callable, config: str, split: str, ubatch_size: int,\n",
    "                      tok_padding: Union[bool, str]=True) -> Dataset:\n",
    "    \"\"\"Create a GLUE dataset.\"\"\"\n",
    "    # pylint: disable=import-outside-toplevel\n",
    "    import datasets\n",
    "    # When doing inference in batches (ubatch_size > 1), each item (tokenized sentence) in a batch\n",
    "    # must have the same length, which requires padding shorter sentences in the batch.\n",
    "    # 'transform' only operates on single items, so we'd be forced to use padding='max_length',\n",
    "    # which always forces very long tensors, resulting in slower inference.\n",
    "    # 'map' operates on batches, which allows for per-batch padding optimization.\n",
    "    # 'transform' runs on-the-fly during dataset iteration, 'map' runs in advance and caches data.\n",
    "    def map_function(batch):\n",
    "        \"\"\"Tokenize sentences in microbatches.\"\"\"\n",
    "        # Using return_tensors='pt' requires splitting the tensors afterward.\n",
    "        # Use a numpy array instead, which will be stacked into a single PyTorch tensor later.\n",
    "        encoding = tokenizer(batch['sentence'], padding=tok_padding, truncation=True,\n",
    "                             return_tensors='np')\n",
    "        batch.update(encoding)\n",
    "        return batch\n",
    "    # This datasets.Dataset should be copmatible with a pytorch Dataset\n",
    "    dataset = datasets.load_dataset('glue', name=config, split=split)\n",
    "    dataset = dataset.map(function=map_function, batched=True, batch_size=ubatch_size,\n",
    "                          remove_columns=['sentence'])\n",
    "    dataset.set_format(type='torch')\n",
    "    return DatasetsDataset(dataset, ['input_ids', 'label'])\n",
    "\n",
    "\n",
    "def load_dataset_imagenet(feature_extractor: Callable, root: str, split: str='train') -> Dataset:\n",
    "    \"\"\"Get the ImageNet dataset.\"\"\"\n",
    "    # pylint: disable=import-outside-toplevel\n",
    "    from torchvision.datasets import ImageNet\n",
    "    def transform(img):\n",
    "        pixels = feature_extractor(images=img.convert('RGB'), return_tensors='pt')['pixel_values']\n",
    "        # feature extractor expects a batch but we only have a single image, so drop the outer dim\n",
    "        return pixels[0]\n",
    "    return ImageNet(root, split=split, transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = (3, 224, 224)  # (channels, height, width)\n",
    "input_tensor = torch.randn(1, *input_size)  # Batch size of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "from torchvision import transforms\n",
    "# from utils import data\n",
    "# from .....utils import data\n",
    "IMG_URL = 'https://raw.githubusercontent.com/EliSchwartz/imagenet-sample-images/master/n01440764_tench.JPEG'\n",
    "batch_size = 8\n",
    "\n",
    "feature_extractor = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225]),\n",
    "            transforms.Lambda(lambda x: x.unsqueeze(0))\n",
    "            ])\n",
    "image = Image.open(requests.get(IMG_URL, stream=True, timeout=60).raw)\n",
    "inputs = feature_extractor(image)\n",
    "dataset = RolloverTensorDataset(batch_size, inputs, torch.tensor([486]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_shard_config = ModuleShardConfig(layer_start=1, layer_end=21, is_first = True, is_last = True)\n",
    "model = ResNetModelShard(res_config, model_shard_config, model)\n",
    "model.eval()\n",
    "with torch.no_grad(): \n",
    "    output_origin = model(inputs)[0]\n",
    "output_origin.unsqueeze(0).argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNetModelShard(\n",
       "  (layers): ModuleList(\n",
       "    (0-1): 2 x ResNetLayerShard(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): ResNetLayerShard(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample_conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (downsample_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): ResNetLayerShard(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): ResNetLayerShard(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample_conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (downsample_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): ResNetLayerShard(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): ResNetLayerShard(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample_conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (downsample_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): ResNetLayerShard(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 5.4785e-01,  6.0767e-01,  4.9525e-01,  ...,  3.1966e-01,\n",
      "            3.7639e-01,  3.4041e-01],\n",
      "          [ 3.1502e-01,  2.9043e-01,  2.1980e-01,  ...,  2.3372e-01,\n",
      "            2.6677e-01,  2.5711e-01],\n",
      "          [ 2.1607e-01,  1.9286e-01,  1.8483e-01,  ...,  2.1594e-01,\n",
      "            2.1146e-01,  1.9933e-01],\n",
      "          ...,\n",
      "          [ 2.2650e-01,  1.8304e-01,  1.8294e-01,  ...,  1.9092e-01,\n",
      "            1.8847e-01,  2.0332e-01],\n",
      "          [ 1.8816e-01,  1.9020e-01,  1.9546e-01,  ...,  1.9678e-01,\n",
      "            1.9659e-01,  2.1632e-01],\n",
      "          [ 6.2006e-01,  6.2553e-01,  6.4838e-01,  ...,  5.1130e-01,\n",
      "            4.6739e-01,  3.5566e-01]],\n",
      "\n",
      "         [[ 4.6243e-01,  5.3014e-01,  4.6628e-01,  ...,  3.2082e-01,\n",
      "            3.5502e-01,  3.3672e-01],\n",
      "          [ 2.0611e-01,  3.0179e-01,  2.9773e-01,  ...,  2.6440e-01,\n",
      "            2.9298e-01,  3.2649e-01],\n",
      "          [ 1.6222e-01,  2.1967e-01,  2.5845e-01,  ...,  2.7436e-01,\n",
      "            2.6707e-01,  3.0400e-01],\n",
      "          ...,\n",
      "          [ 1.7248e-01,  2.7545e-01,  2.7617e-01,  ...,  3.3626e-01,\n",
      "            3.1712e-01,  3.6023e-01],\n",
      "          [ 1.4420e-01,  2.5635e-01,  2.8920e-01,  ...,  3.4074e-01,\n",
      "            3.2407e-01,  3.5602e-01],\n",
      "          [ 1.6704e-01,  2.8085e-01,  3.3321e-01,  ...,  3.2911e-01,\n",
      "            3.0826e-01,  3.4273e-01]],\n",
      "\n",
      "         [[-1.0543e-06, -1.0543e-06, -1.0543e-06,  ..., -1.0543e-06,\n",
      "           -1.0543e-06, -1.0543e-06],\n",
      "          [-1.0543e-06, -1.0543e-06, -1.0543e-06,  ..., -1.0543e-06,\n",
      "           -1.0543e-06, -1.0543e-06],\n",
      "          [-1.0543e-06, -1.0543e-06, -1.0543e-06,  ..., -1.0543e-06,\n",
      "           -1.0543e-06, -1.0543e-06],\n",
      "          ...,\n",
      "          [-1.0543e-06, -1.0542e-06, -1.0542e-06,  ..., -1.0542e-06,\n",
      "           -1.0542e-06, -1.0543e-06],\n",
      "          [-1.0543e-06, -1.0542e-06, -1.0542e-06,  ..., -1.0542e-06,\n",
      "           -1.0542e-06, -1.0543e-06],\n",
      "          [-1.0543e-06, -1.0543e-06, -1.0543e-06,  ..., -1.0543e-06,\n",
      "           -1.0543e-06, -1.0543e-06]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.9852e-01,  4.8990e-01,  5.2297e-01,  ...,  5.4178e-01,\n",
      "            5.2872e-01,  5.2980e-01],\n",
      "          [ 4.5539e-01,  4.5360e-01,  5.0304e-01,  ...,  5.1943e-01,\n",
      "            5.0410e-01,  5.1273e-01],\n",
      "          [ 4.6343e-01,  4.7189e-01,  5.2081e-01,  ...,  5.1761e-01,\n",
      "            5.0274e-01,  5.0638e-01],\n",
      "          ...,\n",
      "          [ 3.7623e-01,  3.2979e-01,  3.7355e-01,  ...,  4.2683e-01,\n",
      "            4.3318e-01,  4.5748e-01],\n",
      "          [ 3.8758e-01,  3.4950e-01,  3.9305e-01,  ...,  4.2571e-01,\n",
      "            4.4039e-01,  4.6718e-01],\n",
      "          [ 4.4558e-01,  4.1412e-01,  4.4076e-01,  ...,  4.5946e-01,\n",
      "            4.7248e-01,  5.0131e-01]],\n",
      "\n",
      "         [[-3.8979e-01, -3.3001e-01, -3.5071e-01,  ..., -4.0731e-01,\n",
      "           -3.9049e-01, -3.6604e-01],\n",
      "          [-4.1586e-01, -2.2835e-01, -2.5510e-01,  ..., -3.9963e-01,\n",
      "           -3.7436e-01, -2.9810e-01],\n",
      "          [-4.2569e-01, -2.7534e-01, -3.0464e-01,  ..., -3.8762e-01,\n",
      "           -3.7635e-01, -2.9948e-01],\n",
      "          ...,\n",
      "          [-4.1365e-01, -1.2955e-01, -9.9732e-02,  ..., -2.3400e-01,\n",
      "           -2.3376e-01, -1.8446e-01],\n",
      "          [-4.1695e-01, -1.5500e-01, -1.3577e-01,  ..., -2.0585e-01,\n",
      "           -2.0850e-01, -1.6842e-01],\n",
      "          [-4.0002e-01, -1.5566e-01, -1.2857e-01,  ..., -1.6612e-01,\n",
      "           -1.7848e-01, -1.7470e-01]],\n",
      "\n",
      "         [[ 2.0608e-02,  4.0664e-01,  4.0619e-01,  ...,  2.0216e-01,\n",
      "            2.2275e-01,  2.9965e-01],\n",
      "          [ 1.9568e-01,  4.1386e-01,  3.3802e-01,  ...,  2.2721e-01,\n",
      "            2.3697e-01,  2.8028e-01],\n",
      "          [ 2.7351e-01,  3.8603e-01,  2.0749e-01,  ...,  2.7621e-01,\n",
      "            2.6875e-01,  2.4757e-01],\n",
      "          ...,\n",
      "          [ 1.6126e-01,  4.1306e-01,  3.2675e-01,  ...,  2.5270e-01,\n",
      "            2.4500e-01,  3.1580e-01],\n",
      "          [ 1.8033e-01,  3.1563e-01,  2.7674e-01,  ...,  2.8482e-01,\n",
      "            3.4973e-01,  3.5696e-01],\n",
      "          [ 3.1509e-01,  5.6314e-01,  5.1767e-01,  ...,  5.3589e-01,\n",
      "            4.8318e-01,  4.3045e-01]]]], grad_fn=<NativeBatchNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "        # if self.shard_config.is_first:\n",
    "        #     data = self.conv1(data)\n",
    "        #     data = self.bn1(data)\n",
    "        #     data = self.relu(data)\n",
    "        #     data = self.maxpool(data)\n",
    "        #     data = [data, data]\n",
    "        # for layer in self.layers:\n",
    "        #     data = layer(data)\n",
    "        # if self.shard_config.is_last:\n",
    "        #     data = self.avgpool(data[0])\n",
    "        #     data = torch.flatten(data, 1)\n",
    "        #     data = self.fc(data)\n",
    "\n",
    "data = model.conv1(inputs)\n",
    "\n",
    "data = model.bn1(data)\n",
    "print(data)\n",
    "data = model.relu(data)\n",
    "data = model.maxpool(data)\n",
    "# data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight',\n",
       "              tensor([ 2.3487e-01,  2.6626e-01, -5.1096e-08,  5.1870e-01,  3.4404e-09,\n",
       "                       2.2239e-01,  4.2289e-01,  1.3153e-07,  2.5093e-01,  1.5152e-06,\n",
       "                       3.1687e-01,  2.5049e-01,  3.7893e-01,  1.0862e-05,  2.7526e-01,\n",
       "                       2.3674e-01,  2.4202e-01,  3.9531e-01,  4.6935e-01,  2.9090e-01,\n",
       "                       2.7268e-01,  2.7803e-01,  2.9069e-01,  2.0693e-01,  2.5899e-01,\n",
       "                       2.7871e-01,  2.9115e-01,  3.1601e-01,  3.8889e-01,  3.0411e-01,\n",
       "                       2.6776e-01,  2.1093e-01,  2.8708e-01,  3.3243e-01,  4.2673e-01,\n",
       "                       3.7326e-01,  7.4804e-08,  1.9068e-01,  1.4740e-08,  2.2303e-01,\n",
       "                       1.7908e-01,  2.4860e-01,  2.7400e-01,  2.5923e-01,  2.9420e-01,\n",
       "                       2.9924e-01,  2.2369e-01,  2.6280e-01,  2.2001e-08,  2.6610e-01,\n",
       "                       2.2089e-01,  2.8429e-01,  3.3072e-01,  2.2681e-01,  3.6538e-01,\n",
       "                       2.1230e-01,  2.3965e-01,  2.4950e-01,  5.2583e-01,  2.4825e-01,\n",
       "                       2.9565e-01,  2.5878e-01,  4.8326e-01,  2.6670e-01])),\n",
       "             ('bias',\n",
       "              tensor([ 2.3072e-01,  2.5382e-01, -1.0543e-06, -6.6439e-01, -1.6571e-08,\n",
       "                       1.6152e-01,  4.5450e-01, -4.3020e-07,  3.0051e-01, -8.0052e-06,\n",
       "                       3.4942e-01,  3.1148e-01, -2.4953e-01, -3.4749e-05,  1.0773e-01,\n",
       "                       2.1897e-01,  3.8141e-01, -5.2988e-01, -6.2864e-01,  5.7140e-01,\n",
       "                       2.9985e-01,  5.8430e-01,  4.8202e-01,  3.2853e-01,  1.9672e-01,\n",
       "                       1.9496e-01,  1.5215e-01,  8.5522e-02,  5.1314e-01,  1.5237e-02,\n",
       "                       1.6644e-01,  3.3239e-01,  2.4921e-01,  4.4337e-01, -2.8017e-01,\n",
       "                      -2.0385e-02, -2.4507e-07,  3.2134e-01, -4.9152e-08,  2.3777e-01,\n",
       "                       2.3291e-01,  3.1527e-01,  4.2776e-01,  2.9313e-01,  2.6379e-01,\n",
       "                       6.7598e-01,  4.2910e-01,  3.4566e-01, -8.6909e-08,  2.4729e-01,\n",
       "                       3.0316e-01,  6.1577e-01,  3.9835e-01,  3.3207e-01, -4.1219e-01,\n",
       "                       3.7807e-01,  1.7895e-01,  2.5748e-01, -4.4908e-01,  2.1306e-01,\n",
       "                       5.6934e-01,  5.7274e-01, -4.0238e-01,  2.3406e-01])),\n",
       "             ('running_mean',\n",
       "              tensor([ 2.7681e-03, -2.5769e-02,  2.1254e-07, -8.4605e-02,  2.1121e-08,\n",
       "                       4.9691e-04, -2.2408e-02, -1.1582e-07, -4.8239e-03,  2.7507e-07,\n",
       "                       3.9582e-02,  3.1994e-02, -3.7490e-02, -1.3716e-06,  6.6002e-03,\n",
       "                       4.3782e-03,  6.4797e-02,  1.1176e-01,  3.6002e-02, -7.5075e-02,\n",
       "                      -3.8240e-02,  8.4358e-02, -5.2287e-02, -1.1799e-02,  1.3019e-03,\n",
       "                       3.2172e-02, -1.7784e-02, -9.1009e-02,  1.1319e-01, -4.1632e-02,\n",
       "                       8.7302e-03,  2.9693e-02, -7.0502e-02, -3.4847e-03,  1.0977e-01,\n",
       "                      -1.7341e-03, -5.9423e-08,  2.9330e-02, -7.8553e-09,  6.7320e-03,\n",
       "                      -3.7100e-03,  1.6028e-02, -2.7883e-02,  2.6593e-02,  2.8475e-02,\n",
       "                      -1.2735e-01,  4.4617e-02,  2.6329e-02,  2.1454e-08, -1.7045e-02,\n",
       "                      -3.5617e-03, -4.5841e-02,  6.3876e-02,  1.5220e-02, -3.8511e-02,\n",
       "                      -1.6428e-02, -1.6569e-02,  5.6057e-02, -8.0306e-02, -2.6646e-03,\n",
       "                      -4.1718e-02,  1.2611e-01, -4.9237e-02, -1.3261e-02])),\n",
       "             ('running_var',\n",
       "              tensor([1.0169e+00, 3.7167e+00, 5.8133e-11, 3.2825e+00, 1.7107e-13, 6.5823e-01,\n",
       "                      4.3701e+00, 6.6005e-12, 9.1552e-01, 1.9318e-09, 4.1256e+00, 2.7440e+00,\n",
       "                      2.8391e+00, 4.7966e-08, 1.1072e+01, 5.0075e-01, 2.2313e+00, 4.8257e+00,\n",
       "                      2.6986e+00, 9.3700e+00, 3.7339e+00, 5.4843e+00, 5.7127e+00, 4.4544e-01,\n",
       "                      4.3628e-01, 7.1563e+00, 1.3718e+01, 5.2512e+00, 6.8174e+00, 1.6724e+00,\n",
       "                      1.6534e+00, 1.2325e+00, 4.9076e+00, 3.0731e+00, 4.2384e+00, 4.9936e+00,\n",
       "                      1.4465e-12, 1.5212e+00, 1.0352e-13, 3.5134e-01, 1.7025e-01, 1.4205e+00,\n",
       "                      1.9085e+00, 2.1512e+00, 2.6608e+00, 4.8444e+00, 1.9297e+00, 1.4999e+00,\n",
       "                      2.9481e-13, 1.5306e+00, 3.6503e-01, 2.9376e+00, 5.4664e+00, 7.0792e-01,\n",
       "                      3.3315e+00, 7.7180e-01, 2.4068e+00, 6.5214e+00, 4.1263e+00, 1.0506e+00,\n",
       "                      2.9530e+00, 1.1366e+01, 4.7690e+00, 1.6559e+00])),\n",
       "             ('num_batches_tracked', tensor(0))])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bn1.state_dict(\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bn1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0])\n",
      "1 tensor(True)\n",
      "tensor([0])\n",
      "2 tensor(True)\n",
      "tensor([0])\n",
      "3 tensor(True)\n",
      "tensor([0])\n",
      "4 tensor(True)\n",
      "tensor([0])\n",
      "5 tensor(True)\n",
      "tensor([0])\n",
      "6 tensor(True)\n",
      "tensor([0])\n",
      "7 tensor(True)\n",
      "tensor([0])\n",
      "8 tensor(True)\n",
      "tensor([0])\n",
      "9 tensor(True)\n",
      "tensor([0])\n",
      "10 tensor(True)\n",
      "tensor([0])\n",
      "11 tensor(True)\n",
      "tensor([0])\n",
      "12 tensor(True)\n",
      "tensor([0])\n",
      "13 tensor(True)\n",
      "tensor([0])\n",
      "14 tensor(True)\n",
      "tensor([0])\n",
      "15 tensor(True)\n",
      "tensor([0])\n",
      "16 tensor(True)\n",
      "tensor([0])\n",
      "17 tensor(True)\n",
      "tensor([0])\n",
      "18 tensor(True)\n",
      "tensor([0])\n",
      "19 tensor(True)\n",
      "tensor([0])\n",
      "20 tensor(True)\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,21):\n",
    "    # print(i)\n",
    "    model_part1_shard_config = ModuleShardConfig(layer_start=1, layer_end=i, is_first = True)\n",
    "    model_part2_shard_config = ModuleShardConfig(layer_start=i+1, layer_end=21, is_last = True)\n",
    "\n",
    "    model_part1 = ResNetModelShard(res_config, model_part1_shard_config, model)\n",
    "    model_part2 = ResNetModelShard(res_config, model_part2_shard_config, model)\n",
    "\n",
    "    model_part1.eval()\n",
    "    model_part2.eval()\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad(): \n",
    "        output_shard = model_part1.forward(inputs)\n",
    "        output_shard = model_part2.forward(output_shard)[0]\n",
    "        output_origin = model(inputs)\n",
    "        # print(output_shard.unsqueeze(0).shape, output_origin.shape)\n",
    "    print(output_shard.unsqueeze(0).argmax(dim=1))\n",
    "        # print(output_origin.argmax(dim=1))\n",
    "    print(i, torch.all(output_shard.eq(output_origin)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.8335, -0.8849, -0.8678,  ..., -0.5424, -0.4226, -0.3541],\n",
       "          [-0.7993, -0.7993, -0.7822,  ..., -0.5596, -0.4911, -0.3712],\n",
       "          [-0.8335, -0.8335, -0.7993,  ..., -0.5424, -0.5424, -0.4226],\n",
       "          ...,\n",
       "          [-0.9534, -0.9705, -0.9705,  ..., -0.7650, -0.6794, -0.6452],\n",
       "          [-0.9877, -0.9877, -0.9363,  ..., -0.7479, -0.6452, -0.6109],\n",
       "          [-0.9192, -0.9363, -0.9705,  ..., -0.6965, -0.5938, -0.6281]],\n",
       "\n",
       "         [[-0.4426, -0.5126, -0.4951,  ..., -0.1800, -0.0924, -0.0399],\n",
       "          [-0.4076, -0.4426, -0.4076,  ..., -0.1625, -0.1099, -0.0399],\n",
       "          [-0.4076, -0.4426, -0.3725,  ..., -0.2150, -0.1625, -0.0399],\n",
       "          ...,\n",
       "          [-0.6352, -0.6527, -0.6176,  ..., -0.4076, -0.3725, -0.3200],\n",
       "          [-0.6001, -0.5826, -0.5826,  ..., -0.3725, -0.3375, -0.3025],\n",
       "          [-0.6001, -0.6352, -0.6176,  ..., -0.3375, -0.2850, -0.2850]],\n",
       "\n",
       "         [[-0.3055, -0.4101, -0.3404,  ..., -0.0615,  0.0082,  0.0605],\n",
       "          [-0.2532, -0.3230, -0.2881,  ..., -0.0790, -0.0092,  0.0431],\n",
       "          [-0.2707, -0.2707, -0.2358,  ..., -0.1138, -0.0790,  0.0431],\n",
       "          ...,\n",
       "          [-0.4973, -0.4973, -0.5147,  ..., -0.2707, -0.2358, -0.2010],\n",
       "          [-0.4624, -0.4101, -0.4973,  ..., -0.2184, -0.1661, -0.1835],\n",
       "          [-0.4450, -0.4624, -0.4973,  ..., -0.2010, -0.1138, -0.1835]]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs\n"
   ]
<<<<<<< HEAD
=======
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet34LayerShard(ModuleShard):\n",
    "    def __init__(self, config, shard_config: ModuleShardConfig):\n",
    "        super().__init__(config, shard_config)\n",
    "        self.conv1 = None\n",
    "        self.bn1 = None\n",
    "        self.relu = None\n",
    "        self.conv2 = None\n",
    "        self.bn2 = None\n",
    "        self.downsample_conv = None\n",
    "        self.downsample_bn = None\n",
    "\n",
    "        self._build_shard()\n",
    "\n",
    "    def _build_shard(self):\n",
    "        if self.has_layer(0):\n",
    "            self.conv1 = Conv2d(**self.config[\"conv1\"])\n",
    "            self.bn1 = BatchNorm2d(**self.config[\"bn1\"])\n",
    "            self.relu = ReLU(**self.config['relu'])\n",
    "        if self.has_layer(1):\n",
    "            self.conv2 = Conv2d(**self.config[\"conv2\"])\n",
    "            self.bn2 = BatchNorm2d(**self.config[\"bn2\"])\n",
    "        if self.has_layer(2):\n",
    "            self.downsample_conv = Conv2d(**self.config[\"downsample_conv\"])\n",
    "            self.downsample_bn = BatchNorm2d(**self.config[\"downsample_bn\"])\n",
    "        if self.shard_config.is_last:\n",
    "            self.relu = ReLU(inplace=True)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def forward(self, data_pack):\n",
    "        \"\"\"Compute layer shard.\"\"\"\n",
    "        identity = data_pack[0]\n",
    "        data = data_pack[1]\n",
    "        if self.has_layer(0):\n",
    "            data_conv = self.conv1(data)\n",
    "            data_bn = self.bn1(data_conv)\n",
    "            data = self.relu(data_bn)\n",
    "        if self.has_layer(1):\n",
    "            data_conv = self.conv2(data)\n",
    "            data = self.bn2(data_conv)\n",
    "        if self.has_layer(2):\n",
    "            data_conv = self.downsample_conv(identity)\n",
    "            identity = self.downsample_bn(data_conv)\n",
    "        if self.shard_config.is_last:\n",
    "            data += identity\n",
    "            data = self.relu(data)\n",
    "            return data, data\n",
    "        return [identity, data]\n",
    "    \n",
    "    # For unit test only\n",
    "    def load_weight(self, weight):\n",
    "        if self.has_layer(0):\n",
    "            self.conv1.load_state_dict(weight.conv1.state_dict())\n",
    "            self.bn1.load_state_dict(weight.bn1.state_dict())\n",
    "            self.relu.load_state_dict(weight.relu.state_dict())\n",
    "        if self.has_layer(1):\n",
    "            self.conv2.load_state_dict(weight.conv2.state_dict())\n",
    "            self.bn2.load_state_dict(weight.bn2.state_dict())\n",
    "        if self.has_layer(2):\n",
    "            self.downsample_conv.load_state_dict(weight.downsample[0].state_dict())\n",
    "            self.downsample_bn.load_state_dict(weight.downsample[1].state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetModelShard34(ModuleShard):\n",
    "    def __init__(self, config, shard_config: ModuleShardConfig,\n",
    "                 model_weights):\n",
    "        super().__init__(config, shard_config)\n",
    "        self.conv1 = None\n",
    "        self.bn1 = None\n",
    "        self.relu = None\n",
    "        self.maxpool = None\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "\n",
    "        self.avgpool = None\n",
    "        self.fc = None\n",
    "\n",
    "        self.layer_map = {\n",
    "            1: (2,7),\n",
    "            2: (8,16),\n",
    "            3: (17,29),\n",
    "            4: (30,36)\n",
    "        }\n",
    "\n",
    "        self.block_map = {\n",
    "            1: [2,2,2],\n",
    "            2: [3,2,2,2],\n",
    "            3: [3,2,2,2,2,2],\n",
    "            4: [3,2,2]\n",
    "        }\n",
    "\n",
    "        logger.debug(\">>>> Model name: %s\", self.config.name_or_path)\n",
    "        if isinstance(model_weights, str):\n",
    "            logger.debug(\">>>> Load weight file: %s\", model_weights)\n",
    "            with np.load(model_weights) as weights:\n",
    "                self._build_shard(weights)\n",
    "        else:\n",
    "            self._build_shard(model_weights)\n",
    "\n",
    "\n",
    "\n",
    "    def _build_shard(self, weights):\n",
    "        if self.shard_config.is_first:\n",
    "            logger.debug(\">>>> Load embeddings layer for the first shard\")\n",
    "            self.conv1 = Conv2d(**self.config['conv1'])\n",
    "            self.bn1 = BatchNorm2d(**self.config['bn1'])\n",
    "            self.relu = ReLU(**self.config['relu'])\n",
    "            self.maxpool = MaxPool2d(**self.config['maxpool'])\n",
    "            self._load_weights_first(weights)\n",
    "        if self.shard_config.layer_end > 1 and self.shard_config.layer_start < 37:\n",
    "            layer_curr = 2 if self.shard_config.layer_start == 1 else self.shard_config.layer_start\n",
    "            layer_end = self.shard_config.layer_end\n",
    "            stop_flag = False\n",
    "            # print(layer_curr, layer_end)\n",
    "            for layer_id in self.layer_map:\n",
    "                ori_layer_start = self.layer_map[layer_id][0]\n",
    "                ori_layer_end = self.layer_map[layer_id][1]\n",
    "                # print(layer_id)\n",
    "                if  ori_layer_start <= layer_curr <= ori_layer_end:\n",
    "                    offset =  0\n",
    "                    bb_map = self.block_map[layer_id]\n",
    "                    # print(bb_map)\n",
    "                    for layer_sub_id in range(len(bb_map)):\n",
    "                        basic_block_range = bb_map[layer_sub_id]\n",
    "                        if ori_layer_start + offset <= layer_curr < ori_layer_start + offset + basic_block_range:\n",
    "                            sublayer_start = layer_curr - (ori_layer_start + offset)\n",
    "                            sub_layer_is_first = True if sublayer_start == 0 else False\n",
    "                            if layer_end >= ori_layer_start + offset + basic_block_range-1:\n",
    "                                sublayer_end = basic_block_range - 1\n",
    "                                sub_layer_is_last = True\n",
    "                                if layer_end == ori_layer_start + offset + basic_block_range-1:\n",
    "                                    stop_flag = True\n",
    "                                else:\n",
    "                                    layer_curr = ori_layer_start + offset + basic_block_range \n",
    "                            else:\n",
    "                                sublayer_end = layer_end - (ori_layer_start + offset)\n",
    "                                sub_layer_is_last = False\n",
    "                                layer_curr = layer_end\n",
    "                                stop_flag = True\n",
    "                            layer_config = ModuleShardConfig(layer_start=sublayer_start, layer_end=sublayer_end\n",
    "                                                            ,is_first = sub_layer_is_first, is_last = sub_layer_is_last)\n",
    "                            sub_model_config = self.config[f'layer{layer_id}_{layer_sub_id}']\n",
    "                            layer = ResNetLayerShard(sub_model_config, layer_config)\n",
    "                            self._load_weights_layer(weights.__getattr__(f'layer{layer_id}')[layer_sub_id], layer)\n",
    "                            self.layers.append(layer)\n",
    "                        if stop_flag:\n",
    "                            break\n",
    "                        offset += basic_block_range\n",
    "\n",
    "                    if stop_flag:\n",
    "                        break\n",
    "                if stop_flag:\n",
    "                    break\n",
    "\n",
    "\n",
    "        if self.shard_config.is_last:\n",
    "            logger.debug(\">>>> Load layernorm for the last shard\")\n",
    "            self.avgpool = nn.AdaptiveAvgPool2d(**self.config[\"avgpool\"])\n",
    "            self.fc = nn.Linear(**self.config[\"fc\"])\n",
    "            self._load_weights_last(weights)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _load_weights_first(self, weights):\n",
    "        self.conv1.load_state_dict(weights.conv1.state_dict())\n",
    "        self.bn1.load_state_dict(weights.bn1.state_dict())\n",
    "        self.relu.load_state_dict(weights.relu.state_dict())\n",
    "        self.maxpool.load_state_dict(weights.maxpool.state_dict())\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _load_weights_last(self, weights):\n",
    "        self.avgpool.load_state_dict(weights.avgpool.state_dict())\n",
    "        self.fc.load_state_dict(weights.fc.state_dict())\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _load_weights_layer(self, weights, layer):\n",
    "        if layer.has_layer(0):\n",
    "            layer.conv1.load_state_dict(weights.conv1.state_dict())\n",
    "            layer.bn1.load_state_dict(weights.bn1.state_dict())\n",
    "            layer.relu.load_state_dict(weights.relu.state_dict())\n",
    "        if layer.has_layer(1):\n",
    "            layer.conv2.load_state_dict(weights.conv2.state_dict())\n",
    "            layer.bn2.load_state_dict(weights.bn2.state_dict())\n",
    "        if layer.has_layer(2):\n",
    "            layer.downsample_conv.load_state_dict(weights.downsample[0].state_dict())\n",
    "            layer.downsample_bn.load_state_dict(weights.downsample[1].state_dict())\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def forward(self, data):\n",
    "        \"\"\"Compute shard layers.\"\"\"\n",
    "        # pdb.set_trace()\n",
    "        if self.shard_config.is_first:\n",
    "            data = self.conv1(data)\n",
    "            data = self.bn1(data)\n",
    "            data = self.relu(data)\n",
    "            data = self.maxpool(data)\n",
    "            data = [data, data]\n",
    "        for layer in self.layers:\n",
    "            data = layer(data)\n",
    "        if self.shard_config.is_last:\n",
    "            data = self.avgpool(data[0])\n",
    "            data = torch.flatten(data, 1)\n",
    "            data = self.fc(data)\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conv1': {'in_channels': 3,\n",
       "  'out_channels': 64,\n",
       "  'kernel_size': (7, 7),\n",
       "  'stride': (2, 2),\n",
       "  'padding': (3, 3),\n",
       "  'bias': False},\n",
       " 'bn1': {'num_features': 64,\n",
       "  'eps': 1e-05,\n",
       "  'momentum': 0.1,\n",
       "  'affine': True,\n",
       "  'track_running_stats': True},\n",
       " 'relu': {'inplace': True},\n",
       " 'maxpool': {'kernel_size': 3,\n",
       "  'stride': 2,\n",
       "  'padding': 1,\n",
       "  'dilation': 1,\n",
       "  'ceil_mode': False},\n",
       " 'layer1_0': {'conv1': {'in_channels': 64,\n",
       "   'out_channels': 64,\n",
       "   'kernel_size': (3, 3),\n",
       "   'stride': (1, 1),\n",
       "   'padding': (1, 1),\n",
       "   'bias': False},\n",
       "  'bn1': {'num_features': 64,\n",
       "   'eps': 1e-05,\n",
       "   'momentum': 0.1,\n",
       "   'affine': True,\n",
       "   'track_running_stats': True},\n",
       "  'relu': {'inplace': True},\n",
       "  'conv2': {'in_channels': 64,\n",
       "   'out_channels': 64,\n",
       "   'kernel_size': (3, 3),\n",
       "   'stride': (1, 1),\n",
       "   'padding': (1, 1),\n",
       "   'bias': False},\n",
       "  'bn2': {'num_features': 64,\n",
       "   'eps': 1e-05,\n",
       "   'momentum': 0.1,\n",
       "   'affine': True,\n",
       "   'track_running_stats': True}},\n",
       " 'layer1_1': {'conv1': {'in_channels': 64,\n",
       "   'out_channels': 64,\n",
       "   'kernel_size': (3, 3),\n",
       "   'stride': (1, 1),\n",
       "   'padding': (1, 1),\n",
       "   'bias': False},\n",
       "  'bn1': {'num_features': 64,\n",
       "   'eps': 1e-05,\n",
       "   'momentum': 0.1,\n",
       "   'affine': True,\n",
       "   'track_running_stats': True},\n",
       "  'relu': {'inplace': True},\n",
       "  'conv2': {'in_channels': 64,\n",
       "   'out_channels': 64,\n",
       "   'kernel_size': (3, 3),\n",
       "   'stride': (1, 1),\n",
       "   'padding': (1, 1),\n",
       "   'bias': False},\n",
       "  'bn2': {'num_features': 64,\n",
       "   'eps': 1e-05,\n",
       "   'momentum': 0.1,\n",
       "   'affine': True,\n",
       "   'track_running_stats': True}},\n",
       " 'layer1_2': {'conv1': {'in_channels': 64,\n",
       "   'out_channels': 64,\n",
       "   'kernel_size': (3, 3),\n",
       "   'stride': (1, 1),\n",
       "   'padding': (1, 1),\n",
       "   'bias': False},\n",
       "  'bn1': {'num_features': 64,\n",
       "   'eps': 1e-05,\n",
       "   'momentum': 0.1,\n",
       "   'affine': True,\n",
       "   'track_running_stats': True},\n",
       "  'relu': {'inplace': True},\n",
       "  'conv2': {'in_channels': 64,\n",
       "   'out_channels': 64,\n",
       "   'kernel_size': (3, 3),\n",
       "   'stride': (1, 1),\n",
       "   'padding': (1, 1),\n",
       "   'bias': False},\n",
       "  'bn2': {'num_features': 64,\n",
       "   'eps': 1e-05,\n",
       "   'momentum': 0.1,\n",
       "   'affine': True,\n",
       "   'track_running_stats': True}},\n",
       " 'layer2_0': {'conv1': {'in_channels': 64,\n",
       "   'out_channels': 128,\n",
       "   'kernel_size': (3, 3),\n",
       "   'stride': (2, 2),\n",
       "   'padding': (1, 1),\n",
       "   'bias': False},\n",
       "  'bn1': {'num_features': 128,\n",
       "   'eps': 1e-05,\n",
       "   'momentum': 0.1,\n",
       "   'affine': True,\n",
       "   'track_running_stats': True},\n",
       "  'relu': {'inplace': True},\n",
       "  'conv2': {'in_channels': 128,\n",
       "   'out_channels': 128,\n",
       "   'kernel_size': (3, 3),\n",
       "   'stride': (1, 1),\n",
       "   'padding': (1, 1),\n",
       "   'bias': False},\n",
       "  'bn2': {'num_features': 128,\n",
       "   'eps': 1e-05,\n",
       "   'momentum': 0.1,\n",
       "   'affine': True,\n",
       "   'track_running_stats': True},\n",
       "  'downsample_conv': {'in_channels': 64,\n",
       "   'out_channels': 128,\n",
       "   'kernel_size': (1, 1),\n",
       "   'stride': (2, 2),\n",
       "   'padding': (0, 0),\n",
       "   'bias': False},\n",
       "  'downsample_bn': {'num_features': 128,\n",
       "   'eps': 1e-05,\n",
       "   'momentum': 0.1,\n",
       "   'affine': True,\n",
       "   'track_running_stats': True}},\n",
       " 'layer2_1': {'conv1': {'in_channels': 128,\n",
       "   'out_channels': 128,\n",
       "   'kernel_size': (3, 3),\n",
       "   'stride': (1, 1),\n",
       "   'padding': (1, 1),\n",
       "   'bias': False},\n",
       "  'bn1': {'num_features': 128,\n",
       "   'eps': 1e-05,\n",
       "   'momentum': 0.1,\n",
       "   'affine': True,\n",
       "   'track_running_stats': True},\n",
       "  'relu': {'inplace': True},\n",
       "  'conv2': {'in_channels': 128,\n",
       "   'out_channels': 128,\n",
       "   'kernel_size': (3, 3),\n",
       "   'stride': (1, 1),\n",
       "   'padding': (1, 1),\n",
       "   'bias': False},\n",
       "  'bn2': {'num_features': 128,\n",
       "   'eps': 1e-05,\n",
       "   'momentum': 0.1,\n",
       "   'affine': True,\n",
       "   'track_running_stats': True}},\n",
       " 'layer2_2': {'conv1': {'in_channels': 128,\n",
       "   'out_channels': 128,\n",
       "   'kernel_size': (3, 3),\n",
       "   'stride': (1, 1),\n",
       "   'padding': (1, 1),\n",
       "   'bias': False},\n",
       "  'bn1': {'num_features': 128,\n",
       "   'eps': 1e-05,\n",
       "   'momentum': 0.1,\n",
       "   'affine': True,\n",
       "   'track_running_stats': True},\n",
       "  'relu': {'inplace': True},\n",
       "  'conv2': {'in_channels': 128,\n",
       "   'out_channels': 128,\n",
       "   'kernel_size': (3, 3),\n",
       "   'stride': (1, 1),\n",
       "   'padding': (1, 1),\n",
       "   'bias': False},\n",
       "  'bn2': {'num_features': 128,\n",
       "   'eps': 1e-05,\n",
       "   'momentum': 0.1,\n",
       "   'affine': True,\n",
       "   'track_running_stats': True}},\n",
       " 'layer2_3': {'conv1': {'in_channels': 128,\n",
       "   'out_channels': 128,\n",
       "   'kernel_size': (3, 3),\n",
       "   'stride': (1, 1),\n",
       "   'padding': (1, 1),\n",
       "   'bias': False},\n",
       "  'bn1': {'num_features': 128,\n",
       "   'eps': 1e-05,\n",
       "   'momentum': 0.1,\n",
       "   'affine': True,\n",
       "   'track_running_stats': True},\n",
       "  'relu': {'inplace': True},\n",
       "  'conv2': {'in_channels': 128,\n",
       "   'out_channels': 128,\n",
       "   'kernel_size': (3, 3),\n",
       "   'stride': (1, 1),\n",
       "   'padding': (1, 1),\n",
       "   'bias': False},\n",
       "  'bn2': {'num_features': 128,\n",
       "   'eps': 1e-05,\n",
       "   'momentum': 0.1,\n",
       "   'affine': True,\n",
       "   'track_running_stats': True}},\n",
       " 'layer3_0': {'conv1': {'in_channels': 128,\n",
       "   'out_channels': 256,\n",
       "   'kernel_size': (3, 3),\n",
       "   'stride': (2, 2),\n",
       "   'padding': (1, 1),\n",
       "   'bias': False},\n",
       "  'bn1': {'num_features': 256,\n",
       "   'eps': 1e-05,\n",
       "   'momentum': 0.1,\n",
       "   'affine': True,\n",
       "   'track_running_stats': True},\n",
       "  'relu': {'inplace': True},\n",
       "  'conv2': {'in_channels': 256,\n",
       "   'out_channels': 256,\n",
       "   'kernel_size': (3, 3),\n",
       "   'stride': (1, 1),\n",
       "   'padding': (1, 1),\n",
       "   'bias': False},\n",
       "  'bn2': {'num_features': 256,\n",
       "   'eps': 1e-05,\n",
       "   'momentum': 0.1,\n",
       "   'affine': True,\n",
       "   'track_running_stats': True},\n",
       "  'downsample_conv': {'in_channels': 128,\n",
       "   'out_channels': 256,\n",
       "   'kernel_size': (1, 1),\n",
       "   'stride': (2, 2),\n",
       "   'padding': (0, 0),\n",
       "   'bias': False},\n",
       "  'downsample_bn': {'num_features': 256,\n",
       "   'eps': 1e-05,\n",
       "   'momentum': 0.1,\n",
       "   'affine': True,\n",
       "   'track_running_stats': True}},\n",
       " 'layer3_1': {'conv1': {'in_channels': 256,\n",
       "   'out_channels': 256,\n",
       "   'kernel_size': (3, 3),\n",
       "   'stride': (1, 1),\n",
       "   'padding': (1, 1),\n",
       "   'bias': False},\n",
       "  'bn1': {'num_features': 256,\n",
       "   'eps': 1e-05,\n",
       "   'momentum': 0.1,\n",
       "   'affine': True,\n",
       "   'track_running_stats': True},\n",
       "  'relu': {'inplace': True},\n",
       "  'conv2': {'in_channels': 256,\n",
       "   'out_channels': 256,\n",
       "   'kernel_size': (3, 3),\n",
       "   'stride': (1, 1),\n",
       "   'padding': (1, 1),\n",
       "   'bias': False},\n",
       "  'bn2': {'num_features': 256,\n",
       "   'eps': 1e-05,\n",
       "   'momentum': 0.1,\n",
       "   'affine': True,\n",
       "   'track_running_stats': True}},\n",
       " 'layer3_2': {'conv1': {'in_channels': 256,\n",
       "   'out_channels': 256,\n",
       "   'kernel_size': (3, 3),\n",
       "   'stride': (1, 1),\n",
       "   'padding': (1, 1),\n",
       "   'bias': False},\n",
       "  'bn1': {'num_features': 256,\n",
       "   'eps': 1e-05,\n",
       "   'momentum': 0.1,\n",
       "   'affine': True,\n",
       "   'track_running_stats': True},\n",
       "  'relu': {'inplace': True},\n",
       "  'conv2': {'in_channels': 256,\n",
       "   'out_channels': 256,\n",
       "   'kernel_size': (3, 3),\n",
       "   'stride': (1, 1),\n",
       "   'padding': (1, 1),\n",
       "   'bias': False},\n",
       "  'bn2': {'num_features': 256,\n",
       "   'eps': 1e-05,\n",
       "   'momentum': 0.1,\n",
       "   'affine': True,\n",
       "   'track_running_stats': True}},\n",
       " 'layer3_3': {'conv1': {'in_channels': 256,\n",
       "   'out_channels': 256,\n",
       "   'kernel_size': (3, 3),\n",
       "   'stride': (1, 1),\n",
       "   'padding': (1, 1),\n",
       "   'bias': False},\n",
       "  'bn1': {'num_features': 256,\n",
       "   'eps': 1e-05,\n",
       "   'momentum': 0.1,\n",
       "   'affine': True,\n",
       "   'track_running_stats': True},\n",
       "  'relu': {'inplace': True},\n",
       "  'conv2': {'in_channels': 256,\n",
       "   'out_channels': 256,\n",
       "   'kernel_size': (3, 3),\n",
       "   'stride': (1, 1),\n",
       "   'padding': (1, 1),\n",
       "   'bias': False},\n",
       "  'bn2': {'num_features': 256,\n",
       "   'eps': 1e-05,\n",
       "   'momentum': 0.1,\n",
       "   'affine': True,\n",
       "   'track_running_stats': True}},\n",
       " 'layer3_4': {'conv1': {'in_channels': 256,\n",
       "   'out_channels': 256,\n",
       "   'kernel_size': (3, 3),\n",
       "   'stride': (1, 1),\n",
       "   'padding': (1, 1),\n",
       "   'bias': False},\n",
       "  'bn1': {'num_features': 256,\n",
       "   'eps': 1e-05,\n",
       "   'momentum': 0.1,\n",
       "   'affine': True,\n",
       "   'track_running_stats': True},\n",
       "  'relu': {'inplace': True},\n",
       "  'conv2': {'in_channels': 256,\n",
       "   'out_channels': 256,\n",
       "   'kernel_size': (3, 3),\n",
       "   'stride': (1, 1),\n",
       "   'padding': (1, 1),\n",
       "   'bias': False},\n",
       "  'bn2': {'num_features': 256,\n",
       "   'eps': 1e-05,\n",
       "   'momentum': 0.1,\n",
       "   'affine': True,\n",
       "   'track_running_stats': True}},\n",
       " 'layer3_5': {'conv1': {'in_channels': 256,\n",
       "   'out_channels': 256,\n",
       "   'kernel_size': (3, 3),\n",
       "   'stride': (1, 1),\n",
       "   'padding': (1, 1),\n",
       "   'bias': False},\n",
       "  'bn1': {'num_features': 256,\n",
       "   'eps': 1e-05,\n",
       "   'momentum': 0.1,\n",
       "   'affine': True,\n",
       "   'track_running_stats': True},\n",
       "  'relu': {'inplace': True},\n",
       "  'conv2': {'in_channels': 256,\n",
       "   'out_channels': 256,\n",
       "   'kernel_size': (3, 3),\n",
       "   'stride': (1, 1),\n",
       "   'padding': (1, 1),\n",
       "   'bias': False},\n",
       "  'bn2': {'num_features': 256,\n",
       "   'eps': 1e-05,\n",
       "   'momentum': 0.1,\n",
       "   'affine': True,\n",
       "   'track_running_stats': True}},\n",
       " 'layer4_0': {'conv1': {'in_channels': 256,\n",
       "   'out_channels': 512,\n",
       "   'kernel_size': (3, 3),\n",
       "   'stride': (2, 2),\n",
       "   'padding': (1, 1),\n",
       "   'bias': False},\n",
       "  'bn1': {'num_features': 512,\n",
       "   'eps': 1e-05,\n",
       "   'momentum': 0.1,\n",
       "   'affine': True,\n",
       "   'track_running_stats': True},\n",
       "  'relu': {'inplace': True},\n",
       "  'conv2': {'in_channels': 512,\n",
       "   'out_channels': 512,\n",
       "   'kernel_size': (3, 3),\n",
       "   'stride': (1, 1),\n",
       "   'padding': (1, 1),\n",
       "   'bias': False},\n",
       "  'bn2': {'num_features': 512,\n",
       "   'eps': 1e-05,\n",
       "   'momentum': 0.1,\n",
       "   'affine': True,\n",
       "   'track_running_stats': True},\n",
       "  'downsample_conv': {'in_channels': 256,\n",
       "   'out_channels': 512,\n",
       "   'kernel_size': (1, 1),\n",
       "   'stride': (2, 2),\n",
       "   'padding': (0, 0),\n",
       "   'bias': False},\n",
       "  'downsample_bn': {'num_features': 512,\n",
       "   'eps': 1e-05,\n",
       "   'momentum': 0.1,\n",
       "   'affine': True,\n",
       "   'track_running_stats': True}},\n",
       " 'layer4_1': {'conv1': {'in_channels': 512,\n",
       "   'out_channels': 512,\n",
       "   'kernel_size': (3, 3),\n",
       "   'stride': (1, 1),\n",
       "   'padding': (1, 1),\n",
       "   'bias': False},\n",
       "  'bn1': {'num_features': 512,\n",
       "   'eps': 1e-05,\n",
       "   'momentum': 0.1,\n",
       "   'affine': True,\n",
       "   'track_running_stats': True},\n",
       "  'relu': {'inplace': True},\n",
       "  'conv2': {'in_channels': 512,\n",
       "   'out_channels': 512,\n",
       "   'kernel_size': (3, 3),\n",
       "   'stride': (1, 1),\n",
       "   'padding': (1, 1),\n",
       "   'bias': False},\n",
       "  'bn2': {'num_features': 512,\n",
       "   'eps': 1e-05,\n",
       "   'momentum': 0.1,\n",
       "   'affine': True,\n",
       "   'track_running_stats': True}},\n",
       " 'layer4_2': {'conv1': {'in_channels': 512,\n",
       "   'out_channels': 512,\n",
       "   'kernel_size': (3, 3),\n",
       "   'stride': (1, 1),\n",
       "   'padding': (1, 1),\n",
       "   'bias': False},\n",
       "  'bn1': {'num_features': 512,\n",
       "   'eps': 1e-05,\n",
       "   'momentum': 0.1,\n",
       "   'affine': True,\n",
       "   'track_running_stats': True},\n",
       "  'relu': {'inplace': True},\n",
       "  'conv2': {'in_channels': 512,\n",
       "   'out_channels': 512,\n",
       "   'kernel_size': (3, 3),\n",
       "   'stride': (1, 1),\n",
       "   'padding': (1, 1),\n",
       "   'bias': False},\n",
       "  'bn2': {'num_features': 512,\n",
       "   'eps': 1e-05,\n",
       "   'momentum': 0.1,\n",
       "   'affine': True,\n",
       "   'track_running_stats': True}},\n",
       " 'avgpool': {'output_size': (1, 1)},\n",
       " 'fc': {'in_features': 512, 'out_features': 1000, 'bias': True}}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model34_config = ResnetConfig(model34)\n",
    "model34_config.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
<<<<<<< HEAD
   "source": []
>>>>>>> 129c7eb (update new resnet)
=======
   "source": [
    "input_size = (3, 224, 224)  # (channels, height, width)\n",
    "input_tensor = torch.randn(1, *input_size)  # Batch size of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([599])\n"
     ]
    }
   ],
   "source": [
    "model34.eval()\n",
    "output_origin = model34(input_tensor)\n",
    "print(output_origin.argmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 True True\n",
      "0 1 True True\n",
      "0 2 True True\n",
      "0 1 True True\n",
      "0 1 True True\n",
      "0 1 True True\n",
      "0 2 True True\n",
      "0 1 True True\n",
      "0 1 True True\n",
      "0 1 True True\n",
      "0 1 True True\n",
      "0 1 True True\n",
      "0 2 True True\n",
      "0 1 True True\n",
      "0 1 True True\n"
     ]
    }
   ],
   "source": [
    "model_shard_config = ModuleShardConfig(layer_start=4, layer_end=37, is_first = True, is_last = True)\n",
    "model34_shard = ResNetModelShard34(model34_config, model_shard_config, model34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNetModelShard34(\n",
       "  (layers): ModuleList(\n",
       "    (0-1): 2 x ResNetLayerShard(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): ResNetLayerShard(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample_conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (downsample_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3-5): 3 x ResNetLayerShard(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): ResNetLayerShard(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample_conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (downsample_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7-11): 5 x ResNetLayerShard(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (12): ResNetLayerShard(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample_conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (downsample_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (13-14): 2 x ResNetLayerShard(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model34_shard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([904])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model34_shard.eval()\n",
    "with torch.no_grad(): \n",
    "    output_shard = model34_shard(input_tensor)[0]\n",
    "output_shard.unsqueeze(0).argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([599])\n",
      "1 tensor(True)\n",
      "tensor([599])\n",
      "2 tensor(True)\n",
      "tensor([599])\n",
      "3 tensor(True)\n",
      "tensor([599])\n",
      "4 tensor(True)\n",
      "tensor([599])\n",
      "5 tensor(True)\n",
      "tensor([599])\n",
      "6 tensor(True)\n",
      "tensor([599])\n",
      "7 tensor(True)\n",
      "tensor([599])\n",
      "8 tensor(True)\n",
      "tensor([599])\n",
      "9 tensor(True)\n",
      "tensor([599])\n",
      "10 tensor(True)\n",
      "tensor([599])\n",
      "11 tensor(True)\n",
      "tensor([599])\n",
      "12 tensor(True)\n",
      "tensor([599])\n",
      "13 tensor(True)\n",
      "tensor([599])\n",
      "14 tensor(True)\n",
      "tensor([599])\n",
      "15 tensor(True)\n",
      "tensor([599])\n",
      "16 tensor(True)\n",
      "tensor([599])\n",
      "17 tensor(True)\n",
      "tensor([599])\n",
      "18 tensor(True)\n",
      "tensor([599])\n",
      "19 tensor(True)\n",
      "tensor([599])\n",
      "20 tensor(True)\n",
      "tensor([599])\n",
      "21 tensor(True)\n",
      "tensor([599])\n",
      "22 tensor(True)\n",
      "tensor([599])\n",
      "23 tensor(True)\n",
      "tensor([599])\n",
      "24 tensor(True)\n",
      "tensor([599])\n",
      "25 tensor(True)\n",
      "tensor([599])\n",
      "26 tensor(True)\n",
      "tensor([599])\n",
      "27 tensor(True)\n",
      "tensor([599])\n",
      "28 tensor(True)\n",
      "tensor([599])\n",
      "29 tensor(True)\n",
      "tensor([599])\n",
      "30 tensor(True)\n",
      "tensor([599])\n",
      "31 tensor(True)\n",
      "tensor([599])\n",
      "32 tensor(True)\n",
      "tensor([599])\n",
      "33 tensor(True)\n",
      "tensor([599])\n",
      "34 tensor(True)\n",
      "tensor([599])\n",
      "35 tensor(True)\n",
      "tensor([599])\n",
      "36 tensor(True)\n",
      "tensor([599])\n",
      "37 tensor(True)\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,38):\n",
    "    # print(i)\n",
    "    model34_part1_shard_config = ModuleShardConfig(layer_start=1, layer_end=i, is_first = True)\n",
    "    model34_part2_shard_config = ModuleShardConfig(layer_start=i+1, layer_end=37, is_last = True)\n",
    "\n",
    "    model34_part1 = ResNetModelShard34(res_config, model34_part1_shard_config, model34)\n",
    "    model34_part2 = ResNetModelShard34(res_config, model34_part2_shard_config, model34)\n",
    "\n",
    "    model34_part1.eval()\n",
    "    model34_part2.eval()\n",
    "    model34.eval()\n",
    "\n",
    "    with torch.no_grad(): \n",
    "        output_shard = model34_part1.forward(input_tensor)\n",
    "        output_shard = model34_part2.forward(output_shard)[0]\n",
    "        output_origin = model34(input_tensor)\n",
    "        # print(output_shard.unsqueeze(0).shape, output_origin.shape)\n",
    "    print(output_shard.unsqueeze(0).argmax(dim=1))\n",
    "        # print(output_origin.argmax(dim=1))\n",
    "    print(i, torch.all(output_shard.eq(output_origin)))"
   ]
>>>>>>> e4bd167 (update resnet 34 and 50)
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
